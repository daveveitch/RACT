#### TCGA - Data Preprocessing ####

explore_gene_20240916<-function(){
  # Based on following ChatGPT log
  # https://chatgpt.com/share/66e97f9f-27e4-8011-a10e-f8a301873a5b
  
  # Install and load TCGAbiolinks
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install("TCGAbiolinks",force=TRUE)
  BiocManager::install("httr2",force=TRUE)
  
  library(TCGAbiolinks)

  query <- GDCquery(
    project = c("TCGA-LUAD"),
    data.category = "Transcriptome Profiling",
    data.type = "Gene Expression Quantification",
    platform = "Illumina",
    experimental.strategy = "RNA-Seq"
  )
  
  # Download and prepare the data
  GDCdownload(query)
  gdc_data <- GDCprepare(query)
  
  if (!requireNamespace("SummarizedExperiment", quietly = TRUE))
    BiocManager::install("SummarizedExperiment")
  
  # Load the SummarizedExperiment package
  library(SummarizedExperiment)
  
  # Convert gdc_data to matrix format
  expression_matrix <- as.matrix(assay(gdc_data))
  
  # Only keep protein coding genes
  protein_coding_rows = rowData(gdc_data)$gene_type=='protein_coding'
  
  orig_protein_coding_matrix = expression_matrix[protein_coding_rows,]
  
  # Process Data using Log2 transofmration
  processed_protein_coding_matrix = log2(orig_protein_coding_matrix + 1)
  
  # Visualize
  hist(rowMeans(processed_protein_coding_matrix),breaks=100)
  
}

explore_gene_20240917<-function(){
  # Based on following ChatGPT log
  # https://chatgpt.com/share/66e97f9f-27e4-8011-a10e-f8a301873a5b
  
  # Install and load TCGAbiolinks
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  if (!requireNamespace("TCGAbiolinks", quietly = TRUE))
    install.packages("TCGAbiolinks")
  if (!requireNamespace("httr2", quietly = TRUE))
    install.packages("httr2")
  if (!requireNamespace("SummarizedExperiment", quietly = TRUE))
    BiocManager::install("SummarizedExperiment")

  library(BiocManager)
  library(TCGAbiolinks)
  library(httr2)
  library(SummarizedExperiment)
  library(Matrix)
  
  query <- GDCquery(
    project = c("TCGA-LUAD","TCGA-LUSC"),
    data.category = "Transcriptome Profiling",
    data.type = "Gene Expression Quantification",
    platform = "Illumina",
    experimental.strategy = "RNA-Seq"
  )
  
  # Download and prepare the data
  GDCdownload(query)
  gdc_data <- GDCprepare(query)
  
  working_dir = 'C:/Users/davev/Documents/UofT/PhD/Research/Brain/BrainR/NewApplications'
  # saveRDS(gdc_data,file=paste(working_dir,'/gdc_data.rds',sep=''))
  setwd(working_dir)
  gdc_data=readRDS('gdc_data.rds')
  
  # Convert gdc_data to matrix format
  expression_matrix <- as.matrix(assay(gdc_data))
  
  # Only keep protein coding genes
  protein_coding_rows = rowData(gdc_data)$gene_type=='protein_coding'
  
  orig_protein_coding_matrix = expression_matrix[protein_coding_rows,]
  
  # Process Data using Log2 transofmration
  processed_protein_coding_matrix = log2(orig_protein_coding_matrix + 1)
  
  # Split into LUAD and LUSC
  luad_columns = colData(gdc_data)$project_id=='TCGA-LUAD'
  lusc_columns = colData(gdc_data)$project_id=='TCGA-LUSC'
  
  processed_LUAD = processed_protein_coding_matrix[,luad_columns]
  processed_LUSC = processed_protein_coding_matrix[,lusc_columns]
  
  # Centre and calculate residuals
  resids_LUAD = processed_LUAD-rowMeans(processed_LUAD)
  resids_LUSC = processed_LUSC-rowMeans(processed_LUSC)
  
  # Variance of Gene Expressions (combined LUAD, LUSC)
  top_amt = 500
  var_genes = apply(cbind(resids_LUAD,resids_LUSC),1,var)
  top_genes = names(sort(var_genes,decreasing=TRUE)[1:top_amt])
  
  # Cov Matrix of top genes
  cov_LUAD = cor(t(resids_LUAD[rownames(resids_LUAD) %in% top_genes,]))
  cov_LUSC = cov(t(resids_LUSC[rownames(resids_LUSC) %in% top_genes,]))
  
  # Visualize
  hist(rowMeans(processed_LUAD),breaks=100,main='Mean Gene Expression LUAD')
  hist(rowMeans(processed_LUSC),breaks=100,,main='Mean Gene Expression LUSC')
  hist(apply(cbind(resids_LUAD,resids_LUSC),1,var),breaks=200,main='Variance by of Residuals')
  
  abline(v=sort(var_genes,decreasing=TRUE)[1:top_amt][top_amt]) # Line showing Cutoff
  
  image(Matrix(cov_LUAD),lwd=0)
  image(Matrix(cov_LUSC),lwd=0)
  
}

gene_preprocess_final_20240917<-function(){
  library(BiocManager)
  library(TCGAbiolinks)
  library(httr2)
  library(SummarizedExperiment)
  library(Matrix)
  
  working_dir = 'C:/Users/davev/Documents/UofT/PhD/Research/Brain/BrainR/NewApplications'
  setwd(working_dir)
  gdc_data=readRDS('gdc_data.rds')
  
  # Convert gdc_data to matrix format
  expression_matrix <- as.matrix(assay(gdc_data))
  
  # Only keep protein coding genes
  protein_coding_rows = rowData(gdc_data)$gene_type=='protein_coding'
  orig_protein_coding_matrix = expression_matrix[protein_coding_rows,]
  
  # Process Data using Log2 transformation (same as BIDIFAC)
  processed_protein_coding_matrix = log2(orig_protein_coding_matrix + 1)
  
  ## Determine top 500 genes in terms of variability ##
  
  # Split into LUAD and LUSC
  luad_columns = colData(gdc_data)$project_id=='TCGA-LUAD'
  lusc_columns = colData(gdc_data)$project_id=='TCGA-LUSC'
  
  processed_LUAD = processed_protein_coding_matrix[,luad_columns]
  processed_LUSC = processed_protein_coding_matrix[,lusc_columns]
  
  resids_LUAD = processed_LUAD-rowMeans(processed_LUAD)
  resids_LUSC = processed_LUSC-rowMeans(processed_LUSC)
  
  # Variance of Gene Expressions (combined LUAD, LUSC)
  top_amt = 500
  var_genes = apply(cbind(resids_LUAD,resids_LUSC),1,var)
  top_genes = names(sort(var_genes,decreasing=TRUE)[1:top_amt])
  top_gene_rows = rownames(processed_protein_coding_matrix) %in% top_genes
  
  residual_matrix_list = list()
  
  for(cancer_type in c('TCGA-LUAD','TCGA-LUSC')){
    # From TCGA data extract gene expression/behavioural for subjects of specific cancer type
    cancer_cols = colData(gdc_data)$project_id==cancer_type
    cancer_gene_expression_matrix = processed_protein_coding_matrix[top_gene_rows,cancer_cols]
    cancer_behavioural_matrix = colData(gdc_data)[cancer_cols,c('age_at_index','gender')]
    
    # Find subjects that have no missing behavioural data, and only keep these
    non_na_subjects = names(
      complete.cases(cancer_behavioural_matrix)
    )[complete.cases(cancer_behavioural_matrix)==TRUE]
    
    cancer_gene_expression_matrix = (
      cancer_gene_expression_matrix[,colnames(cancer_gene_expression_matrix) %in% non_na_subjects]
    )
    cancer_behavioural_matrix = (
      cancer_behavioural_matrix[rownames(cancer_behavioural_matrix) %in% non_na_subjects,]
    )
    
    # Create a new matrix with gene expressions with age/sex regressed out
    cancer_residual_matrix = cancer_gene_expression_matrix
    cancer_residual_matrix[,] = 0
    
    for(j in 1:nrow(cancer_residual_matrix)){
      
      # Create regression matrix and fit linear model
      Y = t(cancer_gene_expression_matrix[j,,drop=FALSE])
      colnames(Y) = 'gene_expression'
      XY_matrix =  merge(Y, 
                         cancer_behavioural_matrix, by = "row.names", all = TRUE)
      mod <- lm(gene_expression ~ age_at_index + gender,data=XY_matrix)
      
      # Extract residuals from linear model
      cancer_residual_matrix[j,] = residuals(mod)
    }
    
    residual_matrix_list[[cancer_type]] = cancer_residual_matrix
    
    print(paste(cancer_type,'residual matrix completed'))
  }
  
  setwd(working_dir)
  saveRDS(residual_matrix_list,file=paste(working_dir,'/residual_matrices.rds',sep=''))
  
  
}

gene_preprocess_data_20240918<-function(){
  # This function downloads the TCGA data and saves it as a RDS file
  # Based on following ChatGPT log
  # https://chatgpt.com/share/66e97f9f-27e4-8011-a10e-f8a301873a5b
  
  ## Important user defined constants ##
  # Where files are saved to
  WORKING_DIR = 'C:/Users/davev/Documents/UofT/PhD/Research/Brain/BrainR/NewApplications'
  # How many genes to include in analysis
  GENE_AMT = 500
  
  # Install and load required packages for TCGA
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  if (!requireNamespace("TCGAbiolinks", quietly = TRUE))
    install.packages("TCGAbiolinks")
  if (!requireNamespace("httr2", quietly = TRUE))
    install.packages("httr2")
  if (!requireNamespace("SummarizedExperiment", quietly = TRUE))
    BiocManager::install("SummarizedExperiment")
  if (!requireNamespace("Matrix", quietly = TRUE))
    BiocManager::install("Matrix")
  
  library(BiocManager)
  library(TCGAbiolinks)
  library(httr2)
  library(SummarizedExperiment)
  library(Matrix)
  
  setwd(WORKING_DIR)
  
  # Conduct query and save raw data as RDS file for TCGA-LUAD and TCGA-LUSC (~30mins)
  query <- GDCquery(
    project = c("TCGA-LUAD","TCGA-LUSC"),
    data.category = "Transcriptome Profiling",
    data.type = "Gene Expression Quantification",
    platform = "Illumina",
    experimental.strategy = "RNA-Seq"
  )
  GDCdownload(query)
  gdc_data <- GDCprepare(query)
  saveRDS(gdc_data,file=paste(WORKING_DIR,'/gdc_data.rds',sep=''))

  # Convert gdc_data to matrix format and keep only protein coding genes
  expression_matrix <- as.matrix(assay(gdc_data))
  protein_coding_rows = rowData(gdc_data)$gene_type=='protein_coding'
  orig_protein_coding_matrix = expression_matrix[protein_coding_rows,]
  
  # Process Data using Log2 transformation (same as BIDIFAC)
  processed_protein_coding_matrix = log2(orig_protein_coding_matrix + 1)
  
  ## Determine top 500 genes in terms of variability ##
  
  # Split into LUAD and LUSC
  luad_columns = colData(gdc_data)$project_id=='TCGA-LUAD'
  lusc_columns = colData(gdc_data)$project_id=='TCGA-LUSC'
  
  processed_LUAD = processed_protein_coding_matrix[,luad_columns]
  processed_LUSC = processed_protein_coding_matrix[,lusc_columns]
  
  resids_LUAD = processed_LUAD-rowMeans(processed_LUAD)
  resids_LUSC = processed_LUSC-rowMeans(processed_LUSC)
  
  # Variance of Gene Expressions (combined LUAD, LUSC)
  var_genes = apply(cbind(resids_LUAD,resids_LUSC),1,var)
  top_genes = names(sort(var_genes,decreasing=TRUE)[1:GENE_AMT])
  top_gene_rows = rownames(processed_protein_coding_matrix) %in% top_genes
  
  residual_matrix_list = list()
  
  for(cancer_type in c('TCGA-LUAD','TCGA-LUSC')){
    # From TCGA data extract gene expression/behavioural for subjects of specific cancer type
    cancer_cols = colData(gdc_data)$project_id==cancer_type
    cancer_gene_expression_matrix = processed_protein_coding_matrix[top_gene_rows,cancer_cols]
    cancer_behavioural_matrix = colData(gdc_data)[cancer_cols,c('age_at_index','gender')]
    
    # Find subjects that have no missing behavioural data, and only keep these
    non_na_subjects = names(
      complete.cases(cancer_behavioural_matrix)
    )[complete.cases(cancer_behavioural_matrix)==TRUE]
    
    cancer_gene_expression_matrix = (
      cancer_gene_expression_matrix[,colnames(cancer_gene_expression_matrix) %in% non_na_subjects]
    )
    cancer_behavioural_matrix = (
      cancer_behavioural_matrix[rownames(cancer_behavioural_matrix) %in% non_na_subjects,]
    )
    
    # Create a new matrix with gene expressions with age/sex regressed out
    cancer_residual_matrix = cancer_gene_expression_matrix
    cancer_residual_matrix[,] = 0
    
    for(j in 1:nrow(cancer_residual_matrix)){
      
      # Create regression matrix and fit linear model
      Y = t(cancer_gene_expression_matrix[j,,drop=FALSE])
      colnames(Y) = 'gene_expression'
      XY_matrix =  merge(Y, 
                         cancer_behavioural_matrix, by = "row.names", all = TRUE)
      mod <- lm(gene_expression ~ age_at_index + gender,data=XY_matrix)
      
      # Extract residuals from linear model
      cancer_residual_matrix[j,] = residuals(mod)
    }
    
    residual_matrix_list[[cancer_type]] = cancer_residual_matrix
    
    print(paste(cancer_type,'residual matrix completed'))
  }
  
  setwd(WORKING_DIR)
  saveRDS(residual_matrix_list,file=paste(WORKING_DIR,'/tcga_residual_matrices.rds',sep=''))
  
}

gene_data_visualize_20240918<-function(){
  ## Important user defined constants ##
  # Where files are saved to
  WORKING_DIR = 'C:/Users/davev/Documents/UofT/PhD/Research/Brain/BrainR/NewApplications'
  FIGURE_DIR = 'C:/Users/davev/Documents/UofT/PhD/Research/Brain/BrainR/NewApplications/figures'
  # How many genes to include in analysis
  GENE_AMT = 500

  library(BiocManager)
  library(TCGAbiolinks)
  library(httr2)
  library(SummarizedExperiment)
  library(Matrix)
  
  setwd(WORKING_DIR)  
  
  gdc_data = readRDS('gdc_data.rds')
  gene_expression_residuals = readRDS('residual_matrices.rds')
  
  # Do processing to look at data
  expression_matrix <- as.matrix(assay(gdc_data))
  protein_coding_rows = rowData(gdc_data)$gene_type=='protein_coding'
  orig_protein_coding_matrix = expression_matrix[protein_coding_rows,]
  
  # Process Data using Log2 transformation (same as BIDIFAC)
  processed_protein_coding_matrix = log2(orig_protein_coding_matrix + 1)
  
  ## Determine top 500 genes in terms of variability ##
  
  # Split into LUAD and LUSC
  luad_columns = colData(gdc_data)$project_id=='TCGA-LUAD'
  lusc_columns = colData(gdc_data)$project_id=='TCGA-LUSC'
  
  processed_LUAD = processed_protein_coding_matrix[,luad_columns]
  processed_LUSC = processed_protein_coding_matrix[,lusc_columns]
  
  resids_LUAD = processed_LUAD-rowMeans(processed_LUAD)
  resids_LUSC = processed_LUSC-rowMeans(processed_LUSC)
  
  # Variance of Gene Expressions (combined LUAD, LUSC)
  var_genes = apply(cbind(resids_LUAD,resids_LUSC),1,var)
  top_genes = names(sort(var_genes,decreasing=TRUE)[1:GENE_AMT])
  top_gene_rows = rownames(processed_protein_coding_matrix) %in% top_genes
  
  setwd(FIGURE_DIR)
  pdf("gene_data_visualize_20240918.pdf",width=7,height=5)
  
  par(mfrow=c(3,2),mar=c(2,2,2,1),cex=0.5)  # Set layout to 2x2
  
  hist(rowMeans(processed_LUAD),breaks=200,main='LUAD Gene Expression Counts')
  hist(rowMeans(processed_LUSC),breaks=200,main='LUSC Gene Expression Counts')
  
  var_cutoff = sort(var_genes,decreasing=TRUE)[500]
  hist(apply(resids_LUAD,1,var),breaks=200,main='LUAD Gene Expression Variances')
  abline(v=var_cutoff,col='red')
  hist(apply(resids_LUSC,1,var),breaks=200,main='LUSC Gene Expression Variances')
  abline(v=var_cutoff,col='red')
  
  my_colors <- colorRampPalette(c("red",'grey','blue'))(100)
  image((cor(t(gene_expression_residuals[['TCGA-LUAD']]))[1:50,1:50]),lwd=0,main='TCGA-LUAD Corelation',
        col=my_colors)
  image((cor(t(gene_expression_residuals[['TCGA-LUSC']]))[1:50,1:50]),lwd=0,main='TCGA-LUSC Corelation',
        col=my_colors)
  
  dev.off()  
  
}

#### TCGA - INITIAL SIMS ####

simple_power_20240918<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  # Experiment Parameters
  function_name = 'simple_power_20240918'
  K = 1000
  B = 1000
  max_k_pct = 0.8
  experiment_df = expand.grid(subsample_size = c(5,10,15,20,25,30,35,40,45,50),
                              alpha = c(0.05, 0.01),
                              null_flag = c('null','not_null'))
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  setwd(WORKING_DIR)  
  gene_expression_residuals = readRDS('residual_matrices.rds')
  n_LUAD = ncol(gene_expression_residuals[['TCGA-LUAD']])
  n_LUSC = ncol(gene_expression_residuals[['TCGA-LUSC']])
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  setwd(file.path(RESULTS_DIR,function_name))
  write.csv(experiment_df,file='experiment_df.csv') 
  
  # Determine which row of experiment_df to run
  if(job_num==999){
    # run all experiments
  }else{
    experiment_df=experiment_df[job_num,]
  }
  
  for(x in 1:nrow(experiment_df)){
    # Extract parameters from experiment_df
    subsample_size = experiment_df[x,'subsample_size']
    alpha = experiment_df[x,'alpha']
    experiment_number=experiment_df[x,'experiment_number']
    null_flag = experiment_df[x,'null_flag']
    
    # Setup Parallelization
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('RSpectra'),
                               .combine='rbind')%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select LUAD, and LUSC subjects
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sample(1:n_LUAD,subsample_size)]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUSC']][,sample(1:n_LUSC,subsample_size)]
                                 }else{
                                   # Sample only from LUAD subjects
                                   sampled_subjects = sample(1:n_LUAD,subsample_size*2)
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[1:subsample_size]]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 combined_residuals = cbind(group_1_residuals,group_2_residuals)
                                 
                                 # Determine k, such that the sum of the top k singular values gives
                                 # max_k_pct of total sum
                                 max_k = max_k_calculation(combined_residuals,max_k_pct)
                                   
                                 test_stat = test_stat_20240918(cor(t(group_1_residuals)),
                                                                cor(t(group_2_residuals)),
                                                                max_k)
                                 
                                 # Calculate test statistics for data when permuting subjects between groups
                                 permutation_stat_matrix = matrix(data=0,nrow=B,ncol=length(test_stat))
                                 colnames(permutation_stat_matrix) = names(test_stat)
                                 
                                 for(j in 1:B){
                                   permuted_order = sample(1:ncol(combined_residuals))
                                   
                                   permuted_group_1 = combined_residuals[,permuted_order[1:subsample_size]]
                                   permuted_group_2 = combined_residuals[,permuted_order[(subsample_size+1):(2*subsample_size)]]
                                   
                                   permuted_test_stat = test_stat_20240918(cor(t(permuted_group_1)),
                                                                           cor(t(permuted_group_2)),
                                                                           max_k)
                                   permutation_stat_matrix[j,] = permuted_test_stat
                                 }
                                 
                                 permutation_stat_mean = apply(permutation_stat_matrix,2,mean)
                                 permutation_stat_sd = apply(permutation_stat_matrix,2,sd)
                                 
                                 # Normalize test statistics from permutation distribution, and calculate critical values
                                 normalized_permutation_stat_matrix = t((t(permutation_stat_matrix) 
                                                                         - permutation_stat_mean) / 
                                                                          permutation_stat_sd)
                                 
                                 sum_cols =  grep('sum_',colnames(normalized_permutation_stat_matrix),value=TRUE)
                                 sumsq_cols =  grep('sumsq_',colnames(normalized_permutation_stat_matrix),value=TRUE)
                                 
                                 max_sum_perm = apply(normalized_permutation_stat_matrix[,sum_cols],1,max)
                                 max_sumsq_perm = apply(normalized_permutation_stat_matrix[,sumsq_cols],1,max)
                                 frob_perm = normalized_permutation_stat_matrix[,'Frobenius']
                                 op_perm = normalized_permutation_stat_matrix[,'sum_1']
                                 
                                 critical_values = c(quantile(max_sum_perm,1-alpha),quantile(max_sumsq_perm,1-alpha),
                                                     quantile(frob_perm,1-alpha),quantile(op_perm,1-alpha))
                                 names(critical_values) = c('max_sum','max_sumsq','frob','op')
                                 
                                 # Calculate normalized test statistic
                                 normalized_test_stat = (test_stat-permutation_stat_mean)/permutation_stat_sd
                                 
                                 sum_cols =  grep('sum_',names(normalized_test_stat),value=TRUE)
                                 sumsq_cols =  grep('sumsq_',names(normalized_test_stat),value=TRUE)
                                 
                                 max_sum_test = max(normalized_test_stat[sum_cols])
                                 max_sumsq_test = max(normalized_test_stat[sumsq_cols])
                                 frob_test = normalized_test_stat['Frobenius']
                                 op_test = normalized_test_stat['sum_1']
                                 
                                 final_test_stats = c(max_sum_test,max_sumsq_test,frob_test,op_test)
                                 names(final_test_stats) = c('max_sum','max_sumsq','frob','op')
                                 
                                 print(i)
                                 
                                 (final_test_stats > critical_values)*1  
    }
    
    parallel::stopCluster(cl)
    
    # Print out message to show experiment done and write results to csv
    print(paste(experiment_number,Sys.time()))
    setwd(file.path(RESULTS_DIR,function_name))
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.csv',sep='')
    write.csv(experiment_results,file=filename)
  }
}

simple_power_20240918_charts<-function(){
  function_name = 'simple_power_20240918'
  setwd(file.path(RESULTS_DIR,function_name))
  
  experiment_df = read.csv('experiment_df.csv')[,-1]
  experiment_df[,c('max_sum','max_sumsq','frob','op')] = 999
  
  for(i in 1:nrow(experiment_df)){
    result_filename = paste(function_name,'-',sprintf("%03d",experiment_df$experiment_number[i]),'.csv',sep='')
    result_df = read.csv(result_filename)[,-1]
    
    experiment_df[i,c('max_sum','max_sumsq','frob','op')] = colMeans(result_df)
  }
  
  setwd(FIGURE_DIR)
  pdf("simple_power_20240918.pdf",width=7,height=3)
  
  par(mfrow=c(2,2),mar=c(5,4,2,1),cex=0.5)  # Set layout to 2x2
  
  plot_cols = c('red','blue','green','purple','black')
  
  for(alpha in c(0.01,0.05)){
    for(null_flag in c('null','not_null')){
      if(null_flag=='null'){
        ylim=c(0,.1)
      }else{
        ylim=c(0,1)
      }
      
      x = experiment_df[(experiment_df$alpha==alpha)&(experiment_df$null_flag==null_flag),'subsample_size']
      plot(x, experiment_df[(experiment_df$alpha==alpha)&(experiment_df$null_flag==null_flag),'max_sum'],
           type="l", col=plot_cols[1], ylim=ylim, xlab="Subsample Size", ylab="Empirical Power", 
           main=paste('Empirical Power, alpha=',alpha,null_flag,'case'))
      
      lines(x,experiment_df[(experiment_df$alpha==alpha)&(experiment_df$null_flag==null_flag),'max_sumsq'],col=plot_cols[2])
      lines(x,experiment_df[(experiment_df$alpha==alpha)&(experiment_df$null_flag==null_flag),'frob'],col=plot_cols[3])
      lines(x,experiment_df[(experiment_df$alpha==alpha)&(experiment_df$null_flag==null_flag),'op'],col=plot_cols[4])
      
      abline(h=alpha,lty=2,col=plot_cols[5])
      
      legend("topleft", legend=c("Max Sum", "Max SumSq", "Frobenius", "Operator","Alpha"), 
             col=plot_cols,lty=c(1,1,1,1,2),lwd=.5,cex=.5)
    }
  }

  dev.off()  
  
  
}


determine_k_20240923<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  # This determines a k to use across all simulations in min_p_power_20240923 so 
  # we can compare power across different norms
  function_name = 'determine_k_20240923'
  max_k_pct = 0.8
  K = 1000
  
  experiment_df = expand.grid(subsample_size = c(5,10,15,20,25,30,35,40,45,50),
                              null_flag = c('null','not_null'))
  experiment_df[,'avg_k'] = 999
  
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  setwd(file.path(RESULTS_DIR,function_name))
  
  # Import Data
  setwd(WORKING_DIR)  
  gene_expression_residuals = readRDS('residual_matrices.rds')
  n_LUAD = ncol(gene_expression_residuals[['TCGA-LUAD']])
  n_LUSC = ncol(gene_expression_residuals[['TCGA-LUSC']])
  
  # Setup Parallelization
  Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
  cl <- parallel::makeCluster(ncores,outfile="")
  doParallel::registerDoParallel(cl)
  
  experiment_results=foreach(j=1:nrow(experiment_df), 
                             .packages = c('RSpectra'),
                             .combine='c')%dopar%{
  
          setwd(WORKING_DIR)
          source('NewAppsHelper.R')
          subsample_size = experiment_df[j,'subsample_size']
          k_dist = c()
          
          for(i in 1:K){
            set.seed(i)
            
            # Sample only from LUAD subjects
            sampled_subjects = sample(1:n_LUAD,subsample_size*2)
            group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[1:subsample_size]]
            group_2_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
            
            combined_residuals = cbind(group_1_residuals,group_2_residuals)
            
            # Determine k, such that the sum of the top k singular values gives
            # max_k_pct of total sum
            max_k = max_k_calculation(combined_residuals,max_k_pct)
            k_dist = c(k_dist,max_k)
            
            print(i)
          }
          
          mean(k_dist)
          
                             }
  parallel::stopCluster(cl)
  
  experiment_df[,'avg_k'] = experiment_results
  
  setwd(file.path(RESULTS_DIR,function_name))
  filename=paste(function_name,'.csv',sep='')
  write.csv(experiment_df,file=filename)
  
}

min_p_power_20240918<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  # Experiment Parameters
  function_name = 'min_p_power_20240918'
  K = 1000
  B = 1000
  experiment_df = expand.grid(subsample_size = c(5,10,15,20,25,30,35,40,45,50),
                              alpha = c(0.05, 0.01),
                              null_flag = c('null','not_null'))
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import results from determine_k_20240923 in order to have consistent k for
  # all subsamples taken for a given parameter combination
  setwd(file.path(RESULTS_DIR,'determine_k_20240923'))
  max_k_csv = read.csv('determine_k_20240923.csv')
  
  experiment_df <- merge(experiment_df, max_k_csv, 
                         by = c('subsample_size','null_flag'), all.x = TRUE)
  experiment_df[,'k_all'] = ceiling(experiment_df[,'avg_k'])
  experiment_df = experiment_df[order(experiment_df$experiment_number),]
  print(experiment_df)
  
  # Import Data
  setwd(WORKING_DIR)  
  gene_expression_residuals = readRDS('residual_matrices.rds')
  n_LUAD = ncol(gene_expression_residuals[['TCGA-LUAD']])
  n_LUSC = ncol(gene_expression_residuals[['TCGA-LUSC']])
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  setwd(file.path(RESULTS_DIR,function_name))
  write.csv(experiment_df,file='experiment_df.csv') 
  
  # Determine which row of experiment_df to run
  if(job_num==999){
    # run all experiments
  }else{
    experiment_df=experiment_df[job_num,]
  }
  
  for(x in 1:nrow(experiment_df)){
    # Extract parameters from experiment_df
    subsample_size = experiment_df[x,'subsample_size']
    alpha = experiment_df[x,'alpha']
    experiment_number=experiment_df[x,'experiment_number']
    null_flag = experiment_df[x,'null_flag']
    k_all = experiment_df[x,'k_all']
    
    # Setup Parallelization
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('RSpectra'),
                               .combine='rbind')%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select LUAD, and LUSC subjects
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sample(1:n_LUAD,subsample_size)]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUSC']][,sample(1:n_LUSC,subsample_size)]
                                 }else{
                                   # Sample only from LUAD subjects
                                   sampled_subjects = sample(1:n_LUAD,subsample_size*2)
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[1:subsample_size]]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 combined_residuals = cbind(group_1_residuals,group_2_residuals)
                                 
                                 test_stat = test_stat_20240918(cor(t(group_1_residuals)),
                                                                cor(t(group_2_residuals)),
                                                                k_all)
                                 
                                 # Calculate test statistics for data when permuting subjects between groups
                                 permutation_stat_matrix = matrix(data=0,nrow=B,ncol=length(test_stat))
                                 colnames(permutation_stat_matrix) = names(test_stat)
                                 
                                 for(j in 1:B){
                                   permuted_order = sample(1:ncol(combined_residuals))
                                   
                                   permuted_group_1 = combined_residuals[,permuted_order[1:subsample_size]]
                                   permuted_group_2 = combined_residuals[,permuted_order[(subsample_size+1):(2*subsample_size)]]
                                   
                                   permuted_test_stat = test_stat_20240918(cor(t(permuted_group_1)),
                                                                           cor(t(permuted_group_2)),
                                                                           k_all)
                                   permutation_stat_matrix[j,] = c(permuted_test_stat)
                                 }
                                 
                                 # For each test statistic type (e.g. sumsq_10) and for each permutation
                                 # we count the number of other permutations with statistics greater than
                                 # that permutations value
                                 permutation_p_value_matrix = apply(permutation_stat_matrix,
                                                                    2,
                                                                    count_greater_than_equal_to)/B    
                                 
                                 # Take a minimum p across all sum, sumsq statistics and add them to 
                                 # permutation_p_value_matrix
                                 sum_cols =  grep('sum_',colnames(permutation_p_value_matrix),value=TRUE)
                                 sumsq_cols =  grep('sumsq_',colnames(permutation_p_value_matrix),value=TRUE)
                                 sum_min_p = apply(permutation_p_value_matrix[,sum_cols],1,min)
                                 sumsq_min_p = apply(permutation_p_value_matrix[,sumsq_cols],1,min)
                                 
                                 permutation_p_value_matrix = cbind(permutation_p_value_matrix,
                                                                    sum_min_p,sumsq_min_p)
                                 
                                 p_critical_values = apply(permutation_p_value_matrix,
                                                           2,
                                                           function(x) quantile(x, probs=0.05))
                                
                                 # Calculate p-values of test statistics, here we count number of
                                 # permutations with test statistic greater than test statistic of observed
                                 # data and then divide by number of permutations + 1
                                 observed_p_values = (colSums(t(t(permutation_stat_matrix)>=test_stat))+1)/B
                                 observed_p_values['sum_min_p'] = min(observed_p_values[sum_cols])
                                 observed_p_values['sumsq_min_p'] = min(observed_p_values[sumsq_cols])
                                 
                                 print(i)
                                 
                                 (observed_p_values < p_critical_values)*1  
                               }
    
    parallel::stopCluster(cl)
    
    # Print out message to show experiment done and write results to csv
    print(paste(experiment_number,Sys.time()))
    setwd(file.path(RESULTS_DIR,function_name))
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.csv',sep='')
    write.csv(experiment_results,file=filename)
  }
}

min_p_power_20240918_charts<-function(){
  function_name = 'min_p_power_20240918'
  setwd(file.path(RESULTS_DIR,function_name))
  
  experiment_df = read.csv('experiment_df.csv')[,-1]
  experiment_df[,c('Frobenius','sum_1','sum_min_p','sumsq_min_p')] = 999
  
  for(i in 1:nrow(experiment_df)){
    # Plot of Power curve across different subsample sizes
    result_filename = paste(function_name,'-',sprintf("%03d",experiment_df$experiment_number[i]),'.csv',sep='')
    result_df = read.csv(result_filename)[,-1]
    
    experiment_df[i,c('Frobenius','sum_1','sum_min_p','sumsq_min_p')] = (
      colMeans(result_df[,c('Frobenius','sum_1','sum_min_p','sumsq_min_p')]))
  }
  
  setwd(FIGURE_DIR)
  pdf("min_p_power_20240918_vary_subsample.pdf",width=7,height=3)
  
  par(mfrow=c(1,1),mar=c(5,4,2,1),cex=0.5)  # Set layout to 2x2
  
  plot_cols = c('red','blue','green','purple','black')
  
  for(alpha in c(0.05)){
    for(null_flag in c('not_null')){
      if(null_flag=='null'){
        ylim=c(0,.1)
      }else{
        ylim=c(0,1)
      }
      
      x = experiment_df[(experiment_df$alpha==alpha)&(experiment_df$null_flag==null_flag),'subsample_size']
      plot(x, experiment_df[(experiment_df$alpha==alpha)&(experiment_df$null_flag==null_flag),'sum_min_p'],
           type="l", col=plot_cols[1], ylim=ylim, xlab="Subsample Size", ylab="Empirical Power", 
           main=paste('Empirical Power, alpha=',alpha,null_flag,'case'))
      
      lines(x,experiment_df[(experiment_df$alpha==alpha)&(experiment_df$null_flag==null_flag),'sumsq_min_p'],col=plot_cols[2])
      lines(x,experiment_df[(experiment_df$alpha==alpha)&(experiment_df$null_flag==null_flag),'Frobenius'],col=plot_cols[3])
      lines(x,experiment_df[(experiment_df$alpha==alpha)&(experiment_df$null_flag==null_flag),'sum_1'],col=plot_cols[4])
      
      abline(h=alpha,lty=2,col=plot_cols[5])
      
      legend("topleft", legend=c("Min P Sum", "Min P SumSq", "Frobenius", "Operator","Alpha"), 
             col=plot_cols,lty=c(1,1,1,1,2),lwd=.5,cex=.5)
    }
  }
  
  dev.off()  
  
  # Subsample of 15 has a good mix of power not exactly equal to 1, this is experiment 33
  experiment_num = 33
  
  setwd(file.path(RESULTS_DIR,function_name))
  result_filename = paste(function_name,'-',sprintf("%03d",experiment_num),'.csv',sep='')
  result_df = read.csv(result_filename)[,-1]
  
  sum_cols =  grep('sum_',colnames(result_df),value=TRUE)
  sumsq_cols =  grep('sumsq_',colnames(result_df),value=TRUE)
  frob_cols =  grep('Frobenius',colnames(result_df),value=TRUE)
  
  sum_results =   colMeans(result_df[,sum_cols])
  sumsq_results = colMeans(result_df[,sumsq_cols])
  frob_results = colMeans(result_df[,frob_cols,drop=FALSE])
  
  # Combine the vectors into a matrix (each vector as a column)
  data_matrix <- rbind(sum_results,
                       sumsq_results)
  data_matrix = cbind(data_matrix,frob_results)
  data_matrix[2,'frob_results'] = NA
  colnames(data_matrix)[ncol(data_matrix)]='Frobenius'
  
  setwd(FIGURE_DIR)
  pdf("min_p_power_20240918_adaptive.pdf",width=7,height=3)
  
  par(mfrow=c(1,1),mar=c(7,4,2,1),cex=0.6)  # Set layout to 2x2
  
  # Create a barplot with side-by-side bars
  barplot(data_matrix, beside=TRUE, 
          col=c(rep(c('blue','red'),ncol(data_matrix)-1),'green'), 
          names.arg=colnames(data_matrix), 
          legend.text=c("Sum of Singular Values", "Sum of Squared Singular Values",'Frobenius'), 
          args.legend=list(x='topleft',cex=1,fill=c('blue','red','green')),
          las=2,
          ylab='Empirical Power',ylim=c(0,1),
          main="Side-by-Side Bar Chart")
  
  dev.off()
  
}

visualize_residual_different_20240924<-function(){
  # Import Data
  setwd(WORKING_DIR)  
  gene_expression_residuals = readRDS('residual_matrices.rds')
  n_LUAD = ncol(gene_expression_residuals[['TCGA-LUAD']])
  n_LUSC = ncol(gene_expression_residuals[['TCGA-LUSC']])
  
  subsample_size = 100
  
  set.seed(i)
  
  
  group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sample(1:n_LUAD,subsample_size)]
  group_2_residuals = gene_expression_residuals[['TCGA-LUSC']][,sample(1:n_LUSC,subsample_size)]
  
  combined_residuals = cbind(group_1_residuals,group_2_residuals)
  
  combined_cor_sv = svd(cor(t(combined_residuals)))$d
  diff_cor_sv     = svd(cor(t(group_1_residuals))-cor(t(group_2_residuals)))$d
  
  setwd(FIGURE_DIR)
  # Set up the PDF output
  pdf("visualize_residual_different_20240924.pdf", width = 7, height = 2.5)
  
  # Set up a 1x2 layout for side-by-side plots
  par(mfrow = c(1, 2),cex=0.5,mar = c(5, 4, 4, 4) + 0.1)
  
  plot(combined_cor_sv, type = "b", main = "Singular Values of Correlation \n (both groups combined) \n 100 from each group", 
       xlab = "", ylab = "Singular Values")
  par(new = TRUE)  # Overlay new plot
  plot(cumsum(combined_cor_sv)/sum(combined_cor_sv), type = "l", axes = FALSE, ylab = "", col = "red")
  axis(4, col = "red", col.axis = "red")  # Add second y-axis on the right
  mtext("Proportion of Sum", side = 4, line = 2, cex=0.5,col = "red")  # Label for second y-axis
  
  
  
  plot(diff_cor_sv, type = "b", main = "Singular Values of Difference \n of Correlation Matrices \n 100 from each group", 
       xlab = "", ylab = "Singular Values")
  par(new = TRUE)  # Overlay new plot
  plot(cumsum(diff_cor_sv)/sum(diff_cor_sv), type = "l", axes = FALSE, ylab = "", col = "red")
  axis(4, col = "red", col.axis = "red")  # Add second y-axis on the right
  mtext("Proportion of Sum", side = 4, line = 2, cex=0.5,col = "red")  # Label for second y-axis
  
  # Close the PDF device to save the file
  dev.off()
  
}

min_p_type_1_20240924<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  # Experiment Parameters
  function_name = 'min_p_type_1_20240924'
  K = 500
  B = 500
  max_k_pct = 0.8
  experiment_df = expand.grid(subsample_size = c(5,10,15,20,25,30,35,40,45,50),
                              alpha = c(0.05))
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  setwd(WORKING_DIR)  
  gene_expression_residuals = readRDS('residual_matrices.rds')
  n_LUAD = ncol(gene_expression_residuals[['TCGA-LUAD']])
  n_LUSC = ncol(gene_expression_residuals[['TCGA-LUSC']])
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  setwd(file.path(RESULTS_DIR,function_name))
  write.csv(experiment_df,file='experiment_df.csv') 
  
  # Determine which row of experiment_df to run
  if(job_num==999){
    # run all experiments
  }else{
    experiment_df=experiment_df[job_num,]
  }
  
  for(x in 1:nrow(experiment_df)){
    # Extract parameters from experiment_df
    subsample_size = experiment_df[x,'subsample_size']
    alpha = experiment_df[x,'alpha']
    experiment_number=experiment_df[x,'experiment_number']
    
    # Setup Parallelization
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('RSpectra'))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 # Sample only from LUAD subjects
                                 sampled_subjects = sample(1:n_LUAD,subsample_size*2)
                                 group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[1:subsample_size]]
                                 group_2_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 combined_residuals = cbind(group_1_residuals,group_2_residuals)
                                 
                                 max_k = max_k_calculation(combined_residuals,max_k_pct,cov_cor='cor') 
                                 
                                 reject_matrix = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                            max_k,test_stat_prefixes,B,alpha,
                                                                            cov_cor='cor')
                                 
                                 reject_matrix  
                               }
    
    parallel::stopCluster(cl)
    
    # Print out message to show experiment done and write results to csv
    print(paste(experiment_number,Sys.time()))
    setwd(file.path(RESULTS_DIR,function_name))
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    saveRDS(experiment_results,file=filename)
  }
}

#### TCGA - INCLUDING SUM OF SQUARES ####
simulated_type_1_20240925<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'simulated_type_1_20240925'
  
  K=10000     
  B=2000          
  alpha=.05
  max_k_pct=.8
  test_stat_prefixes = c('sum','sumsq','frob')
  
  experiment_df=expand.grid(snr=c(1),
                            cov_rank=c(2,5),
                            cov_structure=c('(LowRank)','(LowRankBlockSmall)','(LowRankBlockLarge)','(OffDiagonal)'),
                            n=c(50),
                            p=c(250),
                            stringsAsFactors=FALSE)
  
  # Only need OffDiagonal for one rank, make its snr = 0.5
  experiment_df=experiment_df[!((experiment_df$cov_structure=='(OffDiagonal)')&(experiment_df$cov_rank==5)),]
  experiment_df[experiment_df$cov_structure=='(OffDiagonal)','snr']=.5
  
  experiment_df=experiment_df[order(experiment_df$cov_structure,experiment_df$cov_rank),]
  experiment_df$initial_seed=as.numeric(rownames(experiment_df))*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)

  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }

  setwd(file.path(RESULTS_DIR,function_name))
  write.csv(experiment_df,file='experiment_df.csv') 
  
  # Determine which row of experiment_df to run
  if(job_num==999){
    # run all experiments
  }else{
    experiment_df=experiment_df[job_num,]
  }
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    p=as.numeric(experiment_df$p[x])
    n=as.numeric(experiment_df$n[x])
    snr=as.numeric(experiment_df$snr[x])
    cov_structure=as.character(experiment_df$cov_structure[x])
    cov_rank=experiment_df$cov_rank[x]
    initial_seed=experiment_df$initial_seed[x]
    experiment_number = experiment_df$experiment_number[x]

    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 cov_matrix=generate_covariance_matrix(cov_structure,snr,p,cov_rank)[[1]]
                                 x_matrix=t(mvrnorm(n=n,mu=rep(0,p),Sigm=cov_matrix))
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]

                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor='cov') 
                                 reject_matrix = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                            max_k,test_stat_prefixes,B,alpha,
                                                                            cov_cor = 'cov')
                                 
                                 reject_matrix
                               }
    
    parallel::stopCluster(cl)
    
    # Print out message to show experiment done and write results to csv
    print(paste(experiment_number,Sys.time()))
    setwd(file.path(RESULTS_DIR,function_name))
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    saveRDS(experiment_results,file=filename)
  }
}

simulated_type_1_20240925_table<-function(){
  function_name = 'simulated_type_1_20240925'
  
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  experiment_df$sum_min_reject == 999
  experiment_df$sumsq_min_reject == 999
  experiment_df$frob_min_reject == 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    experiment_df$sum_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[1, 'sum_min_p']))
    experiment_df$sumsq_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[1, 'sumsq_min_p']))
    experiment_df$frob_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[1, 'frob_min_p']))
  }
}

simulated_power_20240925<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'simulated_power_20240925'
  
  K=1000     
  B=1000          
  alpha=.05
  max_k_pct=.8
  k_compare = 25 # number of singular values to look at
  test_stat_prefixes = c('sum','sumsq','frob')
  
  n = 50
  p = 250
  
  experiment_df_1=expand.grid(n=n,p=p,snr=seq(0,.03,length.out=15),
                              cov_rank=2,cov_structure='(LowRank)',seed_init=1,stringsAsFactors = FALSE)
  experiment_df_2=expand.grid(n=n,p=p,snr=seq(0,.02,length.out=15),
                              cov_rank=5,cov_structure='(LowRank)',seed_init=2,stringsAsFactors = FALSE)
  experiment_df_3=expand.grid(n=n,p=p,snr=seq(0,25,length.out=15),
                              cov_rank=2,cov_structure='(LowRankBlockSmall)',seed_init=3,stringsAsFactors = FALSE)
  experiment_df_4=expand.grid(n=n,p=p,snr=seq(0,25,length.out=15),
                              cov_rank=5,cov_structure='(LowRankBlockSmall)',seed_init=4,stringsAsFactors = FALSE)
  experiment_df_5=expand.grid(n=n,p=p,snr=seq(0,.75,length.out=15),
                              cov_rank=2,cov_structure='(LowRankBlockLarge)',seed_init=5,stringsAsFactors = FALSE)
  experiment_df_6=expand.grid(n=n,p=p,snr=seq(0,.75,length.out=15),
                              cov_rank=5,cov_structure='(LowRankBlockLarge)',seed_init=6,stringsAsFactors = FALSE)
  experiment_df_7=expand.grid(n=n,p=p,snr=seq(0,.12,length.out=15),
                              cov_rank=2,cov_structure='(OffDiagonal)',seed_init=7,stringsAsFactors = FALSE)
  
  experiment_df=rbind(experiment_df_1,experiment_df_2,experiment_df_3,experiment_df_4,
                      experiment_df_5,experiment_df_6,experiment_df_7)
  
  experiment_df$initial_seed=(experiment_df$seed_init*100+experiment_df$cov_rank)*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  
  setwd(file.path(RESULTS_DIR,function_name))
  write.csv(experiment_df,file='experiment_df.csv') 
  
  # Determine which row of experiment_df to run
  if(job_num==999){
    # run all experiments
  }else{
    experiment_df=experiment_df[job_num,]
  }
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    p=as.numeric(experiment_df$p[x])
    n=as.numeric(experiment_df$n[x])
    snr=as.numeric(experiment_df$snr[x])
    cov_structure=as.character(experiment_df$cov_structure[x])
    cov_rank=experiment_df$cov_rank[x]
    initial_seed=experiment_df$initial_seed[x]
    experiment_number = experiment_df$experiment_number[x]
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 
                                 cov_mats=generate_covariance_matrix(cov_structure,snr,p,cov_rank)
                                 cov_matrix_1=cov_mats[[1]]
                                 cov_matrix_2=cov_mats[[2]]
                                 
                                 first_half_n=round(n/2)
                                 second_half_n=n-first_half_n
                                 
                                 X_1=t(mvrnorm(n=first_half_n,mu=rep(0,p),Sigm=cov_matrix_1,tol=10))
                                 X_2=t(mvrnorm(n=second_half_n,mu=rep(0,p),Sigm=cov_matrix_2,tol=10))
                                 x_matrix=cbind(X_1,X_2)
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor='cov') 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(initial_seed+i)
                                 reject_matrix_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                            max_k,test_stat_prefixes,B,alpha,cov_cor='cov')
                                 
                                 # Run RACC using k_compare singular values
                                 set.seed(initial_seed+i)
                                 reject_matrix_k_compare = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                      k_compare,test_stat_prefixes,B,alpha,
                                                                                      cov_cor = 'cov')
                                 
                                 
                                 list(reject_matrix_RACC,reject_matrix_k_compare)
                               }
    
    parallel::stopCluster(cl)
    
    # Print out message to show experiment done and write results to csv
    print(paste(experiment_number,Sys.time()))
    setwd(file.path(RESULTS_DIR,function_name))
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    saveRDS(experiment_results,file=filename)
  }
}

simulated_power_20240925_table<-function(){
  function_name = 'simulated_power_20240925'
  
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  experiment_df$sum_min_reject == 999
  experiment_df$sumsq_min_reject == 999
  experiment_df$frob_min_reject == 999
  experiment_df$sum_1_reject == 999
  experiment_df$sum_10_reject == 999
  experiment_df$sum_25_reject == 999
  experiment_df$sumsq_1_reject == 999
  experiment_df$sumsq_10_reject == 999
  experiment_df$sumsq_25_reject == 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    experiment_df$sum_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[1]][1, 'sum_min_p']))
    experiment_df$sumsq_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[1]][1, 'sumsq_min_p']))
    experiment_df$frob_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[1]][1, 'frob_min_p']))
    experiment_df$sum_1_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sum_1']))
    experiment_df$sum_10_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sum_10']))
    experiment_df$sum_25_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sum_25']))
    experiment_df$sumsq_1_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sumsq_1']))
    experiment_df$sumsq_10_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sumsq_10']))
    experiment_df$sumsq_25_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sumsq_25']))
  }
}

# Type I Error Control
simulated_type_1_20240926<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'simulated_type_1_20240926'
  
  K=10000     
  B=2000          
  alpha=.05
  max_k_pct=.8
  test_stat_prefixes = c('sum','sumsq','frob')
  
  experiment_df=expand.grid(snr=c(1),
                            cov_rank=c(2,5),
                            cov_structure=c('(LowRank)','(LowRankBlockSmall)','(LowRankBlockLarge)','(OffDiagonal)'),
                            n=c(50),
                            p=c(250),
                            cov_cor=c('cov','cor'),
                            stringsAsFactors=FALSE)
  
  # Only need OffDiagonal for one rank, make its snr = 0.5
  experiment_df=experiment_df[!((experiment_df$cov_structure=='(OffDiagonal)')&(experiment_df$cov_rank==5)),]
  experiment_df[experiment_df$cov_structure=='(OffDiagonal)','snr']=.5
  
  experiment_df=experiment_df[order(experiment_df$cov_structure,experiment_df$cov_rank),]
  experiment_df$initial_seed=as.numeric(rownames(experiment_df))*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  
  setwd(file.path(RESULTS_DIR,function_name))
  write.csv(experiment_df,file='experiment_df.csv') 
  
  # Determine which row of experiment_df to run
  if(job_num==999){
    # run all experiments
  }else{
    experiment_df=experiment_df[job_num,]
  }
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 cov_matrix=generate_covariance_matrix(cov_structure,snr,p,cov_rank)[[1]]
                                 x_matrix=t(MASS::mvrnorm(n=n,mu=rep(0,p),Sigm=cov_matrix))
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 reject_matrix = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                            max_k,test_stat_prefixes,B,alpha,
                                                                            cov_cor = cov_cor)
                                 
                                 reject_matrix
                               }
    
    parallel::stopCluster(cl)
    
    # Print out message to show experiment done and write results to csv
    print(paste(experiment_number,Sys.time()))
    setwd(file.path(RESULTS_DIR,function_name))
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    saveRDS(experiment_results,file=filename)
  }
}

simulated_power_20240926<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'simulated_power_20240926'
  
  K=1000     
  B=1000          
  alpha=.05
  max_k_pct=.8
  k_compare = 50 # number of singular values to look at
  test_stat_prefixes = c('sum','sumsq','frob')
  
  n = 50
  p = 250
  
  experiment_df_1=expand.grid(n=n,p=p,snr=seq(0,.03,length.out=15),
                              cov_rank=2,cov_structure='(LowRank)',seed_init=1,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_2=expand.grid(n=n,p=p,snr=seq(0,.02,length.out=15),
                              cov_rank=5,cov_structure='(LowRank)',seed_init=2,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_3=expand.grid(n=n,p=p,snr=seq(0,25,length.out=15),
                              cov_rank=2,cov_structure='(LowRankBlockSmall)',seed_init=3,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_4=expand.grid(n=n,p=p,snr=seq(0,25,length.out=15),
                              cov_rank=5,cov_structure='(LowRankBlockSmall)',seed_init=4,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_5=expand.grid(n=n,p=p,snr=seq(0,.75,length.out=15),
                              cov_rank=2,cov_structure='(LowRankBlockLarge)',seed_init=5,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_6=expand.grid(n=n,p=p,snr=seq(0,.75,length.out=15),
                              cov_rank=5,cov_structure='(LowRankBlockLarge)',seed_init=6,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_7=expand.grid(n=n,p=p,snr=seq(0,.12,length.out=15),
                              cov_rank=2,cov_structure='(OffDiagonal)',seed_init=7,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  
  experiment_df=rbind(experiment_df_1,experiment_df_2,experiment_df_3,experiment_df_4,
                      experiment_df_5,experiment_df_6,experiment_df_7)
  
  experiment_df$initial_seed=(experiment_df$seed_init*100+experiment_df$cov_rank)*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  
  setwd(file.path(RESULTS_DIR,function_name))
  write.csv(experiment_df,file='experiment_df.csv') 
  
  # Determine which row of experiment_df to run
  if(job_num==999){
    # run all experiments
  }else{
    experiment_df=experiment_df[job_num,]
  }
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 
                                 cov_mats=generate_covariance_matrix(cov_structure,snr,p,cov_rank)
                                 cov_matrix_1=cov_mats[[1]]
                                 cov_matrix_2=cov_mats[[2]]
                                 
                                 first_half_n=round(n/2)
                                 second_half_n=n-first_half_n
                                 
                                 X_1=t(MASS::mvrnorm(n=first_half_n,mu=rep(0,p),Sigm=cov_matrix_1,tol=10))
                                 X_2=t(MASS::mvrnorm(n=second_half_n,mu=rep(0,p),Sigm=cov_matrix_2,tol=10))
                                 x_matrix=cbind(X_1,X_2)
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(initial_seed+i)
                                 reject_matrix_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                 max_k,test_stat_prefixes,B,alpha,
                                                                                 cov_cor=cov_cor)
                                 
                                 # Run RACC using k_compare singular values
                                 set.seed(initial_seed+i)
                                 reject_matrix_k_compare = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                      k_compare,test_stat_prefixes,B,alpha,
                                                                                      cov_cor = cov_cor)
                                 
                                 
                                 list(reject_matrix_RACC,reject_matrix_k_compare)
                               }
    
    parallel::stopCluster(cl)
    
    # Print out message to show experiment done and write results to csv
    print(paste(experiment_number,Sys.time()))
    setwd(file.path(RESULTS_DIR,function_name))
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    saveRDS(experiment_results,file=filename)
  }
}

tcga_sims_20240926<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'tcga_sims_20240926'
  
  K=1000    # 1000     
  B=1000    # 1000         
  alpha=.05
  max_k_pct=.8
  k_compare = 50 # number of singular values to look at in comparison
  test_stat_prefixes = c('sum','sumsq','frob')
  
  experiment_df = expand.grid(subsample_size = c(5,10,15,20,25,30,35,40,45,50),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov','cor'), stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  setwd(WORKING_DIR)  
  gene_expression_residuals = readRDS('residual_matrices.rds')
  n_LUAD = ncol(gene_expression_residuals[['TCGA-LUAD']])
  n_LUSC = ncol(gene_expression_residuals[['TCGA-LUSC']])
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  
  setwd(file.path(RESULTS_DIR,function_name))
  write.csv(experiment_df,file='experiment_df.csv') 
  
  # Determine which row of experiment_df to run
  if(job_num==999){
    # run all experiments
  }else{
    experiment_df=experiment_df[job_num,]
  }
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select LUAD, and LUSC subjects
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sample(1:n_LUAD,subsample_size)]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUSC']][,sample(1:n_LUSC,subsample_size)]
                                 }else{
                                   # Sample only from LUAD subjects
                                   sampled_subjects = sample(1:n_LUAD,subsample_size*2)
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[1:subsample_size]]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(i)
                                 reject_matrix_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                 max_k,test_stat_prefixes,B,alpha,
                                                                                 cov_cor=cov_cor)
                                 
                                 # Run RACC using k_compare singular values
                                 set.seed(i)
                                 reject_matrix_k_compare = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                      min(k_compare,2*subsample_size),
                                                                                      test_stat_prefixes,B,alpha,
                                                                                      cov_cor = cov_cor)
                                 
                                 print(i)
                                 
                                 list(reject_matrix_RACC,reject_matrix_k_compare)
                               }
    
    parallel::stopCluster(cl)
    
    # Print out message to show experiment done and write results to csv
    print(paste(experiment_number,Sys.time()))
    setwd(file.path(RESULTS_DIR,function_name))
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    saveRDS(experiment_results,file=filename)
  }
}

tcga_sims_20240926_charts<-function(){
  library(RColorBrewer)
  
  function_name = 'tcga_sims_20240926'
  
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  
  # Get column names where we predefine k and add them as columns
  filename=paste(function_name,'-',sprintf("%03d",nrow(experiment_df)),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  result_colnames = colnames(experiment_result[[experiment_number]][[2]])
  experiment_df[,result_colnames] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    result_colnames = colnames(experiment_result[[experiment_number]][[2]])
    K = length(experiment_result)
    
    experiment_df[experiment_number,result_colnames] = Reduce('+',lapply(experiment_result, function(x) x[[2]]))/K
  }
  
  palette <- RColorBrewer::brewer.pal(length(columns_to_plot), "Set2")
  
  # Adapativity Charts 1
  # ave as 1200x600
  
  # Chart of experiment 12 (~50%), subsample size = 10 (up to )
  experiment_number = 12
  data_matrix = matrix(data=NA,nrow=4,ncol=21)
  data_matrix[2,c(1:20)] = unlist(experiment_df[experiment_number,paste0('sum_',1:20)])
  data_matrix[3,1:20] = unlist(experiment_df[experiment_number,paste0('sumsq_',1:20)])
  data_matrix[,21] = unlist(experiment_df[experiment_number,c('sum_min_p','sumsq_min_p','frob_min_p','all_min_p')])
  
  palette <- RColorBrewer::brewer.pal(4, "Set2")
  
  # some bars hidden so need to rearrange colors
  colors_ordered = c(rep(palette,20),
                   palette[2],palette[3],palette[1],palette[4])
  
  par(mfrow=c(1,1),mar=c(5,5,4,1))  # Set layout to 2x2
  barplot(data_matrix, beside = TRUE, col = colors_ordered, 
          names.arg = c(seq(1,20), "min P"),yaxt='n',cex.names=1.5,las=2,ylim=c(0,0.75))
  axis(2, at = c(0, 0.25, 0.50,0.75, 1), labels = c("0.00", "0.25","0.50", "0.75", "1.00"),las=1,cex.axis=1.5)
  
  
  
  
}

simulated_type_1_20240926_table<-function(){
  function_name = 'simulated_type_1_20240926'
  
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  experiment_df$sum_min_reject == 999
  experiment_df$sumsq_min_reject == 999
  experiment_df$frob_min_reject == 999
  experiment_df$all_min_reject == 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    experiment_df$sum_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[1, 'sum_min_p']))
    experiment_df$sumsq_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[1, 'sumsq_min_p']))
    experiment_df$frob_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[1, 'frob_min_p']))
    experiment_df$all_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[1, 'all_min_p']))
  }
  
  experiment_df_wide <- reshape(experiment_df[, c("cov_cor", "cov_structure","cov_rank", "all_min_reject")], 
                     idvar = c("cov_structure","cov_rank"), 
                     timevar = "cov_cor", 
                     direction = "wide")
  
  colnames(experiment_df_wide) = c('Covariance Structure','Covariance Rank','Type I Covariance','Type I Correlation')
  
  xt = xtable::xtable(experiment_df_wide,
              caption='Type I error across different simulated data settings. Calculated over 10,000 experiments with 2000 permutations per experiment. Results reported when testing both equality of covariance, and equality of correlation matrices.',
              label='tab:type1error',
              digits = c(0,0,0,3,3),
              align = "|c|c|c|c|c|")
  
  print(xt,
        table.placement = 'H',
        include.rownames = FALSE, # Exclude row names
        caption.placement = "bottom" # Caption on top
  )
  
}

simulated_power_20240926_charts<-function(){
  library(RColorBrewer)
  
  function_name = 'simulated_power_20240926'
  
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')

  # Get column names where we predefine k and add them as columns
  filename=paste(function_name,'-',sprintf("%03d",1),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  result_colnames = colnames(experiment_result[[1]][[2]]) 
  experiment_df[,result_colnames] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    K = length(experiment_result)
    
    experiment_df[experiment_number,result_colnames] = Reduce('+',lapply(experiment_result, function(x) x[[2]]))/K
  }
  
  
  # ADAPTIVITY CHARTS 2
  columns_to_plot = c(paste0('sum_',1:25),'sum_min_p')
  matrix_to_plot = matrix(data=NA,nrow=2,ncol = length(columns_to_plot))
  colnames(matrix_to_plot) = columns_to_plot
  rownames(matrix_to_plot) = c(2,5)
  
  for(cov_rank in c(2,5)){
    df_slice = experiment_df[((experiment_df$cov_rank == cov_rank)
                              &(experiment_df$cov_structure == '(LowRank)')
                              &(experiment_df$cov_cor == 'cov')),]
    
    pt_50_index = closest_index <- which.min(abs(df_slice$sum_min_p - 0.50))
    
    matrix_to_plot[rownames(matrix_to_plot)==cov_rank,] = unlist(df_slice[pt_50_index,columns_to_plot])
    
  }
  
  # Save as 1200x600 pixels
  # Create a barplot with side-by-side bars
  par(mfrow=c(1,1),mar=c(5,5,4,1))  # Set layout to 2x2
  palette <- RColorBrewer::brewer.pal(nrow(matrix_to_plot), "Set2")
  barplot(matrix_to_plot, beside=TRUE,
          names.arg = c(1:(length(columns_to_plot)-1),'Sum \n min P'),
          col = palette[1:nrow(matrix_to_plot)],yaxt='n',ylim=c(0,0.75),cex.names=1.5,las=2)
  axis(2, at = c(0, 0.25, 0.50,0.75, 1), labels = c("0.00", "0.25","0.50", "0.75", "1.00"),las=1,cex.axis=1.5)
  
  # Table Ky-Fan vs Sum fo Squares
  df_slice = experiment_df[(experiment_df$cov_cor=='cov')&
                           (experiment_df$cov_structure=='(LowRank)')&
                           (experiment_df$cov_rank==5),]
  df_slice$snr = as.numeric(df_slice$snr)
  df_slice = df_slice[,c('snr',
                         'sum_1','sumsq_1',
                         'sum_4','sumsq_4',
                         'sum_10','sumsq_10',
                         'sum_25','sumsq_25',
                         'sum_min_p','sumsq_min_p','frob_min_p','all_min_p')]
  df_slice[,c('sum_1','sumsq_1',
              'sum_4','sumsq_4',
              'sum_10','sumsq_10',
              'sum_25','sumsq_25',
              'sum_min_p','sumsq_min_p','frob_min_p','all_min_p')] = (
                format(round(df_slice[,c('sum_1','sumsq_1',
                            'sum_4','sumsq_4',
                            'sum_10','sumsq_10',
                            'sum_25','sumsq_25',
                            'sum_min_p','sumsq_min_p','frob_min_p','all_min_p')],3),nsmall=3)
              )
  df_slice[,'snr'] = format(round(df_slice[,'snr'],4),nsmall=4)
  
  df_slice = rbind(df_slice,c('Norm Type',
                             'Sum','SumSq',
                             'Sum','SumSq',
                             'Sum','SumSq',
                             'Sum','SumSq',
                             'Sum min P','SumSq min P','Frobenius min P','All min P'))
  df_slice = rbind(df_slice,c('k','1','1','4','4','10','10','25','25','','','',''))
  colnames(df_slice)[-1] <- ""
  colnames(df_slice)[1] = "tau2"
  
  xt = xtable::xtable(df_slice,
                      caption='(LowRank) where rank = 5 comparison of power across different norms. Here we see a slight advantage to SumSq, particularly for larger k. This advantage is also seen in Sum min P relative to SumSq min P.',
                      label='tab:powernormcompare',
                      align = "c|c|cccccccccccc|")
  
  print(xt,
        table.placement = 'H',
        include.rownames = FALSE, # Exclude row names
        caption.placement = "bottom", # Caption on top
        scalebox = 0.7
  )
  
}

power_sumsq_better_20240930<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'power_sumsq_better_20240930'
  
  K=100     
  B=100          
  alpha=.05
  max_k_pct=.8
  k_compare = 50 # number of singular values to look at
  test_stat_prefixes = c('sum','sumsq','frob')
  
  p = 250
  
  experiment_df=expand.grid(n=c(50),p=p,snr=seq(0,.02,length.out=10),
                              cov_rank=c(2,5,10),cov_structure='(LowRank)',seed_init=1,cov_cor=c('cov'),
                              stringsAsFactors = FALSE)
  
  experiment_df$initial_seed=(experiment_df$seed_init*100+experiment_df$cov_rank)*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  
  setwd(file.path(RESULTS_DIR,function_name))
  write.csv(experiment_df,file='experiment_df.csv') 
  
  # Determine which row of experiment_df to run
  if(job_num==999){
    # run all experiments
  }else{
    experiment_df=experiment_df[job_num,]
  }
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 
                                 cov_mats=generate_covariance_matrix(cov_structure,snr,p,cov_rank)
                                 cov_matrix_1=cov_mats[[1]]
                                 cov_matrix_2=cov_mats[[2]]
                                 
                                 first_half_n=round(n/2)
                                 second_half_n=n-first_half_n
                                 
                                 X_1=t(MASS::mvrnorm(n=first_half_n,mu=rep(0,p),Sigm=cov_matrix_1,tol=10))
                                 X_2=t(MASS::mvrnorm(n=second_half_n,mu=rep(0,p),Sigm=cov_matrix_2,tol=10))
                                 x_matrix=cbind(X_1,X_2)
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(initial_seed+i)
                                 reject_matrix_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                 max_k,test_stat_prefixes,B,alpha,
                                                                                 cov_cor=cov_cor)
                                 
                                 # Run RACC using k_compare singular values
                                 set.seed(initial_seed+i)
                                 reject_matrix_k_compare = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                      k_compare,test_stat_prefixes,B,alpha,
                                                                                      cov_cor = cov_cor)
                                 
                                 
                                 list(reject_matrix_RACC,reject_matrix_k_compare)
                               }
    
    parallel::stopCluster(cl)
    
    # Print out message to show experiment done and write results to csv
    print(paste(experiment_number,Sys.time()))
    setwd(file.path(RESULTS_DIR,function_name))
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    saveRDS(experiment_results,file=filename)
  }
}

power_sumsq_better_20240930_charts<-function(){
  library(RColorBrewer)
  
  function_name = 'power_sumsq_better_20240930'
  
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  experiment_df$sum_min_reject = 999
  experiment_df$sumsq_min_reject = 999
  experiment_df$frob_min_reject = 999
  experiment_df$sum_1_reject = 999
  experiment_df$sum_4_reject = 999
  experiment_df$sum_10_reject = 999
  experiment_df$sum_25_reject = 999
  experiment_df$sum_50_reject = 999
  experiment_df$sumsq_1_reject = 999
  experiment_df$sumsq_4_reject = 999
  experiment_df$sumsq_10_reject = 999
  experiment_df$sumsq_25_reject = 999
  experiment_df$sumsq_50_reject = 999
  experiment_df$all_min_reject = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    experiment_df$sum_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sum_min_p']))
    experiment_df$sumsq_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sumsq_min_p']))
    experiment_df$frob_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'frob_min_p']))
    experiment_df$all_min_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'all_min_p']))
    experiment_df$sum_1_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sum_1']))
    experiment_df$sum_4_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sum_4']))
    experiment_df$sum_10_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sum_10']))
    experiment_df$sum_25_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sum_25']))
    experiment_df$sum_50_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sum_50']))
    experiment_df$sumsq_1_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sumsq_1']))
    experiment_df$sumsq_4_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sumsq_4']))
    experiment_df$sumsq_10_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sumsq_10']))
    experiment_df$sumsq_25_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sumsq_25']))
    experiment_df$sumsq_50_reject[experiment_number] = mean(sapply(experiment_result, function(x) x[[2]][1, 'sumsq_50']))
  }
  
  # ADAPTIVITY CHARTS 
  
  # Save as 1200x600 pixels
  # Chart of (OffDiagonal) rank = 2 vs. (LowRankBlockLarge) rank = 2
  columns_to_plot = c('sum_1_reject','sum_4_reject','sum_10_reject','sum_25_reject','sum_min_reject')
  
  for(cov_structure in c('(OffDiagonal)','(LowRankBlockLarge)')){
    df_slice = experiment_df[((experiment_df$cov_rank == 2)
                              &(experiment_df$cov_structure == cov_structure)
                              &(experiment_df$cov_cor == 'cov')),]
    
    # Create a barplot with side-by-side bars
    par(mfrow=c(1,1),mar=c(5,5,4,1))  # Set layout to 2x2
    barplot(as.matrix(t(df_slice[,columns_to_plot])), beside=TRUE, 
            names.arg = sprintf("%.3f", round(df_slice[,'snr'],3)),
            col = c(palette <- RColorBrewer::brewer.pal(length(columns_to_plot), "Set2")),yaxt='n',cex.names=1.5,las=2)
    axis(2, at = c(0, 0.25, 0.50,0.75, 1), labels = c("0.00", "0.25","0.50", "0.75", "1.00"),las=1,cex.axis=1.5)
  }
  
  # Save as 1200x600 pixels
  # Chart of (LowRank) rank = 5 vs. (LowRankBlockSmall) rank = 5
  columns_to_plot = c('sum_min_reject','sumsq_min_reject','frob_min_reject','all_min_reject')
  
  for(cov_structure in c('(LowRank)','(LowRankBlockSmall)')){
    df_slice = experiment_df[((experiment_df$cov_rank == 5)
                              &(experiment_df$cov_structure == cov_structure)
                              &(experiment_df$cov_cor == 'cov')),]
    
    if(cov_structure == '(LowRank)'){
      names.arg = sprintf("%.3f", round(df_slice[,'snr'],3))
    }else if(cov_structure == '(LowRankBlockSmall)'){
      names.arg = round(df_slice[,'snr'])
    }
    
    # Create a barplot with side-by-side bars
    par(mfrow=c(1,1),mar=c(5,5,4,1))  # Set layout to 2x2
    barplot(as.matrix(t(df_slice[,columns_to_plot])), beside=TRUE, 
            names.arg = names.arg,
            col = c(palette <- RColorBrewer::brewer.pal(length(columns_to_plot), "Set2")),yaxt='n',cex.names=1.5,las=2)
    axis(2, at = c(0, 0.25, 0.50,0.75, 1), labels = c("0.00", "0.25","0.50", "0.75", "1.00"),las=1,cex.axis=1.5)
  }
  
  
}

tcga_sims_compare_20240930<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'tcga_sims_compare_20240930'
  
  K=1000    # 1000     
  B=1000    # 1000         
  alpha=.05
  max_k_pct=.8
  k_compare = 50 # number of singular values to look at in comparison
  test_stat_prefixes = c('sum','sumsq','frob')
  
  experiment_df = expand.grid(subsample_size = c(5,10,15,20,25,30,35,40,45,50),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov'), stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  setwd(WORKING_DIR)  
  gene_expression_residuals = readRDS('residual_matrices.rds')
  n_LUAD = ncol(gene_expression_residuals[['TCGA-LUAD']])
  n_LUSC = ncol(gene_expression_residuals[['TCGA-LUSC']])
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  
  setwd(file.path(RESULTS_DIR,function_name))
  write.csv(experiment_df,file='experiment_df.csv') 
  
  # Determine which row of experiment_df to run
  if(job_num==999){
    # run all experiments
  }else{
    experiment_df=experiment_df[job_num,]
  }
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select LUAD, and LUSC subjects
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sample(1:n_LUAD,subsample_size)]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUSC']][,sample(1:n_LUSC,subsample_size)]
                                 }else{
                                   # Sample only from LUAD subjects
                                   sampled_subjects = sample(1:n_LUAD,subsample_size*2)
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[1:subsample_size]]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(i)
                                 reject_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                 max_k,test_stat_prefixes,B,alpha,
                                                                                 cov_cor=cov_cor)[,'all_min_p']
                                 reject_SY = UTDtst::SY2010(t(group_1_residuals),t(group_2_residuals))
                                 reject_LC = UTDtst::LC2012(t(group_1_residuals),t(group_2_residuals))
                                 reject_CLX = UTDtst::CLX2013(t(group_1_residuals),t(group_2_residuals))
                                 reject_HC = UTDtst::HC2018(t(group_1_residuals),t(group_2_residuals),alpha = alpha)
                                 
                                 # XC seems to struggle with small n
                                 reject_XC <- tryCatch({
                                        UTDtst::TwoSampleTest(t(group_1_residuals),t(group_2_residuals),
                                                               k=100,alpha=alpha)
                                   }, error = function(e) {
                                        list(decision=999)  # Return 999 if there is an error
                                   })
                                  
                                 print(i)
                                 
                                 return_vec =c(reject_RACC,
                                               reject_SY$pvalue<alpha,
                                               reject_LC$pvalue<alpha,
                                               reject_CLX$pvalue<alpha,
                                               reject_HC$reject>0,
                                               reject_XC$decision)*1
                                 names(return_vec) = c('RACC','SY','LC','CLX','HC','XC')
                                 
                                 return_vec
                               }
    
    parallel::stopCluster(cl)
    
    # Print out message to show experiment done and write results to csv
    print(paste(experiment_number,Sys.time()))
    setwd(file.path(RESULTS_DIR,function_name))
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    saveRDS(experiment_results,file=filename)
  }
}

tcga_sims_compare_20240930_charts<-function(){
  library(RColorBrewer)
  
  function_name = 'tcga_sims_compare_20240930'
  
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  experiment_df[,c('RACC','SY','LC','CLX','HC','XC')] = 999
  
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    experiment_result = do.call(rbind,experiment_result)
    K = nrow(experiment_result)
    
    experiment_df[experiment_number,c('RACC','SY','LC','CLX','HC','XC')] = colMeans(experiment_result[,c('RACC','SY','LC','CLX','HC','XC')])
    
    if (any(experiment_result[,'XC'] != 999)) {
      XC_avg <- mean(experiment_result[,'XC'][experiment_result[,'XC'] != 999])
    } else {
      XC_avg <- NA  # Handle the case where all values are 999
    }
    
    experiment_df[experiment_number,'XC'] = XC_avg
    
  }
  
  # Type I Table
  type_1_table = experiment_df[experiment_df$null_flag == 'null',
                               c('subsample_size','RACC','SY','LC','CLX','HC','XC')]
  type_1_table[,c('RACC','SY','LC','CLX','HC','XC')] = data.frame(
    apply(type_1_table[,c('RACC','SY','LC','CLX','HC','XC')], 2, function(x) sprintf("%.3f", x)))
  
  
  type_1_table[type_1_table=='NA'] = '-'
  colnames(type_1_table)[1]='Subsample Size'
  colnames(type_1_table)[colnames(type_1_table)=='RACC']='ACT'
  
  xt = xtable::xtable(type_1_table,
                      caption='Type I error across 1000 different subsamples for ACT and competing methods on the TCGA dataset. Type I error calculatd by testing for equality of covariance matrix only using subjects from the LUAD group.',
                      label='tab:tcga_type1error',
                      align = "|c|c|cccccc|")
  
  print(xt,table.placement = "H",include.rownames = FALSE)
  
  # POWER CHARTS
  df_slice = experiment_df[experiment_df$null_flag == 'not_null',]
  color_palette = RColorBrewer::brewer.pal(6, "Set2")
    
  # Create a barplot with side-by-side bars set to 1200 x 600
  par(mfrow=c(1,1),mar=c(5,5,4,1))  # Set layout to 2x2
  barplot(as.matrix(t(df_slice[,columns_to_plot])), beside=TRUE, 
          names.arg = df_slice[,'subsample_size'],
          col = color_palette,yaxt='n',cex.names=1.5,las=2)
  axis(2, at = c(0, 0.25, 0.50,0.75, 1), labels = c("0.00", "0.25","0.50", "0.75", "1.00"),las=1,cex.axis=1.5)

  
}

#### SIMS ####
# Type I Error Control
simulated_type_1_20241002<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'simulated_type_1_20241002'
  
  K=10000     
  B=2000          
  alpha=.05
  max_k_pct=.95
  test_stat_prefixes = c('sum','frob')
  
  experiment_df=expand.grid(snr=c(1),
                            cov_rank=c(2,5),
                            cov_structure=c('(LowRank)','(LowRankBlockSmall)','(LowRankBlockLarge)','(OffDiagonal)'),
                            n=c(50),
                            p=c(250),
                            cov_cor=c('cov','cor'),
                            stringsAsFactors=FALSE)
  
  # Only need OffDiagonal for one rank, make its snr = 0.5
  experiment_df=experiment_df[!((experiment_df$cov_structure=='(OffDiagonal)')&(experiment_df$cov_rank==5)),]
  experiment_df[experiment_df$cov_structure=='(OffDiagonal)','snr']=.5
  
  experiment_df=experiment_df[order(experiment_df$cov_structure,experiment_df$cov_rank),]
  experiment_df$initial_seed=as.numeric(rownames(experiment_df))*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 cov_matrix=generate_covariance_matrix(cov_structure,snr,p,cov_rank)[[1]]
                                 x_matrix=t(MASS::mvrnorm(n=n,mu=rep(0,p),Sigm=cov_matrix))
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 reject_matrix = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                            max_k,test_stat_prefixes,B,alpha,
                                                                            cov_cor = cov_cor)
                                 
                                 reject_matrix
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

simulated_power_20241002<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'simulated_power_20241002'
  
  K=1000     
  B=1000          
  alpha=.05
  max_k_pct=.95
  k_compare = 50 # number of singular values to look at
  test_stat_prefixes = c('sum','frob')
  
  experiment_df_1=expand.grid(n=50,p=250,snr=seq(0,.03,length.out=15),
                              cov_rank=2,cov_structure='(LowRank)',seed_init=1,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_2=expand.grid(n=50,p=250,snr=seq(0,.02,length.out=15),
                              cov_rank=5,cov_structure='(LowRank)',seed_init=2,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_3=expand.grid(n=50,p=250,snr=seq(0,25,length.out=15),
                              cov_rank=2,cov_structure='(LowRankBlockSmall)',seed_init=3,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_4=expand.grid(n=50,p=250,snr=seq(0,25,length.out=15),
                              cov_rank=5,cov_structure='(LowRankBlockSmall)',seed_init=4,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_5=expand.grid(n=50,p=250,snr=seq(0,.75,length.out=15),
                              cov_rank=2,cov_structure='(LowRankBlockLarge)',seed_init=5,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_6=expand.grid(n=50,p=250,snr=seq(0,.75,length.out=15),
                              cov_rank=5,cov_structure='(LowRankBlockLarge)',seed_init=6,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_7=expand.grid(n=50,p=250,snr=seq(0,.12,length.out=15),
                              cov_rank=2,cov_structure='(OffDiagonal)',seed_init=7,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  
  experiment_df=rbind(experiment_df_1,experiment_df_2,experiment_df_3,experiment_df_4,
                      experiment_df_5,experiment_df_6,experiment_df_7)
  
  experiment_df$initial_seed=(experiment_df$seed_init*100+experiment_df$cov_rank)*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 
                                 cov_mats=generate_covariance_matrix(cov_structure,snr,p,cov_rank)
                                 cov_matrix_1=cov_mats[[1]]
                                 cov_matrix_2=cov_mats[[2]]
                                 
                                 first_half_n=round(n/2)
                                 second_half_n=n-first_half_n
                                 
                                 X_1=t(MASS::mvrnorm(n=first_half_n,mu=rep(0,p),Sigm=cov_matrix_1,tol=10))
                                 X_2=t(MASS::mvrnorm(n=second_half_n,mu=rep(0,p),Sigm=cov_matrix_2,tol=10))
                                 x_matrix=cbind(X_1,X_2)
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(initial_seed+i)
                                 reject_matrix_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                 max_k,test_stat_prefixes,B,alpha,
                                                                                 cov_cor=cov_cor)
                                 
                                 # Run RACC using k_compare singular values
                                 set.seed(initial_seed+i)
                                 reject_matrix_k_compare = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                      k_compare,test_stat_prefixes,B,alpha,
                                                                                      cov_cor = cov_cor)
                                 
                                 
                                 list(reject_matrix_RACC,reject_matrix_k_compare)
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

#### SIMS WRITEUP ####

#### TCGA ####


tcga_sims_20241002<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'tcga_sims_20241002'
  
  K=1000    # 1000     
  B=1000    # 1000         
  alpha=.05
  max_k_pct=.95
  k_compare = 50 # number of singular values to look at in comparison
  test_stat_prefixes = c('sum','frob')
  
  experiment_df = expand.grid(subsample_size = c(15,20,25,30,35,40,45,50),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov','cor'), stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  setwd(WORKING_DIR)  
  gene_expression_residuals = readRDS('residual_matrices.rds')
  n_LUAD = ncol(gene_expression_residuals[['TCGA-LUAD']])
  n_LUSC = ncol(gene_expression_residuals[['TCGA-LUSC']])
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select LUAD, and LUSC subjects
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sample(1:n_LUAD,subsample_size)]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUSC']][,sample(1:n_LUSC,subsample_size)]
                                 }else{
                                   # Sample only from LUAD subjects
                                   sampled_subjects = sample(1:n_LUAD,subsample_size*2)
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[1:subsample_size]]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(i)
                                 reject_matrix_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                 max_k,test_stat_prefixes,B,alpha,
                                                                                 cov_cor=cov_cor)
                                 
                                 # Run RACC using k_compare singular values
                                 set.seed(i)
                                 reject_matrix_k_compare = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                      min(k_compare,2*subsample_size),
                                                                                      test_stat_prefixes,B,alpha,
                                                                                      cov_cor = cov_cor)
                                 
                                 print(i)
                                 
                                 list(reject_matrix_RACC,reject_matrix_k_compare)
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

tcga_sims_compare_20241002<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'tcga_sims_compare_20241002'
  
  K=1000    # 1000     
  B=1000    # 1000         
  alpha=.05
  max_k_pct = 0.95 # pct of singular values to consider
  test_stat_prefixes = c('sum','frob')
  
  experiment_df = expand.grid(subsample_size = c(15,20,25,30,35,40,45,50),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov','cor'), stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  setwd(WORKING_DIR)  
  gene_expression_residuals = readRDS('residual_matrices.rds')
  n_LUAD = ncol(gene_expression_residuals[['TCGA-LUAD']])
  n_LUSC = ncol(gene_expression_residuals[['TCGA-LUSC']])
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df),
                               .errorhandling = 'pass')%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select LUAD, and LUSC subjects
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sample(1:n_LUAD,subsample_size)]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUSC']][,sample(1:n_LUSC,subsample_size)]
                                 }else{
                                   # Sample only from LUAD subjects
                                   sampled_subjects = sample(1:n_LUAD,subsample_size*2)
                                   group_1_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[1:subsample_size]]
                                   group_2_residuals = gene_expression_residuals[['TCGA-LUAD']][,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 # If cov_cor = 'cor' then we standardize each dimension (which will then produce a
                                 # correlation matrix)
                                 if(cov_cor == 'cor'){
                                    group_1_residuals = sweep(group_1_residuals,1,apply(group_1_residuals,1,sd),'/')
                                    group_2_residuals = sweep(group_2_residuals,1,apply(group_2_residuals,1,sd),'/')
                                 }
                                 
                                 # Run RACC using max_k singular values
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 set.seed(i)
                                 reject_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                          max_k,test_stat_prefixes,B,alpha,
                                                                          cov_cor=cov_cor)[,'all_min_p']
                                 reject_SY = UTDtst::SY2010(t(group_1_residuals),t(group_2_residuals))
                                 reject_LC = UTDtst::LC2012(t(group_1_residuals),t(group_2_residuals))
                                 reject_CLX = UTDtst::CLX2013(t(group_1_residuals),t(group_2_residuals))
                                 reject_HC = UTDtst::HC2018(t(group_1_residuals),t(group_2_residuals),alpha = alpha)
                                 
                                 # XC seems to struggle with small n
                                 reject_XC <- tryCatch({
                                   UTDtst::TwoSampleTest(t(group_1_residuals),t(group_2_residuals),
                                                         k=100,alpha=alpha)
                                 }, error = function(e) {
                                   list(decision=999)  # Return 999 if there is an error
                                 })
                                 
                                 print(i)
                                 
                                 return_vec =c(reject_RACC,
                                               reject_SY$pvalue<alpha,
                                               reject_LC$pvalue<alpha,
                                               reject_CLX$pvalue<alpha,
                                               reject_HC$reject>0,
                                               reject_XC$decision)*1
                                 names(return_vec) = c('RACC','SY','LC','CLX','HC','XC')
                                 
                                 return_vec
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

#### TCGA - Writeup ####
tcga_writeup<-function(){
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  # Import Data
  setwd(WORKING_DIR)  
  gene_expression_residuals = readRDS('residual_matrices.rds')
  n_LUAD = ncol(gene_expression_residuals[['TCGA-LUAD']])
  n_LUSC = ncol(gene_expression_residuals[['TCGA-LUSC']])
  
  # Characteristics of the data
  svd_diff=svd(cov(t(gene_expression_residuals[['TCGA-LUAD']]))-cov(t(gene_expression_residuals[['TCGA-LUSC']])))$d
  
  print(paste('Percent of variation first singular value',cumsum(svd_diff)[1]/sum(svd_diff)))
  print(paste('Number of singular values accounting for 50% of sum',which((cumsum(svd_diff)/sum(svd_diff))>0.5)[1]))
  
  # COMPARE TYPE I AND POWER ACROSS METHODS
  function_name = 'tcga_sims_compare_20241002'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  experiment_df[,c('RACC','SY','LC','CLX','HC','XC')] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    experiment_result = do.call(rbind,experiment_result)
    K = nrow(experiment_result)
    
    experiment_df[experiment_number,c('RACC','SY','LC','CLX','HC','XC')] = colMeans(experiment_result[,c('RACC','SY','LC','CLX','HC','XC')])
    
    if (any(experiment_result[,'XC'] != 999)) {
      XC_avg <- mean(experiment_result[,'XC'][experiment_result[,'XC'] != 999])
    } else {
      XC_avg <- NA  # Handle the case where all values are 999
    }
    
    experiment_df[experiment_number,'XC'] = XC_avg
    
  }
  
  # Type I Table
  type_1_table = experiment_df[experiment_df$cov_cor=='cov',]
  type_1_table = type_1_table[type_1_table$subsample_size>15,]
  type_1_table = type_1_table[type_1_table$null_flag == 'null',
                               c('subsample_size','RACC','SY','LC','CLX','HC','XC')]
  type_1_table[,c('RACC','SY','LC','CLX','HC','XC')] = data.frame(
    apply(type_1_table[,c('RACC','SY','LC','CLX','HC','XC')], 2, function(x) sprintf("%.3f", x)))
  
  type_1_table[type_1_table=='NA'] = '-'
  colnames(type_1_table)[1]='Subsample Size'
  colnames(type_1_table)[colnames(type_1_table)=='RACC']='ACT'
  
  xt = xtable::xtable(type_1_table,
                      caption='Type I error across 1000 different subsamples for ACT and competing methods on the TCGA dataset. Type I error calculatd by testing for equality of covariance matrix only using subjects from the LUAD group.',
                      label='tab:tcga_type1error',
                      align = "|c|c|cccccc|")
  
  print(xt,table.placement = "H",include.rownames = FALSE)
  
  
  # Power chart, save as 2400x1200 PNG
  df_slice = experiment_df[((experiment_df$null_flag == 'not_null')&
                             (experiment_df$cov_cor=='cor')),]
  df_slice = df_slice[,c('subsample_size','RACC','SY','LC','HC')]
  
  # Given we exclude CLX and XC, only use colors 1,2,3,4
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5))  # Set layout to 2x2
  plt = barplot(as.matrix(t(df_slice[,colnames(df_slice)[-1]])), beside=TRUE, 
          names.arg = df_slice[,'subsample_size'],
          col = color_palette[1:4],yaxt='n',las=1,xaxt='n')
  axis(2, at = c(0, 0.25, 0.50,0.75, 1), labels = c("0.00", "0.25","0.50", "0.75", "1.00"),las=1,cex.axis=3)

  text(plt[2,]+.2, adj=0,par("usr")[3] - 0.05, labels = seq(15,50,by=5), srt = 45, pos = 1, xpd = TRUE,cex=3)
  
  # ADAPTIVITY CHART
  function_name = 'tcga_sims_20241002'
  
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  
  # Get column names where we predefine k and add them as columns
  filename=paste(function_name,'-',sprintf("%03d",nrow(experiment_df)),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  result_colnames = colnames(experiment_result[[experiment_number]][[2]])
  experiment_df[,result_colnames] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    result_colnames = colnames(experiment_result[[experiment_number]][[2]])
    K = length(experiment_result)
    
    experiment_df[experiment_number,result_colnames] = Reduce('+',lapply(experiment_result, function(x) x[[2]]))/K
  }
  
  
  # Chart of experiment 9 (~70% power), subsample size = 15
  experiment_number = 9
  power_vector = c(unlist(experiment_df[experiment_number,c(paste0('sum_',1:20),'frob_all','all_min_p')]))
  
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5)) # Set layout to 2x2
  plt = barplot(power_vector-0.3, beside = TRUE, col = c(rep(color_palette[6],20),color_palette[7],color_palette[1]), 
          xaxt='n',yaxt='n',las=2,ylim=c(0,.6))
  axis(2, at = c(0, 0.3, 0.6), labels = c("0.30", "0.60","0.90"),las=1,cex.axis=3)
  
  text(plt, adj=0,par("usr")[3] - .025 , labels = c(paste0('k=',seq(1,20)),'Frobenius','RACT'), srt = 45, pos = 1, xpd = TRUE,cex=2)
  
  print('MAX POWER FROM')
  which(power_vector==max(power_vector))
  
  
}

#### SPINS - Data Processing ####
spins_processing_20241003<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){

  setwd(SPINS_ORIG_DIR)
  print(SPINS_ORIG_DIR)
  dti_be_data = readRDS('SPINS_Behavioral.rds')
  dti_fa_data = readRDS('SPINS_DTI_FractionalAnistropy.rds')
  
  # Get MRC case subjects for different scanners
  # trio =  Siemens Tim Trio 3T, pris = Siemens Prisma
  subject_list = list()
  residuals_list = list()
  subject_list[['m_trio']] = dti_be_data[(dti_be_data$Scanner=='MRC')&(dti_be_data$Disease=='case'),'ID']
  subject_list[['m_prisma']] = dti_be_data[(dti_be_data$Scanner=='MRP')&(dti_be_data$Disease=='case'),'ID']
  
  for(group_name in c('m_trio','m_prisma')){
    # Get behavioural data of subjects in question
    m_group_x = dti_be_data[dti_be_data$ID %in% subject_list[[group_name]],c('ID','Age','Gender')]
    rownames(m_group_x) = m_group_x$ID
    m_group_x = m_group_x[subject_list[[group_name]],]
    m_group_x$ID = NULL
    
    # Get response variables of subjects in question and give same order
    m_group_y = t(dti_fa_data[,subject_list[[group_name]]])
    m_group_residuals = m_group_y
    m_group_residuals[] = 0

    for(region in colnames(m_group_residuals)){
      # Create regression matrix and fit linear model
      XY_df = merge(m_group_y[,region,drop=FALSE],
                    m_group_x[,c('Age','Gender')], by="row.names")
      rownames(XY_df) = XY_df[,'Row.names']
      XY_df[,'Row.names'] = NULL
      
      # 11 values of m_trio are NA in total, 4 in m prisma, fill with
      # mean value for region
      XY_df[is.na(XY_df[,region]),region] = mean(XY_df[,region],na.rm=TRUE)
      
      mod = lm(as.formula(paste(region,'~ Age + Gender')), data = XY_df)
      
      # Extract residuals from linear model
      m_group_residuals[,region] = residuals(mod)
    }
    
    residuals_list[[group_name]] = t(m_group_residuals)  
  }
  
  setwd(SPINS_PROCESSED_DIR)
  saveRDS(residuals_list,file=paste(SPINS_PROCESSED_DIR,'/spins_residuals_matrices.rds',sep=''))
  
  # NOTE NEED TO RUN THIS LINE BY LINE OR CHARTS WILL NOT SAVE PROPERLY
  setwd(SPINS_PROCESSED_DIR)
  residuals_list = readRDS('spins_residuals_matrices.rds')
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists('spins_processing_20241003')){
    dir.create(file.path(RESULTS_DIR,'spins_processing_20241003'))
  }
  
  setwd(file.path(RESULTS_DIR,'spins_processing_20241003'))
  
  # Output images of covariance and correlation matrix
  pdf('cov_m_trio.pdf',width=4,height=4)
  a = image(Matrix(as.matrix(cov(t(residuals_list[['m_trio']])))), lwd=0)
  print(a)
  dev.off()
  
  
  pdf('cor_m_trio.pdf',width=4,height=4)
  a=image(Matrix(as.matrix(cor(t(residuals_list[['m_trio']])))), lwd=0)
  print(a)
  dev.off()
  
  
  pdf('cov_m_prisma.pdf',width=4,height=4)
  a=image(Matrix(as.matrix(cov(t(residuals_list[['m_prisma']])))), lwd=0)
  print(a)
  dev.off()
  
  
  pdf('cor_m_prisma.pdf',width=4,height=4)
  a=image(Matrix(as.matrix(cor(t(residuals_list[['m_prisma']])))), lwd=0)
  print(a)
  dev.off()
  
  # Output image of difference
  pdf('cov_diff.pdf',width=4,height=4)
  cov_diff = as.matrix(cov(t(residuals_list[['m_trio']])))-as.matrix(cov(t(residuals_list[['m_prisma']])))
  a=image(Matrix(cov_diff), lwd=0)
  print(a)
  dev.off()
  
  pdf('cor_diff.pdf',width=4,height=4)
  cor_diff = as.matrix(cor(t(residuals_list[['m_trio']])))-as.matrix(cor(t(residuals_list[['m_prisma']])))
  a=image(Matrix(cor_diff), lwd=0)
  print(a)
  dev.off()
  
  write.csv(svd(cov_diff)$d,file='cov_diff_singular_values.csv')
  write.csv(svd(cor_diff)$d,file='cor_diff_singular_values.csv')
}

spins_charts_20241003<-function(){
  # NOTE NEED TO RUN THIS LINE BY LINE OR CHARTS WILL NOT SAVE PROPERLY
  setwd(SPINS_PROCESSED_DIR)
  residuals_list = readRDS('spins_residuals_matrices.rds')
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists('spins_processing_20241003')){
    dir.create(file.path(RESULTS_DIR,'spins_processing_20241003'))
  }
  
  setwd(file.path(RESULTS_DIR,'spins_processing_20241003'))
  
  # Output images of covariance and correlation matrix
  pdf('cov_m_trio.pdf',width=4,height=4)
  a = image(Matrix(as.matrix(cov(t(residuals_list[['m_trio']])))), lwd=0)
  print(a)
  dev.off()
  
  
  pdf('cor_m_trio.pdf',width=4,height=4)
  a=image(Matrix(as.matrix(cor(t(residuals_list[['m_trio']])))), lwd=0)
  print(a)
  dev.off()
  
  
  pdf('cov_m_prisma.pdf',width=4,height=4)
  a=image(Matrix(as.matrix(cov(t(residuals_list[['m_prisma']])))), lwd=0)
  print(a)
  dev.off()
  
  
  pdf('cor_m_prisma.pdf',width=4,height=4)
  a=image(Matrix(as.matrix(cor(t(residuals_list[['m_prisma']])))), lwd=0)
  print(a)
  dev.off()
  
  # Output image of difference
  pdf('cov_diff.pdf',width=4,height=4)
  cov_diff = as.matrix(cov(t(residuals_list[['m_trio']])))-as.matrix(cov(t(residuals_list[['m_prisma']])))
  a=image(Matrix(cov_diff), lwd=0)
  print(a)
  dev.off()
  
  pdf(filename = 'cor_diff.pdf',width=4,height=4)
  cor_diff = as.matrix(cor(t(residuals_list[['m_trio']])))-as.matrix(cor(t(residuals_list[['m_prisma']])))
  a=image(Matrix(cor_diff), lwd=0)
  print(a)
  dev.off()
  
  write.csv(svd(cov_diff)$d,file='cov_diff_singular_values.csv')
  write.csv(svd(cor_diff)$d,file='cor_diff_singular_values.csv')
  
}

spins_processing_20241010<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'spins_processing_20241010'
  setwd(SPINS_ORIG_DIR)
  print(SPINS_ORIG_DIR)
  dti_be_data = readRDS('SPINS_Behavioral.rds')
  dti_fa_data = readRDS('SPINS_DTI_FractionalAnistropy.rds')
  
  # Get subjects scanned with     GE (CMH and ZMH)
  # and                           Siemens Primsa (CMP, MRP, ZHP)
  subject_list = list()
  residuals_list = list()
  subject_list[['GE']] = dti_be_data[dti_be_data$Scanner %in% c('CMH','ZMH'),'ID']
  subject_list[['SP']] = dti_be_data[dti_be_data$Scanner %in% c('CMP','MRP','ZHP'),'ID']
  
  for(group_name in c('GE','SP')){
    # Get behavioural data of subjects in question
    m_group_x = dti_be_data[dti_be_data$ID %in% subject_list[[group_name]],c('ID','Age','Gender','Disease')]
    rownames(m_group_x) = m_group_x$ID
    m_group_x = m_group_x[subject_list[[group_name]],]
    m_group_x$ID = NULL
    
    # Get response variables of subjects in question and give same order
    m_group_y = t(dti_fa_data[,subject_list[[group_name]]])
    m_group_residuals = m_group_y
    m_group_residuals[] = 0
    
    for(region in colnames(m_group_residuals)){
      # Create regression matrix and fit linear model
      XY_df = merge(m_group_y[,region,drop=FALSE],
                    m_group_x[,c('Age','Gender','Disease')], by="row.names")
      rownames(XY_df) = XY_df[,'Row.names']
      XY_df[,'Row.names'] = NULL
      
      # Fill any NA values with mean value for region
      XY_df[is.na(XY_df[,region]),region] = mean(XY_df[,region],na.rm=TRUE)
      
      reg_formula = as.formula(paste(region,
                          '~ Age + I(Age**2) + Gender + Disease + Age:Gender + Age:Disease'))
      
      mod = lm(reg_formula, data = XY_df)
      
      # Extract residuals from linear model
      m_group_residuals[,region] = residuals(mod)
    }
    
    residuals_list[[group_name]] = t(m_group_residuals)  
  }
  
  setwd(SPINS_PROCESSED_DIR)
  saveRDS(residuals_list,file=paste(SPINS_PROCESSED_DIR,'/spins_residuals_matrices.rds',sep=''))
  
  # NOTE NEED TO RUN THIS LINE BY LINE OR CHARTS WILL NOT SAVE PROPERLY
  setwd(SPINS_PROCESSED_DIR)
  residuals_list = readRDS('spins_residuals_matrices.rds')
  
  # Setups Results Directory
  setwd(RESULTS_DIR)
  if(!file.exists(function_name)){
    dir.create(file.path(RESULTS_DIR,function_name))
  }
  
  setwd(file.path(RESULTS_DIR,function_name))
  
  # Output images of covariance and correlation matrix
  pdf('cov_GE.pdf',width=4,height=4)
  a = image(Matrix(as.matrix(cov(t(residuals_list[['GE']])))), lwd=0)
  print(a)
  dev.off()
  
  
  pdf('cor_GE.pdf',width=4,height=4)
  a=image(Matrix(as.matrix(cor(t(residuals_list[['GE']])))), lwd=0)
  print(a)
  dev.off()
  
  
  pdf('cov_SP.pdf',width=4,height=4)
  a=image(Matrix(as.matrix(cov(t(residuals_list[['SP']])))), lwd=0)
  print(a)
  dev.off()
  
  
  pdf('cor_SP.pdf',width=4,height=4)
  a=image(Matrix(as.matrix(cor(t(residuals_list[['SP']])))), lwd=0)
  print(a)
  dev.off()
  
  # Output image of difference
  pdf('cov_diff.pdf',width=4,height=4)
  cov_diff = as.matrix(cov(t(residuals_list[['GE']])))-as.matrix(cov(t(residuals_list[['SP']])))
  a=image(Matrix(cov_diff), lwd=0)
  print(a)
  dev.off()
  
  pdf('cor_diff.pdf',width=4,height=4)
  cor_diff = as.matrix(cor(t(residuals_list[['GE']])))-as.matrix(cor(t(residuals_list[['SP']])))
  a=image(Matrix(cor_diff), lwd=0)
  print(a)
  dev.off()
  
  write.csv(svd(cov_diff)$d,file='cov_diff_singular_values.csv')
  write.csv(svd(cor_diff)$d,file='cor_diff_singular_values.csv')
}

spins_processing_both_20241015<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'spins_processing_both_20241015'
  setwd(SPINS_ORIG_DIR)
  print(SPINS_ORIG_DIR)
  
  dti_be_data = readRDS('SPINS_Behavioral.rds')
  # Get subjects scanned with     GE (CMH and ZMH)
  # and                           Siemens Primsa (CMP, MRP, ZHP)
  subject_list = list()
  subject_list[['GE']] = dti_be_data[dti_be_data$Scanner %in% c('CMH','ZMH'),'ID']
  subject_list[['SP']] = dti_be_data[dti_be_data$Scanner %in% c('CMP','MRP','ZHP'),'ID']
  
  for(modality in c('FA','MD')){
    
    setwd(SPINS_ORIG_DIR)
    # Read in FA or MD data
    if(modality == 'FA'){
      spins_data = readRDS('SPINS_DTI_FractionalAnistropy.rds') 
    }else if(modality == 'MD'){
      spins_data = readRDS('SPINS_DTI_MeanDiffusitivity.rds')
    }

    residuals_list = list()
    
    # For GE and SP groups, preprocess data
    for(group_name in c('GE','SP')){
      # Get behavioural data of subjects in question
      m_group_x = dti_be_data[dti_be_data$ID %in% subject_list[[group_name]],c('ID','Age','Gender','Disease')]
      rownames(m_group_x) = m_group_x$ID
      m_group_x = m_group_x[subject_list[[group_name]],]
      m_group_x$ID = NULL
      
      # Get response variables of subjects in question and give same order
      m_group_y = t(spins_data[,subject_list[[group_name]]])
      m_group_residuals = m_group_y
      m_group_residuals[] = 0
      
      for(region in colnames(m_group_residuals)){
        # Create regression matrix and fit linear model
        XY_df = merge(m_group_y[,region,drop=FALSE],
                      m_group_x[,c('Age','Gender','Disease')], by="row.names")
        rownames(XY_df) = XY_df[,'Row.names']
        XY_df[,'Row.names'] = NULL
        
        # Fill any NA values with mean value for region
        XY_df[is.na(XY_df[,region]),region] = mean(XY_df[,region],na.rm=TRUE)
        
        reg_formula = as.formula(paste(region,
                                       '~ Age + I(Age**2) + Gender + Disease + Age:Gender + Age:Disease'))
        
        mod = lm(reg_formula, data = XY_df)
        
        # Extract residuals from linear model
        m_group_residuals[,region] = residuals(mod)
      }
      
      residuals_list[[group_name]] = t(m_group_residuals)  
    }
    
    setwd(SPINS_PROCESSED_DIR)
    filename_data = paste(SPINS_PROCESSED_DIR,'/spins_residuals_matrices_',modality,'.rds',sep='')
    
    saveRDS(residuals_list,file=filename_data)
    
    # Plot charts of covariance and correlation matrices
    setwd(SPINS_PROCESSED_DIR)
    residuals_list = readRDS(filename_data)
    
    # Setup Results Directory
    setwd(RESULTS_DIR)
    if(!file.exists(function_name)){
      dir.create(file.path(RESULTS_DIR,function_name))
    }
    
    setwd(file.path(RESULTS_DIR,function_name))
    
    
    # Output images of covariance and correlation matrix
    pdf(paste('cov_GE_',modality,'.pdf',sep=''),width=4,height=4)
    a = image(Matrix(as.matrix(cov(t(residuals_list[['GE']])))), lwd=0)
    print(a)
    dev.off()
    
    
    pdf(paste('cor_GE_',modality,'.pdf',sep=''),width=4,height=4)
    a=image(Matrix(as.matrix(cor(t(residuals_list[['GE']])))), lwd=0)
    print(a)
    dev.off()
    
    pdf(paste('cov_SP_',modality,'.pdf',sep=''),width=4,height=4)
    cov_mat = as.matrix(cov(t(residuals_list[['SP']])))
    a=image(Matrix(cov_mat), lwd=0)
    print(a)
    dev.off()
    
    pdf(paste('cor_SP_',modality,'.pdf',sep=''),width=4,height=4)
    a=image(Matrix(as.matrix(cor(t(residuals_list[['SP']])))))
    print(a)
    dev.off()
    
    # Output image of difference
    pdf(paste('cov_diff_',modality,'.pdf',sep=''),width=4,height=4)
    cov_diff = as.matrix(cov(t(residuals_list[['GE']])))-as.matrix(cov(t(residuals_list[['SP']])))
    a=image(Matrix(cov_diff), lwd=0)
    print(a)
    dev.off()
    
    pdf(paste('cor_diff_',modality,'.pdf',sep=''),width=4,height=4)
    cor_diff = as.matrix(cor(t(residuals_list[['GE']])))-as.matrix(cor(t(residuals_list[['SP']])))
    a=image(Matrix(cor_diff), lwd=0)
    print(a)
    dev.off()
    
    write.csv(svd(cov_diff)$d,file=paste('cov_diff_singular_values_',modality,'.csv',sep=''))
    write.csv(svd(cor_diff)$d,file=paste('cor_diff_singular_values_',modality,'.csv',sep=''))  
  }
}


#### SPINS - Simulations ####
spins_sims_20241004<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'spins_sims_20241004'
  
  K=1000    # 1000     
  B=1000    # 1000         
  alpha=.05
  max_k_pct=.95
  k_compare = 50 # number of singular values to look at in comparison
  test_stat_prefixes = c('sum','frob')
  
  experiment_df = expand.grid(subsample_size = seq(10,35,by=5),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov','cor'), stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  setwd(SPINS_PROCESSED_DIR)
  spins_residuals = readRDS('spins_residuals_matrices.rds')
  
  n_group_1 = ncol(spins_residuals[['m_trio']])
  n_group_2 = ncol(spins_residuals[['m_prisma']])
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select trio, and prisma subjects
                                   group_1_residuals = spins_residuals[['m_trio']][,sample(1:n_group_1,subsample_size)]
                                   group_2_residuals = spins_residuals[['m_prisma']][,sample(1:n_group_2,subsample_size)]
                                 }else{
                                   # Sample only from trio subjects
                                   sampled_subjects = sample(1:n_group_1,subsample_size*2,replace=TRUE)
                                   group_1_residuals = spins_residuals[['m_trio']][,sampled_subjects[1:subsample_size]]
                                   group_2_residuals = spins_residuals[['m_trio']][,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(i)
                                 reject_matrix_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                 max_k,test_stat_prefixes,B,alpha,
                                                                                 cov_cor=cov_cor)
                                 
                                 # Run RACC using k_compare singular values
                                 set.seed(i)
                                 reject_matrix_k_compare = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                      min(k_compare,2*subsample_size),
                                                                                      test_stat_prefixes,B,alpha,
                                                                                      cov_cor = cov_cor)
                                 
                                 print(i)
                                 
                                 list(reject_matrix_RACC,reject_matrix_k_compare)
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

spins_compare_20241004<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'spins_compare_20241004'
  
  K=1000    # 1000     
  B=1000    # 1000         
  alpha=.05
  max_k_pct=.95
  k_compare = 50 # number of singular values to look at in comparison
  test_stat_prefixes = c('sum','frob')
  
  experiment_df = expand.grid(subsample_size = seq(10,35,by=5),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov','cor'), stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  setwd(SPINS_PROCESSED_DIR)
  spins_residuals = readRDS('spins_residuals_matrices.rds')
  
  n_group_1 = ncol(spins_residuals[['m_trio']])
  n_group_2 = ncol(spins_residuals[['m_prisma']])
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df),
                               .errorhandling = 'pass')%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select trio, and prisma subjects
                                   group_1_residuals = spins_residuals[['m_trio']][,sample(1:n_group_1,subsample_size)]
                                   group_2_residuals = spins_residuals[['m_prisma']][,sample(1:n_group_2,subsample_size)]
                                 }else{
                                   # Sample only from trio subjects
                                   sampled_subjects = sample(1:n_group_1,subsample_size*2,replace=TRUE)
                                   group_1_residuals = spins_residuals[['m_trio']][,sampled_subjects[1:subsample_size]]
                                   group_2_residuals = spins_residuals[['m_trio']][,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(i)
                                 reject_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                          max_k,test_stat_prefixes,B,alpha,
                                                                          cov_cor=cov_cor)[,'all_min_p']
                                 reject_SY = UTDtst::SY2010(t(group_1_residuals),t(group_2_residuals))
                                 reject_LC = UTDtst::LC2012(t(group_1_residuals),t(group_2_residuals))
                                 reject_CLX = UTDtst::CLX2013(t(group_1_residuals),t(group_2_residuals))
                                 reject_HC = UTDtst::HC2018(t(group_1_residuals),t(group_2_residuals),alpha = alpha)
                                 
                                 # XC seems to struggle with small n
                                 reject_XC <- tryCatch({
                                   UTDtst::TwoSampleTest(t(group_1_residuals),t(group_2_residuals),
                                                         k=100,alpha=alpha)
                                 }, error = function(e) {
                                   list(decision=999)  # Return 999 if there is an error
                                 })
                                 
                                 print(i)
                                 
                                 return_vec =c(reject_RACC,
                                               reject_SY$pvalue<alpha,
                                               reject_LC$pvalue<alpha,
                                               reject_CLX$pvalue<alpha,
                                               reject_HC$reject>0,
                                               reject_XC$decision)*1
                                 names(return_vec) = c('RACC','SY','LC','CLX','HC','XC')
                                 
                                 print(i)
                                 
                                 return_vec
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

spins_characteristics<-function(){
  # Have this on separate function as need to run on server
  # Import Data
  setwd(SPINS_PROCESSED_DIR)
  spins_residuals = readRDS('spins_residuals_matrices.rds')
  
  # Characteristics of the data
  svd_diff=svd(cov(t(spins_residuals[['m_trio']]))-cov(t(spins_residuals[['m_prisma']])))$d
  
  print(paste('Percent of variation first singular value',cumsum(svd_diff)[1]/sum(svd_diff)))
  print(paste('Number of singular values accounting for 50% of sum',which((cumsum(svd_diff)/sum(svd_diff))>0.5)[1]))
  
}

spins_sims_writeup<-function(){
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")

  # COMPARE TYPE I AND POWER ACROSS METHODS
  function_name = 'spins_compare_20241004'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  experiment_df[,c('RACC','SY','LC','CLX','HC','XC')] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    experiment_result = do.call(rbind,experiment_result)
    K = nrow(experiment_result)
    
    experiment_df[experiment_number,c('RACC','SY','LC','CLX','HC','XC')] = colMeans(experiment_result[,c('RACC','SY','LC','CLX','HC','XC')])
    
    if (any(experiment_result[,'XC'] != 999)) {
      XC_avg <- mean(experiment_result[,'XC'][experiment_result[,'XC'] != 999])
    } else {
      XC_avg <- NA  # Handle the case where all values are 999
    }
    
    experiment_df[experiment_number,'XC'] = XC_avg
    
  }
  
  # Type I Table
  type_1_table = experiment_df[experiment_df$cov_cor=='cor',]
  type_1_table = type_1_table[type_1_table$subsample_size>=10,]
  type_1_table = type_1_table[type_1_table$null_flag == 'null',
                              c('subsample_size','RACC','SY','LC','CLX','HC','XC')]
  type_1_table[,c('RACC','SY','LC','CLX','HC','XC')] = data.frame(
    apply(type_1_table[,c('RACC','SY','LC','CLX','HC','XC')], 2, function(x) sprintf("%.3f", x)))
  
  type_1_table[type_1_table=='NA'] = '-'
  colnames(type_1_table)[1]='Subsample Size'
  colnames(type_1_table)[colnames(type_1_table)=='RACC']='RACT'
  
  xt = xtable::xtable(type_1_table,
                      caption='Type I error across 1000 different subsamples for RACT and competing methods on the TCGA dataset. Type I error calculatd by testing for equality of covariance matrix only using subjects from the LUAD group.',
                      label='tab:spins_type1error',
                      align = "|c|c|cccccc|")
  
  print(xt,table.placement = "H",include.rownames = FALSE)
  
  # Power chart, save as 2400x1200 PNG
  df_slice = experiment_df[((experiment_df$null_flag == 'not_null')&
                              (experiment_df$cov_cor=='cov')&
                              (experiment_df$subsample_size>=15)),]
  df_slice = df_slice[,c('subsample_size','RACC','SY','LC','HC','CLX')]
  
  # Given we exclude and XC, only use colors 1,2,3,4
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5))  # Set layout to 2x2
  plt = barplot(as.matrix(t(df_slice[,colnames(df_slice)[-1]])), beside=TRUE, 
                names.arg = df_slice[,'subsample_size'],
                col = color_palette[1:5],yaxt='n',las=1,xaxt='n',ylim=c(0,0.75))
  axis(2, at = c(0, 0.25, 0.50,0.75), labels = c("0.00", "0.25","0.50", "0.75"),
       las=1,cex.axis=3,ylim=c(0,1))
  
  text(plt[2,]+.2, adj=0,par("usr")[3] - 0.05, labels = seq(15,35,by=5), srt = 45, pos = 1, xpd = TRUE,cex=3)
  
  
  # ADAPTIVITY CHART
  function_name = 'spins_sims_20241004'
  
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  
  # Get column names where we predefine k and add them as columns
  filename=paste(function_name,'-',sprintf("%03d",nrow(experiment_df)),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  result_colnames = colnames(experiment_result[[experiment_number]][[2]])
  experiment_df[,result_colnames] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    result_colnames = colnames(experiment_result[[experiment_number]][[2]])
    K = length(experiment_result)
    
    experiment_df[experiment_number,result_colnames] = Reduce('+',lapply(experiment_result, function(x) x[[2]]))/K
  }
  
  
  # Chart of experiment 12 (~70% power), subsample size = 15
  experiment_number = 12
  power_vector = c(unlist(experiment_df[experiment_number,c(paste0('sum_',1:20),'frob_all','all_min_p')]))
  
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5)) # Set layout to 2x2
  plt = barplot(power_vector, beside = TRUE, col = c(rep(color_palette[6],20),color_palette[7],color_palette[1]), 
                xaxt='n',yaxt='n',las=2,ylim=c(0,1))
  axis(2, at = c(0,.25,.5,.75,1.00), labels = c("0.00", "0.25","0.50","0.75","1.00"),las=1,cex.axis=3)
  
  text(plt, adj=0,par("usr")[3] - .04 , labels = c(paste0('k=',seq(1,20)),'Frobenius','RACT'), srt = 45, pos = 1, xpd = TRUE,cex=2)
  
  print('MAX POWER FROM')
  which(power_vector==max(power_vector))
  
  
  
  
  
  
 
}

#### REAL DATA SIMULATIONS (BOTH DATASETS) ####
real_data_sims_20241010<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'real_data_sims_20241010'
  
  K=1000    # 1000     
  B=1000    # 1000         
  alpha=.05
  max_k_pct=.80
  k_compare = 50 # number of singular values to look at in comparison
  test_stat_prefixes = c('sum','frob')
  
  experiment_df = expand.grid(subsample_size = c(15,20,25,30,35,40,45,50),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov','cor'), 
                              dataset = c('TCGA','SPINS'),
                              stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    # Based on which dataset we are analyzing, import both groups from the appropriate dataset
    if(dataset=='TCGA'){
      setwd(WORKING_DIR)  
      gene_expression_residuals = readRDS('tcga_residual_matrices.rds')
      group_1_residuals = gene_expression_residuals[['TCGA-LUAD']]
      group_2_residuals = gene_expression_residuals[['TCGA-LUSC']]
    }else if(dataset=='SPINS'){
      # Import Data
      setwd(SPINS_PROCESSED_DIR)
      spins_residuals = readRDS('spins_residuals_matrices.rds')
      group_1_residuals = spins_residuals[['GE']]
      group_2_residuals = spins_residuals[['SP']]
    }
    
    n_group_1 = ncol(group_1_residuals)
    n_group_2 = ncol(group_2_residuals)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select LUAD, and LUSC subjects
                                   group_1_subsample = group_1_residuals[,sample(1:n_group_1,subsample_size)]
                                   group_2_subsample = group_2_residuals[,sample(1:n_group_2,subsample_size)]
                                 }else{
                                   # Sample only from LUAD subjects
                                   sampled_subjects = sample(1:n_group_1,subsample_size*2)
                                   group_1_subsample = group_1_residuals[,sampled_subjects[1:subsample_size]]
                                   group_2_subsample = group_1_residuals[,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 max_k = max_k_calculation(cbind(group_1_subsample,group_2_subsample),
                                                           max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(i)
                                 reject_matrix_RACC = test_equality_cov_20240925(group_1_subsample,group_2_subsample,
                                                                                 max_k,test_stat_prefixes,B,alpha,
                                                                                 cov_cor=cov_cor)
                                 
                                 # Run RACC using k_compare singular values
                                 set.seed(i)
                                 reject_matrix_k_compare = test_equality_cov_20240925(group_1_subsample,group_2_subsample,
                                                                                      min(k_compare,2*subsample_size),
                                                                                      test_stat_prefixes,B,alpha,
                                                                                      cov_cor = cov_cor)
                                 
                                 print(i)
                                 
                                 list(reject_matrix_RACC,reject_matrix_k_compare)
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

real_data_compare_20241010<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'real_data_compare_20241010'
  
  K=1000         # 1000     
  B=1000         # 1000         
  B_other = 1000 # 1000
  alpha=.05
  max_k_pct=.80
  k_compare = 50 # number of singular values to look at in comparison
  test_stat_prefixes = c('sum','frob')
  
  experiment_df = expand.grid(subsample_size = c(15,20,25,30,35,40,45,50),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov','cor'), 
                              dataset = c('TCGA','SPINS'),
                              stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    # Based on which dataset we are analyzing, import both groups from the appropriate dataset
    if(dataset=='TCGA'){
      setwd(WORKING_DIR)  
      gene_expression_residuals = readRDS('tcga_residual_matrices.rds')
      group_1_residuals = gene_expression_residuals[['TCGA-LUAD']]
      group_2_residuals = gene_expression_residuals[['TCGA-LUSC']]
    }else if(dataset=='SPINS'){
      # Import Data
      setwd(SPINS_PROCESSED_DIR)
      spins_residuals = readRDS('spins_residuals_matrices.rds')
      group_1_residuals = spins_residuals[['GE']]
      group_2_residuals = spins_residuals[['SP']]
    }
    
    n_group_1 = ncol(group_1_residuals)
    n_group_2 = ncol(group_2_residuals)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df),
                               .errorhandling = 'pass')%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select LUAD, and LUSC subjects
                                   group_1_subsample = group_1_residuals[,sample(1:n_group_1,subsample_size)]
                                   group_2_subsample = group_2_residuals[,sample(1:n_group_2,subsample_size)]
                                 }else{
                                   # Sample only from LUAD subjects
                                   sampled_subjects = sample(1:n_group_1,subsample_size*2)
                                   group_1_subsample = group_1_residuals[,sampled_subjects[1:subsample_size]]
                                   group_2_subsample = group_1_residuals[,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 max_k = max_k_calculation(cbind(group_1_subsample,group_2_subsample),
                                                           max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC
                                 set.seed(i)
                                 reject_RACC = test_equality_cov_20240925(group_1_subsample,group_2_subsample,
                                                                          max_k,test_stat_prefixes,B,alpha,
                                                                          cov_cor=cov_cor)[,'all_min_p']
                                 
                                 # Other methods (non permutation)
                                 reject_SY = UTDtst::SY2010(t(group_1_subsample),t(group_2_subsample))
                                 reject_LC = UTDtst::LC2012(t(group_1_subsample),t(group_2_subsample))
                                 reject_CLX = UTDtst::CLX2013(t(group_1_subsample),t(group_2_subsample))
                                 reject_HC = UTDtst::HC2018(t(group_1_subsample),t(group_2_subsample),alpha = alpha)
                                 reject_XC <- tryCatch({
                                   # XC seems to struggle with small n
                                   UTDtst::TwoSampleTest(t(group_1_subsample),t(group_2_subsample),
                                                         k=100,alpha=alpha)
                                 }, error = function(e) {
                                   list(decision=999)  # Return 999 if there is an error
                                 })
                                 
                                 # Permutation
                                 other_perm_matrix = matrix(data=NA,ncol=4,nrow=B_other)
                                 colnames(other_perm_matrix) = c('SY','LC','CLX','HC')
                                 
                                 set.seed(i)
                                 for(b in 1:B_other){
                                   combined_subsample = cbind(group_1_subsample,group_2_subsample)
                                   permutation_order = sample(1:(subsample_size*2))
                                   group_1_permutation = combined_subsample[,permutation_order[1:subsample_size]]
                                   group_2_permutation = combined_subsample[,permutation_order[(subsample_size+1):(2*subsample_size)]]
                                   
                                   other_perm_matrix[b,'SY'] = UTDtst::SY2010(t(group_1_permutation),t(group_2_permutation))$Q2
                                   other_perm_matrix[b,'LC'] = UTDtst::LC2012(t(group_1_permutation),t(group_2_permutation))$statistic
                                   other_perm_matrix[b,'CLX'] = UTDtst::CLX2013(t(group_1_permutation),t(group_2_permutation))$TSvalue
                                   other_perm_matrix[b,'HC'] = min(UTDtst::HC2018(t(group_1_permutation),t(group_2_permutation),alpha = alpha)$pvalues)
                                 }
                                 
                                 print(i)
                                 
                                 return_vec =list(reject_RACC,
                                               reject_SY,
                                               reject_LC,
                                               reject_CLX,
                                               reject_HC,
                                               reject_XC,
                                               other_perm_matrix)
                                 names(return_vec) = c('RACC','SY','LC','CLX','HC','XC','permmat')
                                 
                                 return_vec
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

real_data_sims_20241010_writeup<-function(){
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  # COMPARE TYPE I AND POWER ACROSS METHODS
  function_name = 'real_data_sims_20241010'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')

  # Get column names where we predefine k and add them as columns
  filename=paste(function_name,'-',sprintf("%03d",nrow(experiment_df)),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  result_colnames = colnames(experiment_result[[experiment_number]][[2]])
  experiment_df[,result_colnames] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    result_colnames = colnames(experiment_result[[experiment_number]][[2]])
    K = length(experiment_result)
    
    experiment_df[experiment_number,result_colnames] = Reduce('+',lapply(experiment_result, function(x) x[[2]]))/K
  }
  
  
  # ADAPTIVITY CHARTS SAVE AS 2400X1200
  
  # TCGA ~80% power - subsample size = 15
  experiment_number = experiment_df[((experiment_df$subsample_size==15)&
                                     (experiment_df$cov_cor=='cov')&
                                     (experiment_df$dataset=='TCGA')&
                                     (experiment_df$null_flag=='not_null')),'experiment_number']
  power_vector = c(unlist(experiment_df[experiment_number,c(paste0('sum_',1:20),'frob_all','all_min_p')]))
  
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5)) # Set layout to 2x2
  plt = barplot(power_vector-0.3, beside = TRUE, col = c(rep(color_palette[6],20),color_palette[7],color_palette[1]), 
                xaxt='n',yaxt='n',las=2,ylim=c(0,.6))
  axis(2, at = c(0, 0.3, 0.6), labels = c("0.30", "0.60","0.90"),las=1,cex.axis=3)
  
  text(plt, adj=0,par("usr")[3] - .025 , labels = c(paste0('k=',seq(1,20)),'Frobenius','RACT'), srt = 45, pos = 1, xpd = TRUE,cex=2)
  
  print('MAX POWER FROM')
  which(power_vector==max(power_vector))
  
  # SPINS ~80% power - subsample size = 30
  experiment_number = experiment_df[((experiment_df$subsample_size==30)&
                                       (experiment_df$cov_cor=='cov')&
                                       (experiment_df$dataset=='SPINS')&
                                       (experiment_df$null_flag=='not_null')),'experiment_number']
  power_vector = c(unlist(experiment_df[experiment_number,c(paste0('sum_',1:20),'frob_all','all_min_p')]))
  
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5)) # Set layout to 2x2
  plt = barplot(power_vector-0.3, beside = TRUE, col = c(rep(color_palette[6],20),color_palette[7],color_palette[1]), 
                xaxt='n',yaxt='n',las=2,ylim=c(0,.6))
  axis(2, at = c(0, 0.3, 0.6), labels = c("0.30", "0.60","0.90"),las=1,cex.axis=3)
  
  text(plt, adj=0,par("usr")[3] - .025 , labels = c(paste0('k=',seq(1,20)),'Frobenius','RACT'), srt = 45, pos = 1, xpd = TRUE,cex=2)
  
  print('MAX POWER FROM')
  which(power_vector==max(power_vector))
  
  
}


real_data_compare_20241010_writeup<-function(){
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  # COMPARE TYPE I AND POWER ACROSS METHODS
  function_name = 'real_data_compare_20241010'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  experiment_df[,c('RACC','SY','LC','CLX','HC','XC','SYperm','LCperm','CLXperm','HCperm')] = 999
  
  for(experiment_number in c(seq(1,7),seq(9,15),seq(17,23),seq(25,31),seq(33,64))){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    experiment_result = do.call(rbind,experiment_result)
    K = nrow(experiment_result)
    
    experiment_df[experiment_number,c('RACC','SY','LC','CLX','HC','XC','SYperm','LCperm','CLXperm','HCperm')] = colMeans(experiment_result[,c('RACC','SY','LC','CLX','HC','XC','SYperm','LCperm','CLXperm','HCperm')])
    
    if (any(experiment_result[,'XC'] != 999)) {
      XC_avg <- mean(experiment_result[,'XC'][experiment_result[,'XC'] != 999])
    } else {
      XC_avg <- NA  # Handle the case where all values are 999
    }
    
    experiment_df[experiment_number,'XC'] = XC_avg
    
  }
  
  # Type I Table
  type_1_table = experiment_df[experiment_df$cov_cor=='cor',]
  type_1_table = type_1_table[type_1_table$subsample_size>=10,]
  type_1_table = type_1_table[type_1_table$null_flag == 'null',
                              c('subsample_size','RACC','SY','LC','CLX','HC','XC')]
  type_1_table[,c('RACC','SY','LC','CLX','HC','XC')] = data.frame(
    apply(type_1_table[,c('RACC','SY','LC','CLX','HC','XC')], 2, function(x) sprintf("%.3f", x)))
  
  type_1_table[type_1_table=='NA'] = '-'
  colnames(type_1_table)[1]='Subsample Size'
  colnames(type_1_table)[colnames(type_1_table)=='RACC']='RACT'
  
  xt = xtable::xtable(type_1_table,
                      caption='Type I error across 1000 different subsamples for RACT and competing methods on the TCGA dataset. Type I error calculatd by testing for equality of covariance matrix only using subjects from the LUAD group.',
                      label='tab:spins_type1error',
                      align = "|c|c|cccccc|")
  
  print(xt,table.placement = "H",include.rownames = FALSE)
  
  # Power chart, save as 2400x1200 PNG
  df_slice = experiment_df[((experiment_df$null_flag == 'not_null')&
                              (experiment_df$cov_cor=='cov')&
                              (experiment_df$subsample_size>=15)),]
  df_slice = df_slice[,c('subsample_size','RACC','SY','LC','HC','CLX')]
  
  # Given we exclude and XC, only use colors 1,2,3,4
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5))  # Set layout to 2x2
  plt = barplot(as.matrix(t(df_slice[,colnames(df_slice)[-1]])), beside=TRUE, 
                names.arg = df_slice[,'subsample_size'],
                col = color_palette[1:5],yaxt='n',las=1,xaxt='n',ylim=c(0,0.75))
  axis(2, at = c(0, 0.25, 0.50,0.75), labels = c("0.00", "0.25","0.50", "0.75"),
       las=1,cex.axis=3,ylim=c(0,1))
  
  text(plt[2,]+.2, adj=0,par("usr")[3] - 0.05, labels = seq(15,35,by=5), srt = 45, pos = 1, xpd = TRUE,cex=3)
  
  
  # ADAPTIVITY CHART
  function_name = 'spins_sims_20241004'
  
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  
  # Get column names where we predefine k and add them as columns
  filename=paste(function_name,'-',sprintf("%03d",nrow(experiment_df)),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  result_colnames = colnames(experiment_result[[experiment_number]][[2]])
  experiment_df[,result_colnames] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    result_colnames = colnames(experiment_result[[experiment_number]][[2]])
    K = length(experiment_result)
    
    experiment_df[experiment_number,result_colnames] = Reduce('+',lapply(experiment_result, function(x) x[[2]]))/K
  }
  
  
  # Chart of experiment 12 (~70% power), subsample size = 15
  experiment_number = 12
  power_vector = c(unlist(experiment_df[experiment_number,c(paste0('sum_',1:20),'frob_all','all_min_p')]))
  
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5)) # Set layout to 2x2
  plt = barplot(power_vector, beside = TRUE, col = c(rep(color_palette[6],20),color_palette[7],color_palette[1]), 
                xaxt='n',yaxt='n',las=2,ylim=c(0,1))
  axis(2, at = c(0,.25,.5,.75,1.00), labels = c("0.00", "0.25","0.50","0.75","1.00"),las=1,cex.axis=3)
  
  text(plt, adj=0,par("usr")[3] - .04 , labels = c(paste0('k=',seq(1,20)),'Frobenius','RACT'), srt = 45, pos = 1, xpd = TRUE,cex=2)
  
  print('MAX POWER FROM')
  which(power_vector==max(power_vector))
  
  
  
  
  
  
  
  
  
  
  # New compare methods
  function_name = 'real_data_compare_20241010'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  method_names = c('SYperm','LCperm','CLXperm','HCperm','SY','LC','CLX','HC','RACT','XC')
  experiment_df[,method_names] = NA
  alpha = 0.05
  
  for(x in 1:nrow(experiment_df)){
    filename = paste(function_name,'-',sprintf("%03d",x),'.RDS',sep='')
    result = readRDS(filename)
    
    reject_matrix = matrix(data=0,nrow=1000,ncol=10)
    colnames(reject_matrix) = method_names
    
    for(i in 1:length(result)){
      
      if(result[[i]]$SY$Q2 <= quantile(result[[i]]$permmat[,'SY'],alpha/2)){
        reject_matrix[i,'SYperm']=1
      }
      
      if(result[[i]]$SY$Q2 >= quantile(result[[i]]$permmat[,'SY'],1-alpha/2)){
        reject_matrix[i,'SYperm']=1
      }
      
      if(result[[i]]$LC$statistic >= quantile(result[[i]]$permmat[,'LC'],1-alpha)){
        reject_matrix[i,'LCperm']=1
      }
      
      if(result[[i]]$CLX$TSvalue >= quantile(result[[i]]$permmat[,'CLX'],1-alpha)){
        reject_matrix[i,'CLXperm']=1
      }
      
      if(min(result[[i]]$HC$pvalues) <= quantile(result[[i]]$permmat[,'HC'],alpha)){
        reject_matrix[i,'HCperm']=1
      }
      
      
      reject_matrix[i,'RACT'] = result[[i]]$RACC
      reject_matrix[i,'XC'] = result[[i]]$XC$decision
      reject_matrix[i,'SY'] = (result[[i]]$SY$pvalue <= alpha)*1
      reject_matrix[i,'LC'] = (result[[i]]$LC$pvalue <= alpha)*1
      reject_matrix[i,'CLX'] = (result[[i]]$CLX$pvalue <= alpha)*1
      reject_matrix[i,'HC'] = (result[[i]]$HC$reject > 0)*1
      
    }
    
    
    
    experiment_df[x,method_names] = apply(reject_matrix,2,mean)
    
    print(x)  
  }
    
  
  # TCGA Type I
  experiment_df[(experiment_df$dataset=='TCGA')&(experiment_df$cov_cor=='cov'),]
  
  # TCGA Power
  
  # Power chart, save as 2400x1200 PNG
  df_slice = experiment_df[((experiment_df$null_flag == 'not_null')&
                              (experiment_df$cov_cor=='cov')&
                              (experiment_df$subsample_size>=15)&
                              (experiment_df$dataset=='TCGA')),]
  df_slice = df_slice[,c('subsample_size','RACT','SY','LC','CLXperm','HC')]
  
  # Given we exclude and XC, only use colors 1,2,3,4
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5))  # Set layout to 2x2
  plt = barplot(as.matrix(t(df_slice[,colnames(df_slice)[-1]])), beside=TRUE, 
                names.arg = df_slice[,'subsample_size'],
                col = color_palette[1:5],yaxt='n',las=1,xaxt='n',ylim=c(0,1.00))
  axis(2, at = c(0, 0.25, 0.50,0.75,1.00), labels = c("0.00", "0.25","0.50", "0.75","1.00"),
       las=1,cex.axis=3,ylim=c(0,1))
  
  text(plt[2,]+.2, adj=0,par("usr")[3] - 0.05, labels = seq(15,50,by=5), srt = 45, pos = 1, xpd = TRUE,cex=3)
  
  # SPINS Type I
  experiment_df[(experiment_df$dataset=='SPINS')&(experiment_df$cov_cor=='cov'),]
  
  # SPINS Power
  
  # Power chart, save as 2400x1200 PNG
  df_slice = experiment_df[((experiment_df$null_flag == 'not_null')&
                              (experiment_df$cov_cor=='cov')&
                              (experiment_df$subsample_size>=15)&
                              (experiment_df$dataset=='SPINS')),]
  df_slice = df_slice[,c('subsample_size','RACT','SYperm','LC','CLX','HC')]
  
  # Given we exclude and XC, only use colors 1,2,3,4
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5))  # Set layout to 2x2
  plt = barplot(as.matrix(t(df_slice[,colnames(df_slice)[-1]])), beside=TRUE, 
                names.arg = df_slice[,'subsample_size'],
                col = color_palette[1:5],yaxt='n',las=1,xaxt='n',ylim=c(0,1.00))
  axis(2, at = c(0, 0.25, 0.50,0.75,1.00), labels = c("0.00", "0.25","0.50", "0.75","1.00"),
       las=1,cex.axis=3,ylim=c(0,1))
  
  text(plt[2,]+.2, adj=0,par("usr")[3] - 0.05, labels = seq(15,50,by=5), srt = 45, pos = 1, xpd = TRUE,cex=3)
  
 
}

#### Frobenius Norm Check ####
frob_check_20241011<-function(){
  K = 100
  B = 100
  k_norms = c(1,5,20)
  subsample_size = 35
  max_k_pct = 0.8
  cov_cor = 'cov'
  
  # Import Data
  setwd(SPINS_PROCESSED_DIR)
  spins_residuals = readRDS('spins_residuals_matrices.rds')
  group_1_residuals = spins_residuals[['GE']]
  group_2_residuals = spins_residuals[['SP']]
  
  test_stat_list = list()
  perm_matrix_list = list()
  
  for(iteration in 1:K){
    set.seed(iteration)
    
    group_1_subsample = group_1_residuals[,sample(1:ncol(group_1_residuals),subsample_size)]
    group_2_subsample = group_2_residuals[,sample(1:ncol(group_2_residuals),subsample_size)]
    
    diff_mat = cov(t(group_1_subsample))-cov(t(group_2_subsample))
    
    max_k = max_k_calculation(cbind(group_1_subsample,group_2_subsample),
                              max_k_pct,
                              cov_cor=cov_cor) 
    
    svd_subsample = sort(RSpectra::svds(diff_mat,k=max(max_k,k_norms),nu=0,nv=0)$d,decreasing=TRUE)
    
    test_stats = c()
    
    for(k in k_norms){
      test_stats = c(test_stats,sum(svd_subsample[1:k]))
    }
    
    test_stats = c(test_stats,sum(diff_mat**2))
    names(test_stats) = c(k_norms,'frob')
    
    combined_data = cbind(group_1_subsample,group_2_subsample)
    perm_matrix = matrix(data=NA,nrow=B,ncol=length(test_stats))
    colnames(perm_matrix) = names(test_stats)
    
    for(b in 1:B){
      set.seed(iteration*B+b)
      perm_order = sample(1:(2*subsample_size))
      group_1_permutation = combined_data[,perm_order[1:subsample_size]]
      group_2_permutation = combined_data[,perm_order[(subsample_size+1):(2*subsample_size)]]
      
      diff_mat = cov(t(group_1_permutation))-cov(t(group_2_permutation))
      
      svd_permutation = sort(RSpectra::svds(diff_mat,k=max(max_k,k_norms),nu=0,nv=0)$d,decreasing=TRUE)
      
      perm_test_stats = c()
      
      for(k in k_norms){
        perm_test_stats = c(perm_test_stats,sum(svd_permutation[1:k]))
      }
      
      perm_test_stats = c(perm_test_stats,sum(diff_mat**2))
      names(perm_test_stats) = c(k_norms,'frob')
      perm_matrix[b,] = perm_test_stats
      
    }
    
    test_stat_list[[iteration]] = test_stats
    perm_matrix_list[[iteration]] = perm_matrix
  }
  

}

#### Try to explain relative performance ####
explain_relative_performance<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'explain_relative_performance'
  
  K=1000         # 1000     
  B=1000         # 1000         
  B_other = 1000 # 1000
  alpha=.05
  max_k_pct=.80
  k_compare = 50 # number of singular values to look at in comparison
  test_stat_prefixes = c('sum')
  
  experiment_df = expand.grid(subsample_size = c(15,20,25,30,35,40,45,50),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov'), 
                              dataset = c('SPINS-FA'),
                              shuffle_dim = c(TRUE,FALSE),
                              stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    # Import Data
    setwd(SPINS_PROCESSED_DIR)
    spins_residuals = readRDS('spins_residuals_matrices_FA.rds')
    group_1_residuals = spins_residuals[['GE']]
    group_2_residuals = spins_residuals[['SP']]
  
    n_group_1 = ncol(group_1_residuals)
    n_group_2 = ncol(group_2_residuals)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df),
                               .errorhandling = 'pass')%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Sample from group 1 and group 2
                                   group_1_subsample = group_1_residuals[,sample(1:n_group_1,subsample_size)]
                                   group_2_subsample = group_2_residuals[,sample(1:n_group_2,subsample_size)]
                                 }else{
                                   # Sample only from group 1
                                   sampled_subjects = sample(1:n_group_1,subsample_size*2)
                                   group_1_subsample = group_1_residuals[,sampled_subjects[1:subsample_size]]
                                   group_2_subsample = group_1_residuals[,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 if(shuffle_dim){
                                   new_dim_order = sample(1:nrow(group_1_residuals))
                                   group_1_subsample = group_1_subsample[new_dim_order,]
                                   group_2_subsample = group_2_subsample[new_dim_order,]
                                 }
                                 
                                 max_k = max_k_calculation(cbind(group_1_subsample,group_2_subsample),
                                                           max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC
                                 set.seed(i)
                                 reject_RACC = test_equality_cov_20240925(group_1_subsample,group_2_subsample,
                                                                          max_k,test_stat_prefixes,B,alpha,
                                                                          cov_cor=cov_cor)[,'all_min_p']
                                 
                                 # Other methods (non permutation)
                                 reject_HC = UTDtst::HC2018(t(group_1_subsample),t(group_2_subsample),alpha = alpha)
                                
                                 # Permutation
                                 other_perm_matrix = matrix(data=NA,ncol=1,nrow=B_other)
                                 colnames(other_perm_matrix) = c('HC')
                                 
                                 set.seed(i)
                                 for(b in 1:B_other){
                                   combined_subsample = cbind(group_1_subsample,group_2_subsample)
                                   permutation_order = sample(1:(subsample_size*2))
                                   group_1_permutation = combined_subsample[,permutation_order[1:subsample_size]]
                                   group_2_permutation = combined_subsample[,permutation_order[(subsample_size+1):(2*subsample_size)]]
                                   
                                   other_perm_matrix[b,'HC'] = min(UTDtst::HC2018(t(group_1_permutation),t(group_2_permutation),alpha = alpha)$pvalues)
                                 }
                                 
                                 print(i)
                                 
                                 return_vec =list(reject_RACC,
                                                  reject_HC,
                                                  other_perm_matrix)
                                 names(return_vec) = c('RACC','HC','permmat')
                                 
                                 return_vec
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

explain_relative_performance_writeup<-function(){
  # New compare methods
  function_name = 'explain_relative_performance'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  method_names = c('HCperm','HC','RACT')
  experiment_df[,method_names] = NA
  alpha = 0.05
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  for(x in 1:nrow(experiment_df)){
    filename = paste(function_name,'-',sprintf("%03d",x),'.RDS',sep='')
    result = readRDS(filename)
    
    reject_matrix = matrix(data=0,nrow=length(result),ncol=3)
    colnames(reject_matrix) = method_names
    
    for(i in 1:length(result)){
      
      if(min(result[[i]]$HC$pvalues) <= quantile(result[[i]]$permmat[,'HC'],alpha)){
        reject_matrix[i,'HCperm']=1
      }
      
      
      reject_matrix[i,'RACT'] = result[[i]]$RACC
      reject_matrix[i,'HC'] = (result[[i]]$HC$reject > 0)*1
      
    }
    
    experiment_df[x,method_names] = apply(reject_matrix,2,mean)
    
    print(x)  
  }
  
  print(experiment_df[experiment_df$null_flag=='not_null',])
  
  # Found effectively no difference when shuffle rows
  table_df = data.frame(subsample_size = unique(experiment_df$subsample_size))
  table_df[,c('HC orig','HC shuffle',
              'HCperm orig','HCperm shuffle',
              'RACT orig','RACT shuffle')] = 0
  table_df[,c('HC orig')] = experiment_df[(experiment_df$null_flag=='not_null')&(experiment_df$shuffle_dim==FALSE),'HC']
  table_df[,c('HC shuffle')] = experiment_df[(experiment_df$null_flag=='not_null')&(experiment_df$shuffle_dim==TRUE),'HC']
  table_df[,c('HCperm orig')] = experiment_df[(experiment_df$null_flag=='not_null')&(experiment_df$shuffle_dim==FALSE),'HCperm']
  table_df[,c('HCperm shuffle')] = experiment_df[(experiment_df$null_flag=='not_null')&(experiment_df$shuffle_dim==TRUE),'HCperm']
  table_df[,c('RACT orig')] = experiment_df[(experiment_df$null_flag=='not_null')&(experiment_df$shuffle_dim==FALSE),'RACT']
  table_df[,c('RACT shuffle')] = experiment_df[(experiment_df$null_flag=='not_null')&(experiment_df$shuffle_dim==TRUE),'RACT']
  
  # Take example for SPINS-FA where power about 0.50 (subsample size 20) and look at p-values
  experiment_number = experiment_df[(experiment_df$subsample_size==20)&(experiment_df$null_flag=='not_null'),]
  shuffled_number = experiment_number[experiment_number$shuffle_dim==TRUE,'experiment_number']
  orig_number = experiment_number[experiment_number$shuffle_dim==FALSE,'experiment_number']
  p_value_list = list()
  
  for(x in c(shuffled_number,orig_number)){
    filename = paste(function_name,'-',sprintf("%03d",x),'.RDS',sep='')
    result = readRDS(filename)
    p_value_vec = c()
    
    for(i in 1:length(result)){
      hcperm_pval = 1-sum(min(result[[i]]$HC$pvalues)<=result[[i]]$permmat[,'HC'])/1000
      p_value_vec = c(p_value_vec,hcperm_pval)
    }
    
    p_value_list[[x]]=p_value_vec
  }
  
  plot(sort(p_value_list[[shuffled_number]]),sort(p_value_list[[orig_number]]),
       ylab='Sorted p values original ordering',xlab='Sorted p values shuffled ordering',
       main='SPINS FA, HC with permutation method \n compare p-values for subsample size 20 \n original dimensions vs shuffled dimensions')
  lines(seq(0,1,by=.1),seq(0,1,by=.1),col='red')
  
  print('Power of HC, HCperm, and RACT when using original dimension ordering or shuffling them. FA data subsample size 20.')
  print(table_df)

}

explain_relative_performance_AR<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'explain_relative_performance_AR'
  
  K=100           # 1000     
  B_other = 100   # 1000
  alpha=.05
  
  p=100
  ar_parameter = 0.5

  experiment_df = expand.grid(shuffle_dim = c(TRUE,FALSE),subsample_size = c(15,20,25,30,35,40,45,50),
                              null_flag = c('not_null'),
                              cov_cor = c('cov'),
                              stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    # Generate data from Identity plus AR(1) vs. identity covariance
    AR_cov_mat = outer(1:p, 1:p, function(i, j) ar_parameter^abs(i - j))
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    #ncores = 6
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df),
                               .errorhandling = 'pass')%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 group_1_subsample=t(MASS::mvrnorm(n=subsample_size,mu=rep(0,p),Sigm=AR_cov_mat,tol=10))
                                 group_2_subsample=t(MASS::mvrnorm(n=subsample_size,mu=rep(0,p),Sigm=diag(1,p),tol=10))
                                 
                                 if(shuffle_dim){
                                   new_dim_order = sample(1:nrow(group_1_subsample))
                                   group_1_subsample = group_1_subsample[new_dim_order,]
                                   group_2_subsample = group_2_subsample[new_dim_order,]
                                 }
                                 
                                 # Other methods (non permutation)
                                 reject_HC = UTDtst::HC2018(t(group_1_subsample),t(group_2_subsample),alpha = alpha)
                                 
                                 # Permutation
                                 other_perm_matrix = matrix(data=NA,ncol=1,nrow=B_other)
                                 colnames(other_perm_matrix) = c('HC')
                                 
                                 set.seed(i)
                                 for(b in 1:B_other){
                                   combined_subsample = cbind(group_1_subsample,group_2_subsample)
                                   permutation_order = sample(1:(subsample_size*2))
                                   group_1_permutation = combined_subsample[,permutation_order[1:subsample_size]]
                                   group_2_permutation = combined_subsample[,permutation_order[(subsample_size+1):(2*subsample_size)]]
                                   
                                   other_perm_matrix[b,'HC'] = min(UTDtst::HC2018(t(group_1_permutation),t(group_2_permutation),alpha = alpha)$pvalues)
                                 }
                                 
                                 print(i)
                                 
                                 return_vec =list(reject_HC,
                                                  other_perm_matrix)
                                 names(return_vec) = c('HC','permmat')
                                 
                                 return_vec
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

explain_relative_performance_AR_writeup<-function(){
  # New compare methods
  function_name = 'explain_relative_performance_AR'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv') 
  
  experiment_number = experiment_df[(experiment_df$subsample_size==20)&(experiment_df$null_flag=='not_null'),]
  shuffled_number = 15 #experiment_number[experiment_number$shuffle_dim==TRUE,'experiment_number']
  orig_number = 16 #experiment_number[experiment_number$shuffle_dim==FALSE,'experiment_number']
  p_value_list = list()
  
  for(x in c(shuffled_number,orig_number)){
    filename = paste(function_name,'-',sprintf("%03d",x),'.RDS',sep='')
    result = readRDS(filename)
    p_value_vec = c()
    
    for(i in 1:length(result)){
      hcperm_pval = 1-sum(min(result[[i]]$HC$pvalues)<=result[[i]]$permmat[,'HC'])/nrow(result[[1]]$permmat)
      p_value_vec = c(p_value_vec,hcperm_pval)
    }
    
    p_value_list[[x]]=p_value_vec
  }
  
  plot(sort(p_value_list[[shuffled_number]]),sort(p_value_list[[orig_number]]),
       ylab='Sorted p values original ordering',xlab='Sorted p values shuffled ordering',
       main='SPINS FA, HC with permutation method \n compare p-values for subsample size 20 \n original dimensions vs shuffled dimensions')
  lines(seq(0,1,by=.1),seq(0,1,by=.1),col='red')
  
  
}

explain_relative_performance_AR_vary<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'explain_relative_performance_AR_vary'
  
  K=100           # 1000     
  B_other = 100   # 1000
  alpha=.05
  
  p=100

  experiment_df = expand.grid(shuffle_dim = c(TRUE,FALSE),subsample_size = c(20),
                              ar_parameter=c(.01,.05,.1,.25,.33,.5),
                              null_flag = c('not_null'),
                              cov_cor = c('cov'),
                              stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    # Generate data from Identity plus AR(1) vs. identity covariance
    AR_cov_mat = outer(1:p, 1:p, function(i, j) ar_parameter^abs(i - j))
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    #ncores = 6
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df),
                               .errorhandling = 'pass')%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 group_1_subsample=t(MASS::mvrnorm(n=subsample_size,mu=rep(0,p),Sigm=AR_cov_mat,tol=10))
                                 group_2_subsample=t(MASS::mvrnorm(n=subsample_size,mu=rep(0,p),Sigm=diag(1,p),tol=10))
                                 
                                 if(shuffle_dim){
                                   new_dim_order = sample(1:nrow(group_1_subsample))
                                   group_1_subsample = group_1_subsample[new_dim_order,]
                                   group_2_subsample = group_2_subsample[new_dim_order,]
                                 }
                                 
                                 # Other methods (non permutation)
                                 reject_HC = UTDtst::HC2018(t(group_1_subsample),t(group_2_subsample),alpha = alpha)
                                 
                                 # Permutation
                                 other_perm_matrix = matrix(data=NA,ncol=1,nrow=B_other)
                                 colnames(other_perm_matrix) = c('HC')
                                 
                                 set.seed(i)
                                 for(b in 1:B_other){
                                   combined_subsample = cbind(group_1_subsample,group_2_subsample)
                                   permutation_order = sample(1:(subsample_size*2))
                                   group_1_permutation = combined_subsample[,permutation_order[1:subsample_size]]
                                   group_2_permutation = combined_subsample[,permutation_order[(subsample_size+1):(2*subsample_size)]]
                                   
                                   other_perm_matrix[b,'HC'] = min(UTDtst::HC2018(t(group_1_permutation),t(group_2_permutation),alpha = alpha)$pvalues)
                                 }
                                 
                                 print(i)
                                 
                                 return_vec =list(reject_HC,
                                                  other_perm_matrix)
                                 names(return_vec) = c('HC','permmat')
                                 
                                 return_vec
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

explain_relative_performance_AR_vary_writeup<-function(){
  # New compare methods
  function_name = 'explain_relative_performance_AR_vary'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv') 
  experiment_df[,'mean_p'] = 999
  
  
  p_value_list = list()
  
  for(x in 1:nrow(experiment_df)){
    filename = paste(function_name,'-',sprintf("%03d",x),'.RDS',sep='')
    result = readRDS(filename)
    p_value_vec = c()
    
    for(i in 1:length(result)){
      hcperm_pval = 1-sum(min(result[[i]]$HC$pvalues)<=result[[i]]$permmat[,'HC'])/nrow(result[[1]]$permmat)
      p_value_vec = c(p_value_vec,hcperm_pval)
    }
    
    p_value_list[[x]]=p_value_vec
    
    experiment_df[x,'mean_p'] = mean(p_value_vec)
    
  }
  
  plot(sort(p_value_list[[7]]),sort(p_value_list[[8]]),
       ylab='Sorted p values original ordering',xlab='Sorted p values shuffled ordering',
       main='Simulated Data - AR(1), phi=0.25, covariance structure \n compare p-values for subsample size 20 \n original dimensions vs shuffled dimensions')
  lines(seq(0,1,by=.1),seq(0,1,by=.1),col='red')
  
  print('mean p-value for HCperm when shuffling dimensions vs. when difference in covariance caused by an AR structure.')
  print(experiment_df[,c('shuffle_dim','ar_parameter','mean_p')])
  
}


#### FINAL SIMS ####
real_data_sims<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'real_data_sims'
  
  K=1000    # 1000     
  B=1000    # 1000         
  alpha=.05
  max_k_pct=.80
  k_compare = 50 # number of singular values to look at in comparison
  test_stat_prefixes = c('sum')
  
  experiment_df = expand.grid(subsample_size = c(15,20,25,30,35,40,45,50),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov','cor'), 
                              dataset = c('TCGA','SPINS-FA','SPINS-MD'),
                              stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    # Based on which dataset we are analyzing, import both groups from the appropriate dataset
    if(dataset=='TCGA'){
      setwd(WORKING_DIR)  
      gene_expression_residuals = readRDS('tcga_residual_matrices.rds')
      group_1_residuals = gene_expression_residuals[['TCGA-LUAD']]
      group_2_residuals = gene_expression_residuals[['TCGA-LUSC']]
    }else if(dataset=='SPINS-FA'){
      # Import Data
      setwd(SPINS_PROCESSED_DIR)
      spins_residuals = readRDS('spins_residuals_matrices_FA.rds')
      group_1_residuals = spins_residuals[['GE']]
      group_2_residuals = spins_residuals[['SP']]
    }else if(dataset=='SPINS-MD'){
      # Import Data
      setwd(SPINS_PROCESSED_DIR)
      spins_residuals = readRDS('spins_residuals_matrices_MD.rds')
      group_1_residuals = spins_residuals[['GE']]
      group_2_residuals = spins_residuals[['SP']]
    }
    
    n_group_1 = ncol(group_1_residuals)
    n_group_2 = ncol(group_2_residuals)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select LUAD, and LUSC subjects
                                   group_1_subsample = group_1_residuals[,sample(1:n_group_1,subsample_size)]
                                   group_2_subsample = group_2_residuals[,sample(1:n_group_2,subsample_size)]
                                 }else{
                                   # Sample only from LUAD subjects
                                   sampled_subjects = sample(1:n_group_1,subsample_size*2)
                                   group_1_subsample = group_1_residuals[,sampled_subjects[1:subsample_size]]
                                   group_2_subsample = group_1_residuals[,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 max_k = max_k_calculation(cbind(group_1_subsample,group_2_subsample),
                                                           max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(i)
                                 reject_matrix_RACC = test_equality_cov_20240925(group_1_subsample,group_2_subsample,
                                                                                 max_k,test_stat_prefixes,B,alpha,
                                                                                 cov_cor=cov_cor)
                                 
                                 # Run RACC using k_compare singular values
                                 set.seed(i)
                                 reject_matrix_k_compare = test_equality_cov_20240925(group_1_subsample,group_2_subsample,
                                                                                      min(k_compare,2*subsample_size),
                                                                                      test_stat_prefixes,B,alpha,
                                                                                      cov_cor = cov_cor)
                                 
                                 print(i)
                                 
                                 list(reject_matrix_RACC,reject_matrix_k_compare)
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

real_data_compare<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'real_data_compare'
  
  K=1000        # 1000     
  B=1000         # 1000         
  B_other = 1000 # 1000
  alpha=.05
  max_k_pct=.80
  k_compare = 50 # number of singular values to look at in comparison
  test_stat_prefixes = c('sum')
  
  experiment_df = expand.grid(subsample_size = c(15,20,25,30,35,40,45,50),
                              null_flag = c('null','not_null'),
                              cov_cor = c('cov','cor'), 
                              dataset = c('TCGA','SPINS-FA','SPINS-MD'),
                              stringsAsFactors = FALSE)
  experiment_df$experiment_number = 1:nrow(experiment_df)
  
  # Import Data
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    # Based on which dataset we are analyzing, import both groups from the appropriate dataset
    if(dataset=='TCGA'){
      setwd(WORKING_DIR)  
      gene_expression_residuals = readRDS('tcga_residual_matrices.rds')
      group_1_residuals = gene_expression_residuals[['TCGA-LUAD']]
      group_2_residuals = gene_expression_residuals[['TCGA-LUSC']]
    }else if(dataset=='SPINS-FA'){
      # Import Data
      setwd(SPINS_PROCESSED_DIR)
      spins_residuals = readRDS('spins_residuals_matrices_FA.rds')
      group_1_residuals = spins_residuals[['GE']]
      group_2_residuals = spins_residuals[['SP']]
    }else if(dataset=='SPINS-MD'){
      # Import Data
      setwd(SPINS_PROCESSED_DIR)
      spins_residuals = readRDS('spins_residuals_matrices_MD.rds')
      group_1_residuals = spins_residuals[['GE']]
      group_2_residuals = spins_residuals[['SP']]
    }
    
    n_group_1 = ncol(group_1_residuals)
    n_group_2 = ncol(group_2_residuals)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df),
                               .errorhandling = 'pass')%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 
                                 set.seed(i)
                                 
                                 if(null_flag=='not_null'){
                                   # Select LUAD, and LUSC subjects
                                   group_1_subsample = group_1_residuals[,sample(1:n_group_1,subsample_size)]
                                   group_2_subsample = group_2_residuals[,sample(1:n_group_2,subsample_size)]
                                 }else{
                                   # Sample only from LUAD subjects
                                   sampled_subjects = sample(1:n_group_1,subsample_size*2)
                                   group_1_subsample = group_1_residuals[,sampled_subjects[1:subsample_size]]
                                   group_2_subsample = group_1_residuals[,sampled_subjects[(subsample_size+1):(2*subsample_size)]]
                                 }
                                 
                                 max_k = max_k_calculation(cbind(group_1_subsample,group_2_subsample),
                                                           max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC
                                 set.seed(i)
                                 reject_RACC = test_equality_cov_20240925(group_1_subsample,group_2_subsample,
                                                                          max_k,test_stat_prefixes,B,alpha,
                                                                          cov_cor=cov_cor)[,'all_min_p']
                                 
                                 # Other methods (non permutation)
                                 reject_SY = UTDtst::SY2010(t(group_1_subsample),t(group_2_subsample))
                                 reject_LC = UTDtst::LC2012(t(group_1_subsample),t(group_2_subsample))
                                 reject_CLX = UTDtst::CLX2013(t(group_1_subsample),t(group_2_subsample))
                                 reject_HC = UTDtst::HC2018(t(group_1_subsample),t(group_2_subsample),alpha = alpha)
                                 reject_XC <- tryCatch({
                                   # XC seems to struggle with small n
                                   UTDtst::TwoSampleTest(t(group_1_subsample),t(group_2_subsample),
                                                         k=100,alpha=alpha)
                                 }, error = function(e) {
                                   list(decision=999)  # Return 999 if there is an error
                                 })
                                 
                                 # Permutation
                                 other_perm_matrix = matrix(data=NA,ncol=4,nrow=B_other)
                                 colnames(other_perm_matrix) = c('SY','LC','CLX','HC')
                                 
                                 set.seed(i)
                                 for(b in 1:B_other){
                                   combined_subsample = cbind(group_1_subsample,group_2_subsample)
                                   permutation_order = sample(1:(subsample_size*2))
                                   group_1_permutation = combined_subsample[,permutation_order[1:subsample_size]]
                                   group_2_permutation = combined_subsample[,permutation_order[(subsample_size+1):(2*subsample_size)]]
                                   
                                   other_perm_matrix[b,'SY'] = UTDtst::SY2010(t(group_1_permutation),t(group_2_permutation))$Q2
                                   other_perm_matrix[b,'LC'] = UTDtst::LC2012(t(group_1_permutation),t(group_2_permutation))$statistic
                                   other_perm_matrix[b,'CLX'] = UTDtst::CLX2013(t(group_1_permutation),t(group_2_permutation))$TSvalue
                                   other_perm_matrix[b,'HC'] = min(UTDtst::HC2018(t(group_1_permutation),t(group_2_permutation),alpha = alpha)$pvalues)
                                 }
                                 
                                 print(i)
                                 
                                 return_vec =list(reject_RACC,
                                                  reject_SY,
                                                  reject_LC,
                                                  reject_CLX,
                                                  reject_HC,
                                                  reject_XC,
                                                  other_perm_matrix)
                                 names(return_vec) = c('RACC','SY','LC','CLX','HC','XC','permmat')
                                 
                                 return_vec
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

# Type I Error Control
simulated_type_1<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'simulated_type_1'
  
  K=10000     
  B=2000          
  alpha=.05
  max_k_pct=.80
  test_stat_prefixes = c('sum')
  
  experiment_df=expand.grid(snr=c(1),
                            cov_rank=c(2,5),
                            cov_structure=c('(LowRank)','(LowRankBlockSmall)','(LowRankBlockLarge)','(OffDiagonal)'),
                            n=c(50),
                            p=c(250),
                            cov_cor=c('cov','cor'),
                            stringsAsFactors=FALSE)
  
  # Only need OffDiagonal for one rank, make its snr = 0.5
  experiment_df=experiment_df[!((experiment_df$cov_structure=='(OffDiagonal)')&(experiment_df$cov_rank==5)),]
  experiment_df[experiment_df$cov_structure=='(OffDiagonal)','snr']=.5
  
  experiment_df=experiment_df[order(experiment_df$cov_structure,experiment_df$cov_rank),]
  experiment_df$initial_seed=as.numeric(rownames(experiment_df))*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 cov_matrix=generate_covariance_matrix(cov_structure,snr,p,cov_rank)[[1]]
                                 x_matrix=t(MASS::mvrnorm(n=n,mu=rep(0,p),Sigm=cov_matrix))
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 reject_matrix = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                            max_k,test_stat_prefixes,B,alpha,
                                                                            cov_cor = cov_cor)
                                 
                                 reject_matrix
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

simulated_type_1_writeup<-function(){
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  # COMPARE TYPE I AND POWER ACROSS METHODS
  function_name = 'simulated_type_1'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  
  # Get column names where we predefine k and add them as columns
  filename=paste(function_name,'-',sprintf("%03d",nrow(experiment_df)),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  result_colnames = colnames(experiment_result[[1]][[2]])
  experiment_df[,result_colnames] = 999
  experiment_df[,'RACT'] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    K = length(experiment_result)
    rejects = 0
    
    for(k in 1:K){
      rejects = rejects + experiment_result[[k]][,'all_min_p']
    }
    
    experiment_df[experiment_number,'RACT'] = rejects/K
  }

  print(min(experiment_df[,'RACT']))
  print(max(experiment_df[,'RACT']))
  
}


simulated_power<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'simulated_power'
  
  K=1000     
  B=1000          
  alpha=.05
  max_k_pct=.80
  k_compare = 50 # number of singular values to look at
  test_stat_prefixes = c('sum')
  
  experiment_df_1=expand.grid(n=50,p=250,snr=seq(0,.03,length.out=15),
                              cov_rank=2,cov_structure='(LowRank)',seed_init=1,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_2=expand.grid(n=50,p=250,snr=seq(0,.02,length.out=15),
                              cov_rank=5,cov_structure='(LowRank)',seed_init=2,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_3=expand.grid(n=50,p=250,snr=seq(0,25,length.out=15),
                              cov_rank=2,cov_structure='(LowRankBlockSmall)',seed_init=3,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_4=expand.grid(n=50,p=250,snr=seq(0,25,length.out=15),
                              cov_rank=5,cov_structure='(LowRankBlockSmall)',seed_init=4,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_5=expand.grid(n=50,p=250,snr=seq(0,.75,length.out=15),
                              cov_rank=2,cov_structure='(LowRankBlockLarge)',seed_init=5,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_6=expand.grid(n=50,p=250,snr=seq(0,.75,length.out=15),
                              cov_rank=5,cov_structure='(LowRankBlockLarge)',seed_init=6,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_7=expand.grid(n=50,p=250,snr=seq(0,.12,length.out=15),
                              cov_rank=2,cov_structure='(OffDiagonal)',seed_init=7,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  
  experiment_df=rbind(experiment_df_1,experiment_df_2,experiment_df_3,experiment_df_4,
                      experiment_df_5,experiment_df_6,experiment_df_7)
  
  experiment_df$initial_seed=(experiment_df$seed_init*100+experiment_df$cov_rank)*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 
                                 cov_mats=generate_covariance_matrix(cov_structure,snr,p,cov_rank)
                                 cov_matrix_1=cov_mats[[1]]
                                 cov_matrix_2=cov_mats[[2]]
                                 
                                 first_half_n=round(n/2)
                                 second_half_n=n-first_half_n
                                 
                                 X_1=t(MASS::mvrnorm(n=first_half_n,mu=rep(0,p),Sigm=cov_matrix_1,tol=10))
                                 X_2=t(MASS::mvrnorm(n=second_half_n,mu=rep(0,p),Sigm=cov_matrix_2,tol=10))
                                 x_matrix=cbind(X_1,X_2)
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # Run RACC using 80% sum singular values
                                 set.seed(initial_seed+i)
                                 reject_matrix_RACC = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                 max_k,test_stat_prefixes,B,alpha,
                                                                                 cov_cor=cov_cor)
                                 
                                 # Run RACC using k_compare singular values
                                 set.seed(initial_seed+i)
                                 reject_matrix_k_compare = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                                      k_compare,test_stat_prefixes,B,alpha,
                                                                                      cov_cor = cov_cor)
                                 
                                 
                                 list(reject_matrix_RACC,reject_matrix_k_compare)
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

simulated_power_writeup<-function(){
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  # COMPARE TYPE I AND POWER ACROSS METHODS
  function_name = 'simulated_power'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  
  # Get column names where we predefine k and add them as columns
  filename=paste(function_name,'-',sprintf("%03d",nrow(experiment_df)),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  result_colnames = colnames(experiment_result[[1]][[2]])
  experiment_df[,result_colnames] = 999
  experiment_df[,'RACT'] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    result_colnames = colnames(experiment_result[[experiment_number]][[2]])
    K = length(experiment_result)
    
    experiment_df[experiment_number,result_colnames] = Reduce('+',lapply(experiment_result, function(x) x[[2]]))/K
    
    # Extract results when using RACT (which will select K differently)
    ract_result = 0
    for(j in 1:K){
      ract_result = ract_result + experiment_result[[j]][[1]][,'all_min_p']
    }
    experiment_df[experiment_number,'RACT'] = ract_result/K
    
  }
  
  norms_to_plot=c('RACT','sum_1','sum_4','sum_10','sum_25')
  norms_to_plot_name=c('RACT','Operator','KF-4','KF-10','KF-25')
  
  # EACH PLOT SAVE AS 300X600
  point_cex=2
  text_size=2
  
  cov_slice = experiment_df[experiment_df$cov_cor=='cov',]
  
  for(n in unique(cov_slice$n)){
    n_slice=cov_slice[cov_slice$n==n,]
    for(cov_structure in unique(experiment_df$cov_structure)){
      cov_structure_slice=n_slice[n_slice$cov_structure==cov_structure,]
      
      for(cov_rank in sort(unique(cov_structure_slice$cov_rank))){
        experiment_df_slice=cov_structure_slice[cov_structure_slice$cov_rank==cov_rank,]
        p=experiment_df_slice$p[1]
        
        # Plot 1
        x=unique(experiment_df_slice$snr)
        
        if(cov_structure=='(OffDiagonal)'){
          plotname=paste(cov_structure,'\n',' n=',n,' p=',p,sep='')
        }else{
          plotname=paste(cov_structure,'\n','w=',cov_rank,' n=',n,' p=',p,sep='')
        }
        
        par(mfrow=c(1,1),mar=c(2.5,4,1,1.5),mgp = c(3, 1.5, 0))
        plot(x=x,
             y=experiment_df_slice[,norms_to_plot[1]],
             col=color_palette[1],ylim=c(0,1),type='p',pch=15,
             cex.main=text_size,cex.lab=text_size,cex.axis=text_size,
             cex=point_cex,main='',xlab='',ylab='',las=1)
        lines(x=x,
              y=experiment_df_slice[,norms_to_plot[1]],
              col=color_palette[1],type='l',pch=15,cex=point_cex) 
        
        for(i in 2:5){
          lines(x=x,
                y=experiment_df_slice[,norms_to_plot[i]],
                col=color_palette[i],type='p',pch=15,cex=point_cex) 
        }
        
        if(cov_structure=='(OffDiagonal)'){
          lines(x=x,
                y=experiment_df_slice[experiment_df_slice$norm_param==norms_to_plot[1],'power'],
                col=color_palette[1],type='p',pch=15,cex=point_cex,las=1)
        }
        
        abline(h=.05,lty=2)
        
        print(paste(cov_structure,cov_rank)) 
      }
      
    }
    
    
  }
  
  # LowRankBlocKSmall w=5
  # When power ~50% for RACT
  experiment_number = 97
  filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  
  K_vec = c()
  
  for(i in 1:length(experiment_result)){
    norms_used = colnames(experiment_result[[i]][[1]])
    K = norms_used[length(norms_used)-2]
    K = as.numeric(strsplit(K,'_')[[1]][2])

    K_vec = c(K_vec,K)    
  }
  
  print(mean(K_vec))
  
  # LowRankBlocKLarge w=2
  # When power ~50% for RACT
  # Experiment number = 126
  experiment_number = 126
  filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  
  K_vec = c()
  
  for(i in 1:length(experiment_result)){
    norms_used = colnames(experiment_result[[i]][[1]])
    K = norms_used[length(norms_used)-2]
    K = as.numeric(strsplit(K,'_')[[1]][2])
    
    K_vec = c(K_vec,K)    
  }
  
  print(mean(K_vec))
  
  # LowRankBlocKLarge w=2
  # When power ~50% for RACT
  # Experiment number = 157
  experiment_number = 157
  filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  
  K_vec = c()
  
  for(i in 1:length(experiment_result)){
    norms_used = colnames(experiment_result[[i]][[1]])
    K = norms_used[length(norms_used)-2]
    K = as.numeric(strsplit(K,'_')[[1]][2])
    
    K_vec = c(K_vec,K)    
  }
  
  print(mean(K_vec))
  
  
}

simulated_compare_type_1<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  # For n=100 p=1000 covariance case 5mins per sim using B=2000
  
  function_name = 'simulated_compare_type_1'
  
  total_K = 10000   # 10000 for final
  K=1000            # 2000 K per experiment (so compute not too large)     
  B=2000            # 2000
  alpha=.05
  max_k_pct=.80
  
  test_stat_prefixes = c('sum')
  
  experiment_df=expand.grid(snr=c(1),
                            cov_rank=c(2,5),
                            cov_structure=c('(LowRank)','(LowRankBlockSmall)','(LowRankBlockLarge)','(OffDiagonal)'),
                            n=c(50),
                            p=c(250),
                            cov_cor=c('cov','cor'),
                            stringsAsFactors=FALSE)
  
  experiment_df_vary_n_p=expand.grid(snr=c(1),cov_rank=c(2,5),cov_structure=c('(LowRank)'),
                                     n=c(50,100),
                                     p=c(25,250,1000),
                                     cov_cor=c('cov','cor'),
                                     stringsAsFactors=FALSE)
  
  # Only need OffDiagonal for one rank, make its snr = 0.5
  experiment_df=experiment_df[!((experiment_df$cov_structure=='(OffDiagonal)')&(experiment_df$cov_rank==5)),]
  experiment_df[experiment_df$cov_structure=='(OffDiagonal)','snr']=.5
  
  
  # Create total_K/K copies of the dataframe
  experiment_df = do.call(rbind, replicate(total_K/K, experiment_df, simplify = FALSE))
  experiment_df_vary_n_p = do.call(rbind, replicate(total_K/K, experiment_df_vary_n_p, simplify = FALSE))
  
  experiment_df=experiment_df[order(experiment_df$cov_structure,experiment_df$cov_rank),]
  experiment_df_vary_n_p=experiment_df_vary_n_p[order(experiment_df_vary_n_p$cov_structure,
                                                      experiment_df_vary_n_p$cov_rank,
                                                      experiment_df_vary_n_p$n,
                                                      experiment_df_vary_n_p$p),]
  
  experiment_df=rbind(experiment_df,experiment_df_vary_n_p)
  
  experiment_df$experiment_number=1:nrow(experiment_df)
  rownames(experiment_df) = experiment_df$experiment_number
  experiment_df$initial_seed=as.numeric(rownames(experiment_df))*1000000
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 cov_matrix=generate_covariance_matrix(cov_structure,snr,p,cov_rank)[[1]]
                                 x_matrix=t(MASS::mvrnorm(n=n,mu=rep(0,p),Sigm=cov_matrix))
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 # avoid low probability situation where testing very large p and max_k
                                 # becomes far too big to compute in reasonable time
                                 if(p==1000){max_k=min(max_k,50)}
                                 
                                 reject_RACT = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                          max_k,test_stat_prefixes,B,alpha,
                                                                          cov_cor = cov_cor)
                                 
                                 # Other methods (non permutation)
                                 reject_SY = UTDtst::SY2010(t(group_1_residuals),t(group_2_residuals))
                                 reject_LC = UTDtst::LC2012(t(group_1_residuals),t(group_2_residuals))
                                 reject_CLX = UTDtst::CLX2013(t(group_1_residuals),t(group_2_residuals))
                                 reject_HC = UTDtst::HC2018(t(group_1_residuals),t(group_2_residuals),alpha = alpha)
                                 reject_XC <- tryCatch({
                                   # XC seems to struggle with small n
                                   UTDtst::TwoSampleTest(t(group_1_residuals),t(group_2_residuals),
                                                         k=100,alpha=alpha)
                                 }, error = function(e) {
                                   list(decision=999)  # Return 999 if there is an error
                                 })
                                 
                                 print(i)
                                 print(Sys.time())
                                 
                                 return_vec =list(reject_RACT,
                                                  reject_SY,
                                                  reject_LC,
                                                  reject_CLX,
                                                  reject_HC,
                                                  reject_XC)
                                 names(return_vec) = c('RACT','SY','LC','CLX','HC','XC')
                                 
                                 return_vec
                                 
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

simulated_compare_type_1_writeup<-function(){
  K_total = 10000
  K=1000
  
  # New compare methods
  function_name = 'simulated_compare_type_1'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  method_names = c('SY','LC','CLX','HC','RACT','XC')
  experiment_df[,method_names] = NA
  alpha = 0.05
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  for(x in 1:nrow(experiment_df)){
    filename = paste(function_name,'-',sprintf("%03d",x),'.RDS',sep='')
    result = readRDS(filename)
    
    reject_matrix = matrix(data=0,nrow=length(result),ncol=6)
    colnames(reject_matrix) = method_names
    
    for(i in 1:length(result)){
      reject_matrix[i,'RACT'] = result[[i]]$RACT[,'all_min_p']
      reject_matrix[i,'XC'] = result[[i]]$XC$decision
      reject_matrix[i,'SY'] = (result[[i]]$SY$pvalue <= alpha)*1
      reject_matrix[i,'LC'] = (result[[i]]$LC$pvalue <= alpha)*1
      reject_matrix[i,'CLX'] = (result[[i]]$CLX$pvalue <= alpha)*1
      reject_matrix[i,'HC'] = (result[[i]]$HC$reject > 0)*1
      
    }
    
    experiment_df[x,method_names] = apply(reject_matrix,2,mean)
    
    print(x)  
  }
  
  type_1_df = unique(experiment_df[,c('snr','cov_rank','cov_structure','n','p','cov_cor')])
  type_1_df[,c('RACT','XC','SY','LC','CLX','HC')] = 999
  
  for(x in 1:nrow(type_1_df)){
    experiment_df_slice = experiment_df[((experiment_df$snr == type_1_df[x,'snr'])&
                                         (experiment_df$cov_rank == type_1_df[x,'cov_rank'])&
                                         (experiment_df$cov_structure == type_1_df[x,'cov_structure'])&
                                         (experiment_df$n == type_1_df[x,'n'])&
                                         (experiment_df$p == type_1_df[x,'p'])&
                                         (experiment_df$cov_cor == type_1_df[x,'cov_cor'])),]
    
    # for cases where same sim was run twice (due to running extra simulations to explore change in n,p)
    experiment_df_slice = experiment_df_slice[1:(K_total/K),]
    
    type_1_df[x,c('RACT','XC','SY','LC','CLX','HC')] = colMeans(experiment_df_slice[,c('RACT','XC','SY','LC','CLX','HC')])
  }
  
  type_1_df_1 = type_1_df[(type_1_df$cov_cor == 'cov')&(type_1_df$p==250)&(type_1_df$n==50),
                        !names(type_1_df) %in% c('cov_cor')]
  type_1_df_1 = type_1_df_1[,c('cov_structure','cov_rank','snr','n','p','XC','SY','CLX','LC','HC','RACT')]
  
  type_1_df_2 = type_1_df[(type_1_df$cov_cor == 'cov')&(type_1_df$cov_rank==2)&(type_1_df$cov_structure=='(LowRank)'),
                          !names(type_1_df) %in% c('cov_cor')]
  type_1_df_2 = type_1_df_2[order(type_1_df_2$n,type_1_df_2$p),c('cov_structure','cov_rank','snr','n','p','XC','SY','CLX','LC','HC','RACT')]
  
  
  print(xtable(rbind(type_1_df_1,type_1_df_2),digits=c(0,0,0,2,0,0,3,3,3,3,3,3)),include.rownames=FALSE)
  
  
  
}

simulated_compare_power<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'simulated_compare_power'
  
  K=1000 # 1000     
  B=1000 # 1000
  B_other = 1000 # 1000
  alpha=.05
  max_k_pct=.80
  test_stat_prefixes = c('sum')
  
  experiment_df_1=expand.grid(n=50,p=250,snr=seq(0,.03,length.out=15),
                              cov_rank=2,cov_structure='(LowRank)',seed_init=1,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_2=expand.grid(n=50,p=250,snr=seq(0,.02,length.out=15),
                              cov_rank=5,cov_structure='(LowRank)',seed_init=2,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_3=expand.grid(n=50,p=250,snr=seq(0,25,length.out=15),
                              cov_rank=2,cov_structure='(LowRankBlockSmall)',seed_init=3,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_4=expand.grid(n=50,p=250,snr=seq(0,25,length.out=15),
                              cov_rank=5,cov_structure='(LowRankBlockSmall)',seed_init=4,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_5=expand.grid(n=50,p=250,snr=seq(0,.75,length.out=15),
                              cov_rank=2,cov_structure='(LowRankBlockLarge)',seed_init=5,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_6=expand.grid(n=50,p=250,snr=seq(0,.75,length.out=15),
                              cov_rank=5,cov_structure='(LowRankBlockLarge)',seed_init=6,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  experiment_df_7=expand.grid(n=50,p=250,snr=seq(0,.12,length.out=15),
                              cov_rank=2,cov_structure='(OffDiagonal)',seed_init=7,cov_cor=c('cov','cor'),
                              stringsAsFactors = FALSE)
  
  experiment_df=rbind(experiment_df_1,experiment_df_2,experiment_df_3,experiment_df_4,
                      experiment_df_5,experiment_df_6,experiment_df_7)
  
  experiment_df$initial_seed=(experiment_df$seed_init*100+experiment_df$cov_rank)*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 
                                 cov_mats=generate_covariance_matrix(cov_structure,snr,p,cov_rank)
                                 cov_matrix_1=cov_mats[[1]]
                                 cov_matrix_2=cov_mats[[2]]
                                 
                                 first_half_n=round(n/2)
                                 second_half_n=n-first_half_n
                                 
                                 X_1=t(MASS::mvrnorm(n=first_half_n,mu=rep(0,p),Sigm=cov_matrix_1,tol=10))
                                 X_2=t(MASS::mvrnorm(n=second_half_n,mu=rep(0,p),Sigm=cov_matrix_2,tol=10))
                                 x_matrix=cbind(X_1,X_2)
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 reject_RACT = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                          max_k,test_stat_prefixes,B,alpha,
                                                                          cov_cor = cov_cor)
                                 
                                 # Other methods (non permutation)
                                 reject_SY = UTDtst::SY2010(t(group_1_residuals),t(group_2_residuals))
                                 reject_LC = UTDtst::LC2012(t(group_1_residuals),t(group_2_residuals))
                                 reject_CLX = UTDtst::CLX2013(t(group_1_residuals),t(group_2_residuals))
                                 reject_HC = UTDtst::HC2018(t(group_1_residuals),t(group_2_residuals),alpha = alpha)
                                 reject_XC <- tryCatch({
                                   # XC seems to struggle with small n
                                   UTDtst::TwoSampleTest(t(group_1_residuals),t(group_2_residuals),
                                                         k=100,alpha=alpha)
                                 }, error = function(e) {
                                   list(decision=999)  # Return 999 if there is an error
                                 })
                                 
                                 # Permutation
                                 other_perm_matrix = matrix(data=NA,ncol=4,nrow=B_other)
                                 colnames(other_perm_matrix) = c('SY','LC','CLX','HC')
                                 
                                 set.seed(initial_seed+i)
                                 for(b in 1:B_other){
                                   combined_residuals = cbind(group_1_residuals,group_2_residuals)
                                   permutation_order = sample(1:n)
                                   group_1_permutation = combined_residuals[,permutation_order[1:(n/2)]]
                                   group_2_permutation = combined_residuals[,permutation_order[(n/2+1):(n)]]
                                   
                                   other_perm_matrix[b,'SY'] = UTDtst::SY2010(t(group_1_permutation),t(group_2_permutation))$Q2
                                   other_perm_matrix[b,'LC'] = UTDtst::LC2012(t(group_1_permutation),t(group_2_permutation))$statistic
                                   other_perm_matrix[b,'CLX'] = UTDtst::CLX2013(t(group_1_permutation),t(group_2_permutation))$TSvalue
                                   other_perm_matrix[b,'HC'] = min(UTDtst::HC2018(t(group_1_permutation),t(group_2_permutation),alpha = alpha)$pvalues)
                                 }
                                 
                                 print(i)
                                 print(Sys.time())
                                 
                                 return_vec =list(reject_RACT,
                                                  reject_SY,
                                                  reject_LC,
                                                  reject_CLX,
                                                  reject_HC,
                                                  reject_XC,
                                                  other_perm_matrix)
                                 names(return_vec) = c('RACT','SY','LC','CLX','HC','XC','permmat')
                                 
                                 return_vec
                                 
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

simulated_compare_power_writeup<-function(){
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  # COMPARE TYPE I AND POWER ACROSS METHODS
  function_name = 'simulated_compare_power'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  method_names = c('SYperm','LCperm','CLXperm','HCperm','SY','LC','CLX','HC','RACT','XC')
  experiment_df[,method_names] = NA
  alpha = 0.05
  
  for(x in 1:nrow(experiment_df)){
    filename = paste(function_name,'-',sprintf("%03d",x),'.RDS',sep='')
    result = readRDS(filename)
    
    reject_matrix = matrix(data=0,nrow=length(result),ncol=10)
    colnames(reject_matrix) = method_names
    
    for(i in 1:length(result)){
      
      if(result[[i]]$SY$Q2 <= quantile(result[[i]]$permmat[,'SY'],alpha/2)){
        reject_matrix[i,'SYperm']=1
      }
      
      if(result[[i]]$SY$Q2 >= quantile(result[[i]]$permmat[,'SY'],1-alpha/2)){
        reject_matrix[i,'SYperm']=1
      }
      
      if(result[[i]]$LC$statistic >= quantile(result[[i]]$permmat[,'LC'],1-alpha)){
        reject_matrix[i,'LCperm']=1
      }
      
      if(result[[i]]$CLX$TSvalue >= quantile(result[[i]]$permmat[,'CLX'],1-alpha)){
        reject_matrix[i,'CLXperm']=1
      }
      
      if(min(result[[i]]$HC$pvalues) <= quantile(result[[i]]$permmat[,'HC'],alpha)){
        reject_matrix[i,'HCperm']=1
      }
      
      
      reject_matrix[i,'RACT'] = result[[i]]$RACT[,'all_min_p']
      reject_matrix[i,'XC'] = result[[i]]$XC$decision
      reject_matrix[i,'SY'] = (result[[i]]$SY$pvalue <= alpha)*1
      reject_matrix[i,'LC'] = (result[[i]]$LC$pvalue <= alpha)*1
      reject_matrix[i,'CLX'] = (result[[i]]$CLX$pvalue <= alpha)*1
      reject_matrix[i,'HC'] = (result[[i]]$HC$reject > 0)*1
      
    }
    
    experiment_df[x,method_names] = apply(reject_matrix,2,mean)
    
    print(x)  
  }
  
  col_order = color_palette[c(4,3,2,5,1)]
  
  norms_to_plot=c('SYperm','CLXperm','LCperm','HCperm','RACT')
  norms_to_plot_name=c('SY','CLX','LC','HC','RACT')
  
  # EACH PLOT SAVE AS 300X600
  point_cex=2
  text_size=2
  
  cov_slice = experiment_df[experiment_df$cov_cor=='cov',]
  
  for(n in unique(cov_slice$n)){
    n_slice=cov_slice[cov_slice$n==n,]
    for(cov_structure in unique(experiment_df$cov_structure)){
      cov_structure_slice=n_slice[n_slice$cov_structure==cov_structure,]
      
      for(cov_rank in sort(unique(cov_structure_slice$cov_rank))){
        experiment_df_slice=cov_structure_slice[cov_structure_slice$cov_rank==cov_rank,]
        p=experiment_df_slice$p[1]
        
        # Plot 1
        x=unique(experiment_df_slice$snr)
        
        par(mfrow=c(1,1),mar=c(2.5,4,1,1.5),mgp = c(3, 1.5, 0))
        plot(x=x,
             y=experiment_df_slice[,norms_to_plot[1]],
             col=col_order[1],ylim=c(0,1),type='p',pch=15,
             cex.main=text_size,cex.lab=text_size,cex.axis=text_size,
             cex=point_cex,main='',xlab='',ylab='',las=1)
        
        for(i in 2:5){
          lines(x=x,
                y=experiment_df_slice[,norms_to_plot[i]],
                col=col_order[i],type='p',pch=15,cex=point_cex) 
          
          if(norms_to_plot[i]=='RACT'){
            lines(x=x,
                  y=experiment_df_slice[,norms_to_plot[i]],
                  col=col_order[i],type='l',pch=15,cex=point_cex)
          }
        }
        
        abline(h=.05,lty=2)
        
        print(paste(cov_structure,cov_rank)) 
      }
      
    }
    
    
  }
  
  
}

simulated_compare_power_high_rank<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){
  function_name = 'simulated_compare_power_high_rank'
  
  K=1000         # 1000     
  B=1000         # 1000
  B_other = 1000 # 1000
  alpha=.05
  max_k_pct=.80
  test_stat_prefixes = c('sum')
  
  experiment_df_1=expand.grid(n=50,p=250,snr=seq(0,.03,length.out=15),
                              cov_rank=2,cov_structure='(LowRank)',seed_init=1,cov_cor=c('cov'),
                              stringsAsFactors = FALSE)
  experiment_df_2=expand.grid(n=50,p=250,snr=seq(0,.02,length.out=15),
                              cov_rank=5,cov_structure='(LowRank)',seed_init=1,cov_cor=c('cov'),
                              stringsAsFactors = FALSE)
  experiment_df_3=expand.grid(n=50,p=250,snr=seq(0,.02,length.out=15),
                              cov_rank=10,cov_structure='(LowRank)',seed_init=1,cov_cor=c('cov'),
                              stringsAsFactors = FALSE)
  experiment_df_4=expand.grid(n=50,p=250,snr=seq(0,.01,length.out=15),
                              cov_rank=25,cov_structure='(LowRank)',seed_init=2,cov_cor=c('cov'),
                              stringsAsFactors = FALSE)
  experiment_df_5=expand.grid(n=50,p=250,snr=seq(0,.01,length.out=15),
                              cov_rank=50,cov_structure='(LowRank)',seed_init=3,cov_cor=c('cov'),
                              stringsAsFactors = FALSE)
  experiment_df_6=expand.grid(n=50,p=250,snr=seq(0,.01,length.out=15),
                              cov_rank=100,cov_structure='(LowRank)',seed_init=4,cov_cor=c('cov'),
                              stringsAsFactors = FALSE)
  
  experiment_df=rbind(experiment_df_1,experiment_df_2,experiment_df_3,experiment_df_4,
                      experiment_df_5,experiment_df_6)
  
  experiment_df$initial_seed=(experiment_df$seed_init*100+experiment_df$cov_rank)*1000000
  experiment_df$experiment_number=1:nrow(experiment_df)
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    # Create variables from row of experiment_df
    list2env(as.list(experiment_df[x,]), envir = .GlobalEnv)
    
    setwd(WORKING_DIR)
    Sys.setenv(OMP_NUM_THREADS = 1,MKL_NUM_THREADS=1,BLAS_NUM_THREADS=1,LAPACK_NUM_THREDS=1)
    cl <- parallel::makeCluster(ncores,outfile="")
    doParallel::registerDoParallel(cl)
    
    experiment_results=foreach(i=1:K, 
                               .packages = c('MASS','RSpectra'),
                               .export = colnames(experiment_df))%dopar%{
                                 setwd(WORKING_DIR)
                                 source('NewAppsHelper.R')
                                 source('BrainHelperRevisions.R')
                                 
                                 set.seed(initial_seed+i)
                                 
                                 cov_mats=generate_covariance_matrix(cov_structure,snr,p,cov_rank)
                                 cov_matrix_1=cov_mats[[1]]
                                 cov_matrix_2=cov_mats[[2]]
                                 
                                 first_half_n=round(n/2)
                                 second_half_n=n-first_half_n
                                 
                                 X_1=t(MASS::mvrnorm(n=first_half_n,mu=rep(0,p),Sigm=cov_matrix_1,tol=10))
                                 X_2=t(MASS::mvrnorm(n=second_half_n,mu=rep(0,p),Sigm=cov_matrix_2,tol=10))
                                 x_matrix=cbind(X_1,X_2)
                                 
                                 group_1_residuals = x_matrix[,1:(n/2)]
                                 group_2_residuals = x_matrix[,(n/2+1):(n)]
                                 
                                 max_k = max_k_calculation(cbind(group_1_residuals,group_2_residuals),max_k_pct,
                                                           cov_cor=cov_cor) 
                                 
                                 reject_RACT = test_equality_cov_20240925(group_1_residuals,group_2_residuals,
                                                                          max_k,test_stat_prefixes,B,alpha,
                                                                          cov_cor = cov_cor)
                                 
                                 # Other methods (non permutation)
                                 reject_SY = UTDtst::SY2010(t(group_1_residuals),t(group_2_residuals))
                                 reject_LC = UTDtst::LC2012(t(group_1_residuals),t(group_2_residuals))
                                 reject_CLX = UTDtst::CLX2013(t(group_1_residuals),t(group_2_residuals))
                                 reject_HC = UTDtst::HC2018(t(group_1_residuals),t(group_2_residuals),alpha = alpha)
                                 reject_XC <- tryCatch({
                                   # XC seems to struggle with small n
                                   UTDtst::TwoSampleTest(t(group_1_residuals),t(group_2_residuals),
                                                         k=100,alpha=alpha)
                                 }, error = function(e) {
                                   list(decision=999)  # Return 999 if there is an error
                                 })

                                 # Permutation
                                 other_perm_matrix = matrix(data=NA,ncol=4,nrow=B_other)
                                 colnames(other_perm_matrix) = c('SY','LC','CLX','HC')

                                 set.seed(initial_seed+i)
                                 for(b in 1:B_other){
                                   combined_residuals = cbind(group_1_residuals,group_2_residuals)
                                   permutation_order = sample(1:n)
                                   group_1_permutation = combined_residuals[,permutation_order[1:(n/2)]]
                                   group_2_permutation = combined_residuals[,permutation_order[(n/2+1):(n)]]

                                   other_perm_matrix[b,'SY'] = UTDtst::SY2010(t(group_1_permutation),t(group_2_permutation))$Q2
                                   other_perm_matrix[b,'LC'] = UTDtst::LC2012(t(group_1_permutation),t(group_2_permutation))$statistic
                                   other_perm_matrix[b,'CLX'] = UTDtst::CLX2013(t(group_1_permutation),t(group_2_permutation))$TSvalue
                                   other_perm_matrix[b,'HC'] = min(UTDtst::HC2018(t(group_1_permutation),t(group_2_permutation),alpha = alpha)$pvalues)
                                 }

                                 print(i)
                                 print(Sys.time())

                                 return_vec =list(reject_RACT,
                                                  reject_SY,
                                                  reject_LC,
                                                  reject_CLX,
                                                  reject_HC,
                                                  reject_XC,
                                                  other_perm_matrix)
                                 names(return_vec) = c('RACT','SY','LC','CLX','HC','XC','permmat')


                                 
                                 return_vec
                                 
                               }
    
    parallel::stopCluster(cl)
    
    save_experiment_result_to_RDS(experiment_number,function_name,RESULTS_DIR,experiment_results)
  }
}

simulated_compare_power_high_rank_writeup<-function(){
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  # COMPARE TYPE I AND POWER ACROSS METHODS
  function_name = 'simulated_compare_power_high_rank'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  method_names = c('SYperm','LCperm','CLXperm','HCperm','SY','LC','CLX','HC','RACT','XC')
  experiment_df[,method_names] = NA
  alpha = 0.05
  
  for(x in 1:nrow(experiment_df)){
    filename = paste(function_name,'-',sprintf("%03d",x),'.RDS',sep='')
    result = readRDS(filename)
    
    reject_matrix = matrix(data=0,nrow=length(result),ncol=10)
    colnames(reject_matrix) = method_names
    
    for(i in 1:length(result)){
      
      if(result[[i]]$SY$Q2 <= quantile(result[[i]]$permmat[,'SY'],alpha/2)){
        reject_matrix[i,'SYperm']=1
      }

      if(result[[i]]$SY$Q2 >= quantile(result[[i]]$permmat[,'SY'],1-alpha/2)){
        reject_matrix[i,'SYperm']=1
      }

      if(result[[i]]$LC$statistic >= quantile(result[[i]]$permmat[,'LC'],1-alpha)){
        reject_matrix[i,'LCperm']=1
      }

      if(result[[i]]$CLX$TSvalue >= quantile(result[[i]]$permmat[,'CLX'],1-alpha)){
        reject_matrix[i,'CLXperm']=1
      }

      if(min(result[[i]]$HC$pvalues) <= quantile(result[[i]]$permmat[,'HC'],alpha)){
        reject_matrix[i,'HCperm']=1
      }
      
      
      reject_matrix[i,'RACT'] = result[[i]]$RACT[,'all_min_p']
      reject_matrix[i,'XC'] = result[[i]]$XC$decision
      reject_matrix[i,'SY'] = (result[[i]]$SY$pvalue <= alpha)*1
      reject_matrix[i,'LC'] = (result[[i]]$LC$pvalue <= alpha)*1
      reject_matrix[i,'CLX'] = (result[[i]]$CLX$pvalue <= alpha)*1
      reject_matrix[i,'HC'] = (result[[i]]$HC$reject > 0)*1

    }
    
    experiment_df[x,method_names] = apply(reject_matrix,2,mean)
    
    print(x)  
  }
  
  col_order = color_palette[c(4,3,2,5,1)]
  
  norms_to_plot=c('SYperm','CLXperm','LCperm','HCperm','RACT')
  norms_to_plot_name=c('SY','CLX','LC','HC','RACT')
  
  # EACH PLOT SAVE AS 300X600
  point_cex=2
  text_size=2
  
  cov_slice = experiment_df[experiment_df$cov_cor=='cov',]
  
  for(n in unique(cov_slice$n)){
    n_slice=cov_slice[cov_slice$n==n,]
    for(cov_structure in unique(experiment_df$cov_structure)){
      cov_structure_slice=n_slice[n_slice$cov_structure==cov_structure,]
      
      for(cov_rank in sort(unique(cov_structure_slice$cov_rank))){
        experiment_df_slice=cov_structure_slice[cov_structure_slice$cov_rank==cov_rank,]
        p=experiment_df_slice$p[1]
        
        # Plot 1
        x=unique(experiment_df_slice$snr)
        
        par(mfrow=c(1,1),mar=c(2.5,4,1,1.5),mgp = c(3, 1.5, 0))
        plot(x=x,
             y=experiment_df_slice[,norms_to_plot[1]],
             col=col_order[1],ylim=c(0,1),type='p',pch=15,
             cex.main=text_size,cex.lab=text_size,cex.axis=text_size,
             cex=point_cex,main='',xlab='',ylab='',las=1)
        
        for(i in 2:5){
          lines(x=x,
                y=experiment_df_slice[,norms_to_plot[i]],
                col=col_order[i],type='p',pch=15,cex=point_cex) 
          
          if(norms_to_plot[i]=='RACT'){
            lines(x=x,
                  y=experiment_df_slice[,norms_to_plot[i]],
                  col=col_order[i],type='l',pch=15,cex=point_cex)
          }
        }
        
        abline(h=.05,lty=2)
        
        print(paste(cov_structure,cov_rank)) 
      }
      
    }
    
    
  }
  
  
}


cov_difference<-function(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR){

  function_name = 'cov_difference'
  
  experiment_df = expand.grid(dataset = c('TCGA','SPINS-FA','SPINS-MD'),
                              stringsAsFactors = FALSE)
  
  experiment_df = setup_directory_and_experiment_df(experiment_df,job_num,RESULTS_DIR,function_name)
  
  # Run experiments
  for(x in 1:nrow(experiment_df)){
    dataset = experiment_df[x,'dataset']
    
    # Based on which dataset we are analyzing, import both groups from the appropriate dataset
    if(dataset=='TCGA'){
      setwd(WORKING_DIR)  
      gene_expression_residuals = readRDS('tcga_residual_matrices.rds')
      group_1_residuals = gene_expression_residuals[['TCGA-LUAD']]
      group_2_residuals = gene_expression_residuals[['TCGA-LUSC']]
    }else if(dataset=='SPINS-FA'){
      # Import Data
      setwd(SPINS_PROCESSED_DIR)
      spins_residuals = readRDS('spins_residuals_matrices_FA.rds')
      group_1_residuals = spins_residuals[['GE']]
      group_2_residuals = spins_residuals[['SP']]
    }else if(dataset=='SPINS-MD'){
      # Import Data
      setwd(SPINS_PROCESSED_DIR)
      spins_residuals = readRDS('spins_residuals_matrices_MD.rds')
      group_1_residuals = spins_residuals[['GE']]
      group_2_residuals = spins_residuals[['SP']]
    }
    
    cov_diff = cov(t(group_1_residuals)) - cov(t(group_2_residuals))
    
    setwd(file.path(RESULTS_DIR,function_name))
    saveRDS(cov_diff,file=paste(dataset,'_cov.RDS',sep=''))
    
    # Save CSV of spectrum
    spectrum_df = data.frame(matrix(ncol = 4, nrow = nrow(group_1_residuals)))
    colnames(spectrum_df) = c('pooled','group_1','group_2','difference')
    spectrum_df[,'pooled'] = sort(svd(cov(t(cbind(group_1_residuals,group_2_residuals))))$d,decreasing=TRUE)
    spectrum_df[,'group_1'] = sort(svd(cov(t(group_1_residuals)))$d,decreasing=TRUE)
    spectrum_df[,'group_2'] = sort(svd(cov(t(group_2_residuals)))$d,decreasing=TRUE)
    spectrum_df[,'difference'] = sort(svd(cov_diff)$d,decreasing=TRUE)
    
    for(col in colnames(spectrum_df)){
      spectrum_df[,col] = spectrum_df[,col]/sum(spectrum_df[,col])
      spectrum_df[,col] = cumsum(spectrum_df[,col])
    }
    
    write.csv(spectrum_df,file=paste(dataset,'_spectrum.csv',sep=''))
        
  }
    
    
}


cov_difference_writeup<-function(){
  library(RColorBrewer)
  # Difference between covariance matrices
  function_name = 'cov_difference'
  
  setwd(file.path(RESULTS_DIR,function_name))
  
  # Smallest k most powerful for subsample size 20
  select_k = list('TCGA'=19,'SPINS-FA'=12,'SPINS-MD'=20)
  
  # Need to repeat code so image(Matrix()) works  
  ncolors = 25
  ramp_colors = colors <- colorRampPalette(c("blue", "grey", "red"))(ncolors+1)
  at_colors = seq(-1,1,length.out=ncolors)
  
  dataset = 'TCGA'  
  orig_cov_mat_diff = readRDS(paste(dataset,'_cov.RDS',sep=''))
  svd_cov_mat_diff  = svd(orig_cov_mat_diff)
  svd_cov_mat_diff$d[(as.numeric(select_k[dataset])+1):nrow(orig_cov_mat_diff)] = 0
  low_rank_cov_mat_diff = svd_cov_mat_diff$u %*% diag(svd_cov_mat_diff$d) %*% t(svd_cov_mat_diff$v)
  max_abs = max(max(abs(orig_cov_mat_diff)),max(abs(low_rank_cov_mat_diff)))
  
  cluster_order = rev(hclust(as.dist(orig_cov_mat_diff),method='average')$order)
  
  image(Matrix(orig_cov_mat_diff[cluster_order,cluster_order]/max_abs),lwd=0,xlab='',ylab='',sub='',
        col.regions=ramp_colors,at=at_colors,colorkey=FALSE, 
        scales = list(x = list(draw=FALSE), y = list(draw=FALSE))) 
  image(Matrix(low_rank_cov_mat_diff[cluster_order,cluster_order]/max_abs),lwd=0,xlab='',ylab='',sub='',
        col.regions=ramp_colors,at=at_colors,colorkey=FALSE,
        scales = list(x = list(draw=FALSE), y = list(draw=FALSE)))          
  
  dataset = 'SPINS-FA'  
  orig_cov_mat_diff = readRDS(paste(dataset,'_cov.RDS',sep=''))
  svd_cov_mat_diff  = svd(orig_cov_mat_diff)
  svd_cov_mat_diff$d[(as.numeric(select_k[dataset])+1):nrow(orig_cov_mat_diff)] = 0
  low_rank_cov_mat_diff = svd_cov_mat_diff$u %*% diag(svd_cov_mat_diff$d) %*% t(svd_cov_mat_diff$v)
  max_abs = max(max(abs(orig_cov_mat_diff)),max(abs(low_rank_cov_mat_diff)))

  image(Matrix(orig_cov_mat_diff/max_abs),lwd=0,xlab='',ylab='',sub='',
        col.regions=ramp_colors,at=at_colors,colorkey=FALSE,
        scales = list(x = list(draw=FALSE), y = list(draw=FALSE))) 
  image(Matrix(low_rank_cov_mat_diff/max_abs),lwd=0,xlab='',ylab='',sub='',
        col.regions=ramp_colors,at=at_colors,colorkey=FALSE,
        scales = list(x = list(draw=FALSE), y = list(draw=FALSE)))
  
  dataset = 'SPINS-MD'  
  orig_cov_mat_diff = readRDS(paste(dataset,'_cov.RDS',sep=''))
  svd_cov_mat_diff  = svd(orig_cov_mat_diff)
  svd_cov_mat_diff$d[(as.numeric(select_k[dataset])+1):nrow(orig_cov_mat_diff)] = 0
  low_rank_cov_mat_diff = svd_cov_mat_diff$u %*% diag(svd_cov_mat_diff$d) %*% t(svd_cov_mat_diff$v)
  max_abs = max(max(abs(orig_cov_mat_diff)),max(abs(low_rank_cov_mat_diff)))
  
  image(Matrix(orig_cov_mat_diff/max_abs),lwd=0,xlab='',ylab='',sub='',
        col.regions=ramp_colors,at=at_colors,        
        colorkey=FALSE,
        scales = list(x = list(draw=FALSE), y = list(draw=FALSE))) 
  image(Matrix(low_rank_cov_mat_diff/max_abs),lwd=0,xlab='',ylab='',sub='',
        col.regions=ramp_colors,at=at_colors,colorkey=FALSE,
        scales = list(x = list(draw=FALSE), y = list(draw=FALSE)))
  
  
  # JUST TO GET THE SCALE
  image(Matrix(low_rank_cov_mat_diff/max_abs),lwd=0,xlab='',ylab='',sub='',
        col.regions=ramp_colors,at=at_colors,colorkey=TRUE,
        scales = list(x = list(draw=FALSE), y = list(draw=FALSE)))
  
  
  
  # Spectrum Facts
  
  
}

real_data_sims_writeup<-function(){
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  # COMPARE TYPE I AND POWER ACROSS METHODS
  function_name = 'real_data_sims'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  
  # Get column names where we predefine k and add them as columns
  filename=paste(function_name,'-',sprintf("%03d",nrow(experiment_df)),'.RDS',sep='')
  experiment_result = readRDS(file=filename)
  result_colnames = colnames(experiment_result[[1]][[2]])
  experiment_df[,result_colnames] = 999
  
  for(experiment_number in experiment_df$experiment_number){
    filename=paste(function_name,'-',sprintf("%03d",experiment_number),'.RDS',sep='')
    experiment_result = readRDS(file=filename)
    result_colnames = colnames(experiment_result[[experiment_number]][[2]])
    K = length(experiment_result)
    
    experiment_df[experiment_number,result_colnames] = Reduce('+',lapply(experiment_result, function(x) x[[2]]))/K
  }
  
  # Manually found
  target_power = 0.75
  
  # ADAPTIVITY CHARTS SAVE AS 2400X1200
  for(dataset in unique(experiment_df$dataset)){
    # Closest experiment to target power
    df_slice = experiment_df[((experiment_df$cov_cor=='cov')&
                                         (experiment_df$dataset==dataset)&
                                         (experiment_df$null_flag=='not_null')),]
    experiment_number = df_slice[which.min(abs(df_slice$all_min_p-target_power)),'experiment_number']
    
    power_vector = c(unlist(experiment_df[experiment_number,c(paste0('sum_',1:20),'all_min_p')]))
    
    par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5)) # Set layout to 2x2
    plt = barplot(power_vector-0.25, beside = TRUE, col = c(rep(color_palette[6],20),color_palette[1]), 
                  xaxt='n',yaxt='n',las=2,ylim=c(0,.75))
    axis(2, at = c(0, 0.25, 0.5,0.75), labels = c("0.25", "0.50","0.75","1.00"),las=1,cex.axis=3)
    
    text(plt, adj=0,par("usr")[3] - .025 , labels = c(paste0('k=',seq(1,20)),'RACT'), srt = 45, pos = 1, xpd = TRUE,cex=2)
    
    print(dataset)
    print(experiment_df[experiment_df$experiment_number==experiment_number,'subsample_size'])
    print('MAX POWER FROM')
    print(which(power_vector==max(power_vector)))
    
  }
  
  # For cases where power is not 1.000, which k have highest power
  optim_df_slice = experiment_df[(experiment_df$null_flag=='not_null')&(experiment_df$cov_cor=='cov'),]
  optim_df_slice[optim_df_slice == 999] = 0
  max_df_slice = optim_df_slice
  max_df_slice[,paste0('sum_',1:50)] = 0
  rownames(max_df_slice) = 1:nrow(max_df_slice)
  
  for(x in 1:nrow(optim_df_slice)){
    max_df_slice[x,paste0('sum_',1:50)] = (
      1*(optim_df_slice[x,paste0('sum_',1:50)] == max( optim_df_slice[x,paste0('sum_',1:50)]))
    )
  }
  
  manual_max = max_df_slice[,1:7]
  manual_max[,'range']= c('13','19-22','13-34','12-50','7-50','5-50','5-50','4-50',
                          '9-12','12','10','12','16','14','19, 22-23','19-26',
                          '14','20','13','8-50','6-50','3-50','2-50','1-50')
  
  manual_table = data.frame('Subsample Size'=seq(15,50,by=5))
  for(dataset in unique(manual_max$dataset)){
    manual_table[,dataset] = manual_max[manual_max$dataset==dataset,'range']  
  }
  
  
  
  
}

real_data_compare_writeup<-function(){
  # New compare methods
  function_name = 'real_data_compare'
  setwd(file.path(RESULTS_DIR,function_name))
  experiment_df = read.csv('experiment_df.csv')
  method_names = c('SYperm','LCperm','CLXperm','HCperm','SY','LC','CLX','HC','RACT','XC')
  experiment_df[,method_names] = NA
  alpha = 0.05
  library(RColorBrewer)
  color_palette = RColorBrewer::brewer.pal(8, "Set2")
  
  for(x in 1:nrow(experiment_df)){
    filename = paste(function_name,'-',sprintf("%03d",x),'.RDS',sep='')
    result = readRDS(filename)
    
    reject_matrix = matrix(data=0,nrow=length(result),ncol=10)
    colnames(reject_matrix) = method_names
    
    for(i in 1:length(result)){
      
      if(result[[i]]$SY$Q2 <= quantile(result[[i]]$permmat[,'SY'],alpha/2)){
        reject_matrix[i,'SYperm']=1
      }
      
      if(result[[i]]$SY$Q2 >= quantile(result[[i]]$permmat[,'SY'],1-alpha/2)){
        reject_matrix[i,'SYperm']=1
      }
      
      if(result[[i]]$LC$statistic >= quantile(result[[i]]$permmat[,'LC'],1-alpha)){
        reject_matrix[i,'LCperm']=1
      }
      
      if(result[[i]]$CLX$TSvalue >= quantile(result[[i]]$permmat[,'CLX'],1-alpha)){
        reject_matrix[i,'CLXperm']=1
      }
      
      if(min(result[[i]]$HC$pvalues) <= quantile(result[[i]]$permmat[,'HC'],alpha)){
        reject_matrix[i,'HCperm']=1
      }
      
      
      reject_matrix[i,'RACT'] = result[[i]]$RACC
      reject_matrix[i,'XC'] = result[[i]]$XC$decision
      reject_matrix[i,'SY'] = (result[[i]]$SY$pvalue <= alpha)*1
      reject_matrix[i,'LC'] = (result[[i]]$LC$pvalue <= alpha)*1
      reject_matrix[i,'CLX'] = (result[[i]]$CLX$pvalue <= alpha)*1
      reject_matrix[i,'HC'] = (result[[i]]$HC$reject > 0)*1
      
    }
    
    experiment_df[x,method_names] = apply(reject_matrix,2,mean)
    
    print(x)  
  }
  
  # Ordering of methods/colors
  adaptivity_order = c('subsample_size','SY','CLXperm','LCperm','HCperm','RACT')
  col_order = color_palette[c(4,3,2,5,1)]
  
  # TCGA Type I
  experiment_df[(experiment_df$dataset=='TCGA')&(experiment_df$cov_cor=='cov'),]
  
  # TCGA Power
  
  # Power chart, save as 2400x1200 PNG
  df_slice = experiment_df[((experiment_df$null_flag == 'not_null')&
                              (experiment_df$cov_cor=='cov')&
                              (experiment_df$subsample_size>=15)&
                              (experiment_df$dataset=='TCGA')),]
  df_slice = df_slice[,adaptivity_order]
  
  # Given we exclude and XC, only use colors 1,2,3,4
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5))  # Set layout to 2x2
  plt = barplot(as.matrix(t(df_slice[,colnames(df_slice)[-1]])), beside=TRUE, 
                names.arg = df_slice[,'subsample_size'],
                col = col_order,yaxt='n',las=1,xaxt='n',ylim=c(0,1.00))
  axis(2, at = c(0, 0.25, 0.50,0.75,1.00), labels = c("0.00", "0.25","0.50", "0.75","1.00"),
       las=1,cex.axis=3,ylim=c(0,1))
  
  text(plt[2,]+.2, adj=0,par("usr")[3] - 0.05, labels = seq(15,50,by=5), srt = 45, pos = 1, xpd = TRUE,cex=3)
  
  # SPINS FA Type I
  experiment_df[(experiment_df$dataset=='SPINS-FA')&(experiment_df$cov_cor=='cov'),]
  
  # SPINS FA Power
  
  # Power chart, save as 2400x1200 PNG
  df_slice = experiment_df[((experiment_df$null_flag == 'not_null')&
                              (experiment_df$cov_cor=='cov')&
                              (experiment_df$subsample_size>=15)&
                              (experiment_df$dataset=='SPINS-FA')),]
  df_slice = df_slice[,adaptivity_order]
  
  # Given we exclude and XC, only use colors 1,2,3,4
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5))  # Set layout to 2x2
  plt = barplot(as.matrix(t(df_slice[,colnames(df_slice)[-1]])), beside=TRUE, 
                names.arg = df_slice[,'subsample_size'],
                col = col_order,yaxt='n',las=1,xaxt='n',ylim=c(0,1.00))
  axis(2, at = c(0, 0.25, 0.50,0.75,1.00), labels = c("0.00", "0.25","0.50", "0.75","1.00"),
       las=1,cex.axis=3,ylim=c(0,1))
  
  text(plt[2,]+.2, adj=0,par("usr")[3] - 0.05, labels = seq(15,50,by=5), srt = 45, pos = 1, xpd = TRUE,cex=3)
  
  # SPINS MD Type I
  experiment_df[(experiment_df$dataset=='SPINS-MD')&(experiment_df$cov_cor=='cov'),]
  
  # SPINS MD Power
  
  # Power chart, save as 2400x1200 PNG
  df_slice = experiment_df[((experiment_df$null_flag == 'not_null')&
                              (experiment_df$cov_cor=='cov')&
                              (experiment_df$subsample_size>=15)&
                              (experiment_df$dataset=='SPINS-MD')),]
  df_slice = df_slice[,adaptivity_order]
  
  # Given we exclude and XC, only use colors 1,2,3,4
  par(mfrow=c(1,1),mar=c(6.5,6.5,4,0.5))  # Set layout to 2x2
  plt = barplot(as.matrix(t(df_slice[,colnames(df_slice)[-1]])), beside=TRUE, 
                names.arg = df_slice[,'subsample_size'],
                col = col_order,yaxt='n',las=1,xaxt='n',ylim=c(0,1.00))
  axis(2, at = c(0, 0.25, 0.50,0.75,1.00), labels = c("0.00", "0.25","0.50", "0.75","1.00"),
       las=1,cex.axis=3,ylim=c(0,1))
  
  text(plt[2,]+.2, adj=0,par("usr")[3] - 0.05, labels = seq(15,50,by=5), srt = 45, pos = 1, xpd = TRUE,cex=3)
  
  
  
}



#### Run Code ####
print(Sys.time())
do.call(function_call,list(job_num,RESULTS_DIR,WORKING_DIR,FIGURE_DIR))
print(Sys.time())

